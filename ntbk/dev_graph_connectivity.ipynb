{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600pt\" height=\"600pt\" viewBox=\"0 0 600 600\" version=\"1.1\">\n",
       "<g id=\"surface218\">\n",
       "<rect x=\"0\" y=\"0\" width=\"600\" height=\"600\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 328.414062 580 L 183.84375 567.5625 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 183.84375 567.5625 L 76.066406 554.535156 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 113.167969 312.484375 L 20 177.296875 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 403.28125 403.304688 L 233.890625 441.113281 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 113.167969 312.484375 L 233.890625 441.113281 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 328.414062 580 L 233.890625 441.113281 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 183.84375 567.5625 L 233.890625 441.113281 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 76.066406 554.535156 L 233.890625 441.113281 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 113.167969 312.484375 L 25.707031 443.445312 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 183.84375 567.5625 L 25.707031 443.445312 \"/>\n",
       "<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 76.066406 554.535156 L 25.707031 443.445312 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 413.28125 403.304688 C 413.28125 408.828125 408.804688 413.304688 403.28125 413.304688 C 397.761719 413.304688 393.28125 408.828125 393.28125 403.304688 C 393.28125 397.78125 397.761719 393.304688 403.28125 393.304688 C 408.804688 393.304688 413.28125 397.78125 413.28125 403.304688 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 590 223.867188 C 590 229.390625 585.523438 233.867188 580 233.867188 C 574.476562 233.867188 570 229.390625 570 223.867188 C 570 218.34375 574.476562 213.867188 580 213.867188 C 585.523438 213.867188 590 218.34375 590 223.867188 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 123.167969 312.484375 C 123.167969 318.007812 118.691406 322.484375 113.167969 322.484375 C 107.648438 322.484375 103.167969 318.007812 103.167969 312.484375 C 103.167969 306.960938 107.648438 302.484375 113.167969 302.484375 C 118.691406 302.484375 123.167969 306.960938 123.167969 312.484375 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 338.414062 580 C 338.414062 585.523438 333.9375 590 328.414062 590 C 322.894531 590 318.414062 585.523438 318.414062 580 C 318.414062 574.476562 322.894531 570 328.414062 570 C 333.9375 570 338.414062 574.476562 338.414062 580 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 193.84375 567.5625 C 193.84375 573.085938 189.367188 577.5625 183.84375 577.5625 C 178.320312 577.5625 173.84375 573.085938 173.84375 567.5625 C 173.84375 562.039062 178.320312 557.5625 183.84375 557.5625 C 189.367188 557.5625 193.84375 562.039062 193.84375 567.5625 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 86.066406 554.535156 C 86.066406 560.058594 81.589844 564.535156 76.066406 564.535156 C 70.542969 564.535156 66.066406 560.058594 66.066406 554.535156 C 66.066406 549.015625 70.542969 544.535156 76.066406 544.535156 C 81.589844 544.535156 86.066406 549.015625 86.066406 554.535156 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 30 177.296875 C 30 182.820312 25.523438 187.296875 20 187.296875 C 14.476562 187.296875 10 182.820312 10 177.296875 C 10 171.777344 14.476562 167.296875 20 167.296875 C 25.523438 167.296875 30 171.777344 30 177.296875 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 243.890625 441.113281 C 243.890625 446.636719 239.414062 451.113281 233.890625 451.113281 C 228.367188 451.113281 223.890625 446.636719 223.890625 441.113281 C 223.890625 435.589844 228.367188 431.113281 233.890625 431.113281 C 239.414062 431.113281 243.890625 435.589844 243.890625 441.113281 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 312.703125 20 C 312.703125 25.523438 308.226562 30 302.703125 30 C 297.179688 30 292.703125 25.523438 292.703125 20 C 292.703125 14.476562 297.179688 10 302.703125 10 C 308.226562 10 312.703125 14.476562 312.703125 20 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 35.707031 443.445312 C 35.707031 448.96875 31.230469 453.445312 25.707031 453.445312 C 20.183594 453.445312 15.707031 448.96875 15.707031 443.445312 C 15.707031 437.921875 20.183594 433.445312 25.707031 433.445312 C 31.230469 433.445312 35.707031 437.921875 35.707031 443.445312 \"/>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<igraph.drawing.Plot at 0x7fdfdfa49c50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = ig.Graph.Erdos_Renyi(n = 10, m = 11)\n",
    "layout = g.layout('kk')\n",
    "ig.plot(g, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(inf, grad_fn=<NegBackward>)\n",
      "tensor(16.8405, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "adjM = torch.autograd.Variable(torch.Tensor(g.get_adjacency().data), requires_grad = True)\n",
    "N = adjM.shape[0]\n",
    "\n",
    "# get Laplacian\n",
    "L = torch.diag(torch.matmul(adjM, torch.ones(N))) - adjM\n",
    "L_mod = L + torch.ones_like(L)/N\n",
    "\n",
    "# calculate log dets\n",
    "eps = 10e-6\n",
    "print(-torch.logdet(L_mod))\n",
    "print(-torch.logdet(L_mod + eps * torch.eye(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<DetBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.det(L_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "from otgnn.graph import SYMBOLS, FORMAL_CHARGES, BOND_TYPES, get_bt_index\n",
    "\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.decoder_mol_opt import MolOptDecoder\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, get_latest_model\n",
    "from mol_opt.ot_utils import encode_target, FGW, Penalty\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"val\", 96, False)\n",
    "for i in data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\", \"-cuda\"]\n",
    "args = get_args()\n",
    "args.output_dir = \"mol_opt/output/\"\n",
    "\n",
    "mol_opt = MolOpt(args)\n",
    "mol_opt_decoder = MolOptDecoder(args)\n",
    "loss = FGW(alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9284454981486"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding, x_delta_hat = mol_opt.forward(X)\n",
    "yhat_embedding = x_embedding + x_delta_hat\n",
    "yhat_logits = mol_opt_decoder.forward(yhat_embedding, Y)\n",
    "yhat_labels = mol_opt_decoder.discretize(*yhat_logits)\n",
    "\n",
    "pred_pack = (yhat_labels, yhat_logits, Y.scope), Y\n",
    "loss(*pred_pack).item() / 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4475, 1.4952, 1.5972, 1.6081, 1.9811],\n",
       "         [1.4704, 1.4572, 1.6036, 1.6494, 1.9384],\n",
       "         [1.4597, 1.4890, 1.5800, 1.6491, 1.9386],\n",
       "         ...,\n",
       "         [1.4925, 1.4767, 1.5328, 1.6879, 1.9245],\n",
       "         [1.4903, 1.5252, 1.5346, 1.6160, 1.9457],\n",
       "         [1.4720, 1.4965, 1.5149, 1.6838, 1.9582]],\n",
       "\n",
       "        [[1.4704, 1.4572, 1.6036, 1.6494, 1.9384],\n",
       "         [1.4578, 1.4504, 1.6220, 1.6865, 1.8964],\n",
       "         [1.4670, 1.4519, 1.6187, 1.6727, 1.9014],\n",
       "         ...,\n",
       "         [1.4980, 1.4536, 1.5355, 1.7377, 1.8878],\n",
       "         [1.5056, 1.4817, 1.5517, 1.6461, 1.9231],\n",
       "         [1.4901, 1.4428, 1.5473, 1.7056, 1.9386]],\n",
       "\n",
       "        [[1.4597, 1.4890, 1.5800, 1.6491, 1.9386],\n",
       "         [1.4670, 1.4519, 1.6187, 1.6727, 1.9014],\n",
       "         [1.4731, 1.4495, 1.6059, 1.6871, 1.8949],\n",
       "         ...,\n",
       "         [1.4940, 1.4757, 1.5199, 1.7161, 1.9078],\n",
       "         [1.4890, 1.5136, 1.5446, 1.6427, 1.9143],\n",
       "         [1.4738, 1.4779, 1.5288, 1.7063, 1.9344]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.4925, 1.4767, 1.5328, 1.6879, 1.9245],\n",
       "         [1.4980, 1.4536, 1.5355, 1.7377, 1.8878],\n",
       "         [1.4940, 1.4757, 1.5199, 1.7161, 1.9078],\n",
       "         ...,\n",
       "         [1.5497, 1.4605, 1.4622, 1.7624, 1.8825],\n",
       "         [1.5330, 1.4936, 1.4664, 1.7031, 1.9194],\n",
       "         [1.5187, 1.4800, 1.4566, 1.7456, 1.9256]],\n",
       "\n",
       "        [[1.4903, 1.5252, 1.5346, 1.6160, 1.9457],\n",
       "         [1.5056, 1.4817, 1.5517, 1.6461, 1.9231],\n",
       "         [1.4890, 1.5136, 1.5446, 1.6427, 1.9143],\n",
       "         ...,\n",
       "         [1.5330, 1.4936, 1.4664, 1.7031, 1.9194],\n",
       "         [1.5357, 1.5408, 1.4610, 1.6441, 1.9290],\n",
       "         [1.5132, 1.5016, 1.4511, 1.7101, 1.9530]],\n",
       "\n",
       "        [[1.4720, 1.4965, 1.5149, 1.6838, 1.9582],\n",
       "         [1.4901, 1.4428, 1.5473, 1.7056, 1.9386],\n",
       "         [1.4738, 1.4779, 1.5288, 1.7063, 1.9344],\n",
       "         ...,\n",
       "         [1.5187, 1.4800, 1.4566, 1.7456, 1.9256],\n",
       "         [1.5132, 1.5016, 1.4511, 1.7101, 1.9530],\n",
       "         [1.4873, 1.4723, 1.4410, 1.7682, 1.9856]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(*pred_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_logits, charges_logits, bonds_logits = yhat_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44494, 5])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonds_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = Penalty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23.408793131510418"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pen.conn(*pred_pack).item() / 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_idx = 0\n",
    "num_atoms = 22\n",
    "adjM = bonds_soft[bond_idx:bond_idx+num_atoms*num_atoms].view(num_atoms, num_atoms, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0',\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjM.sum(axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5057, 1.4681, 1.5239, 1.7426, 1.8653], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjM[0,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 22, 5])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44494, 5])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonds_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1937,  0.1839,  0.1660, -0.0629, -0.1889], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonds_logits[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1544, 0.1548, 0.1487,  ..., 0.1446, 0.1421, 0.1404], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonds_soft[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds_soft = nn.Softmax(dim=1)(bonds_logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
