{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, get_latest_model\n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(N_transformer=6, agg_func='sum', batch_norm=False, batch_size=500, conn_lambda_end=3, conn_lambda_epochs_end=20, conn_lambda_epochs_start=12, conn_lambda_start=0.001, conn_penalty_function='capped_logdet', connectivity=True, connectivity_hard=False, cross_att_dim=150, cross_att_use=False, cuda=True, device='cuda:0', dim_tangent_space=40, dropout_ffn=0.0, dropout_gcn=0.0, dropout_transformer=0.1, euler_characteristic_penalty=True, euler_lambda_end=2, euler_lambda_epochs_end=20, euler_lambda_epochs_start=12, euler_lambda_start=0.001, ffn_activation='LeakyReLU', init_decoder_model='deepsets-chembl1_decode', init_model='deepsets-chembl1', linear_out=False, max_num_atoms=70, model_type='deepsets', morgan_bits=0, n_epochs=30, n_ffn_hidden=100, n_ffn_transformer=100, n_heads_transformer=10, n_hidden=400, n_labels=1, n_layers=5, one_batch_train=False, ot_solver='emd', output_dir='mol_opt/output_dev3/deepsets-chembl1', pc_hidden=150, penalty_gumbel=False, pred_hidden=150, rec_lambda_end=100, rec_lambda_epochs_end=50, rec_lambda_epochs_start=1, rec_lambda_start=1, reconstruction_loss=False, scale_lambdas=True, sinkhorn_entropy=0.1, sinkhorn_max_it=10000, task='qed', tau_end=0.01, tau_epochs_end=17, tau_epochs_start=1, tau_start=1, tb_logs_dir='mol_opt/logs_dev3/deepsets-chembl1', valency=True, valency_hard=False, valency_lambda_end=5, valency_lambda_epochs_end=20, valency_lambda_epochs_start=12, valency_lambda_start=0.001) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = \"deepsets\"\n",
    "sys.argv = [\"\", \"-cuda\", \"-model_type\", model_type]\n",
    "args = get_args()\n",
    "outdir_suffix = \"dev3\"\n",
    "args.n_epochs = 30 \n",
    "args.init_model = \"{}-chembl1\".format(model_type)\n",
    "# args.init_model = \"{}-test1\".format(model_type)\n",
    "args.init_decoder_model = \"{}_decode\".format(args.init_model)\n",
    "args.output_dir = \"mol_opt/output_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "args.tb_logs_dir = \"mol_opt/logs_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "args.batch_size = 500\n",
    "\n",
    "args.penalty_gumbel = False \n",
    "\n",
    "args.n_hidden = 400\n",
    "\n",
    "# for long runs\n",
    "args.scale_lambdas = True\n",
    "args.connectivity = True \n",
    "args.valency = True \n",
    "args.euler_characteristic_penalty = True\n",
    "args.conn_lambda_start = 0.001\n",
    "args.conn_lambda_end = 3\n",
    "args.conn_lambda_epochs_start = 12\n",
    "args.conn_lambda_epochs_end = 20\n",
    "args.valency_lambda_start = 0.001\n",
    "args.valency_lambda_end = 5\n",
    "args.valency_lambda_epochs_start = 12\n",
    "args.valency_lambda_epochs_end = 20\n",
    "args.euler_lambda_start = 0.001 \n",
    "args.euler_lambda_end = 2 \n",
    "args.euler_lambda_epochs_start = 12\n",
    "args.euler_lambda_epochs_end = 20\n",
    "args.tau_start = 1\n",
    "args.tau_end = 0.01\n",
    "args.tau_epochs_start = 1\n",
    "args.tau_epochs_end = 17\n",
    "\n",
    "args.morgan_bits = 0\n",
    "\n",
    "args.conn_penalty_function = \"capped_logdet\" \n",
    "\n",
    "print(args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = \"molemb\"\n",
    "# sys.argv = [\"\", \"-cuda\", \"-model_type\", model_type, \"-one_batch_train\"]\n",
    "# args = get_args()\n",
    "# outdir_suffix = \"dev3\"\n",
    "# args.n_epochs = 15000 \n",
    "# args.init_model = \"{}-morgan-test1\".format(model_type)\n",
    "# # args.init_model = \"{}-test1\".format(model_type)\n",
    "# args.init_decoder_model = \"{}_decode\".format(args.init_model)\n",
    "# args.output_dir = \"mol_opt/output_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "# args.tb_logs_dir = \"mol_opt/logs_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "# args.batch_size = 50 \n",
    "\n",
    "# args.penalty_gumbel = False \n",
    "\n",
    "# args.scale_lambdas = True\n",
    "# args.connectivity = True \n",
    "# args.valency = True \n",
    "# args.euler_characteristic_penalty = True\n",
    "# args.conn_lambda_start = 0.001\n",
    "# args.conn_lambda_end = 3\n",
    "# args.conn_lambda_epochs_start = 4001\n",
    "# args.conn_lambda_epochs_end = 12000\n",
    "# args.valency_lambda_start = 0.001\n",
    "# args.valency_lambda_end = 5\n",
    "# args.valency_lambda_epochs_start = 4001\n",
    "# args.valency_lambda_epochs_end = 12000\n",
    "# args.euler_lambda_start = 0.001 \n",
    "# args.euler_lambda_end = 2 \n",
    "# args.euler_lambda_epochs_start = 4001\n",
    "# args.euler_lambda_epochs_end = 12000\n",
    "# args.tau_start = 1\n",
    "# args.tau_end = 0.01\n",
    "# args.tau_epochs_start = 1\n",
    "# args.tau_epochs_end = 12000\n",
    "\n",
    "# args.morgan_bits = 1024\n",
    "\n",
    "# args.conn_penalty_function = \"capped_logdet\" \n",
    "\n",
    "# print(args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train_pairs\", args.batch_size, same_number_atoms = True)\n",
    "# train_data_loader = get_loader(\"molgen/data/chembl50\", \"train\", args.batch_size, same_number_atoms = True)\n",
    "# val_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"valid\", 36, False)\n",
    "\n",
    "train_data_loader = get_loader(\"molgen/data/chembl50\", \"train_split\", args.batch_size, same_number_atoms = True)\n",
    "val_data_loader = get_loader(\"molgen/data/chembl50\", \"val_split\", args.batch_size, same_number_atoms = True)\n",
    "# val_data_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found previous model mol_opt/output_dev3/deepsets-chembl1/model_deepsets-chembl1_20, epoch 20. Overwriting args.\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=20 mode=[0 0 0] conn=True val=True euler=True\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:398: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses Batch 0, train\n",
      " fgw:1.1903840\n",
      " conn_penalty:0.7469680\n",
      " val_penalty:0.5352757\n",
      " euler_penalty:3.7419802\n",
      " total:13.5916270\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 30, train\n",
      " fgw:1.1870097\n",
      " conn_penalty:1.3145099\n",
      " val_penalty:0.4423656\n",
      " euler_penalty:3.6304339\n",
      " total:14.6032352\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 60, train\n",
      " fgw:1.1444648\n",
      " conn_penalty:1.1738984\n",
      " val_penalty:0.3440101\n",
      " euler_penalty:3.3563245\n",
      " total:13.0988594\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 90, train\n",
      " fgw:1.1147998\n",
      " conn_penalty:1.0513408\n",
      " val_penalty:0.2746484\n",
      " euler_penalty:2.9775109\n",
      " total:11.5970863\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 120, train\n",
      " fgw:1.0945075\n",
      " conn_penalty:0.9597093\n",
      " val_penalty:0.2343661\n",
      " euler_penalty:2.7502143\n",
      " total:10.6458944\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 150, train\n",
      " fgw:1.0823177\n",
      " conn_penalty:0.8940236\n",
      " val_penalty:0.2132032\n",
      " euler_penalty:2.6231132\n",
      " total:10.0766308\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 180, train\n",
      " fgw:1.0777652\n",
      " conn_penalty:0.8443762\n",
      " val_penalty:0.1934038\n",
      " euler_penalty:2.5031529\n",
      " total:9.5842187\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 210, train\n",
      " fgw:1.0707997\n",
      " conn_penalty:0.7991298\n",
      " val_penalty:0.1794848\n",
      " euler_penalty:2.4117109\n",
      " total:9.1890348\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 240, train\n",
      " fgw:1.0627306\n",
      " conn_penalty:0.7620641\n",
      " val_penalty:0.1691276\n",
      " euler_penalty:2.3373354\n",
      " total:8.8692315\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 270, train\n",
      " fgw:1.0544012\n",
      " conn_penalty:0.7305804\n",
      " val_penalty:0.1611876\n",
      " euler_penalty:2.2692074\n",
      " total:8.5904950\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 300, train\n",
      " fgw:1.0475043\n",
      " conn_penalty:0.7022978\n",
      " val_penalty:0.1555982\n",
      " euler_penalty:2.2174682\n",
      " total:8.3673253\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 330, train\n",
      " fgw:1.0405990\n",
      " conn_penalty:0.6848230\n",
      " val_penalty:0.1507016\n",
      " euler_penalty:2.1651822\n",
      " total:8.1789406\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 360, train\n",
      " fgw:1.0346568\n",
      " conn_penalty:0.6619965\n",
      " val_penalty:0.1453116\n",
      " euler_penalty:2.1156704\n",
      " total:7.9785450\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 390, train\n",
      " fgw:1.0304597\n",
      " conn_penalty:0.6413354\n",
      " val_penalty:0.1402311\n",
      " euler_penalty:2.0653459\n",
      " total:7.7863130\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 420, train\n",
      " fgw:1.0256818\n",
      " conn_penalty:0.6230984\n",
      " val_penalty:0.1367305\n",
      " euler_penalty:2.0257846\n",
      " total:7.6301987\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 450, train\n",
      " fgw:1.0211149\n",
      " conn_penalty:0.6085169\n",
      " val_penalty:0.1342706\n",
      " euler_penalty:1.9923092\n",
      " total:7.5026368\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 480, train\n",
      " fgw:1.0181695\n",
      " conn_penalty:0.5992210\n",
      " val_penalty:0.1320646\n",
      " euler_penalty:1.9676510\n",
      " total:7.4114574\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 510, train\n",
      " fgw:1.0138451\n",
      " conn_penalty:0.5927827\n",
      " val_penalty:0.1301715\n",
      " euler_penalty:1.9511312\n",
      " total:7.3453131\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 540, train\n",
      " fgw:1.0100765\n",
      " conn_penalty:0.5871921\n",
      " val_penalty:0.1321363\n",
      " euler_penalty:1.9657849\n",
      " total:7.3639043\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 570, train\n",
      " fgw:1.0077130\n",
      " conn_penalty:0.5863550\n",
      " val_penalty:0.1305093\n",
      " euler_penalty:1.9612014\n",
      " total:7.3417273\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 600, train\n",
      " fgw:1.0134522\n",
      " conn_penalty:0.6333838\n",
      " val_penalty:0.1689088\n",
      " euler_penalty:2.1368512\n",
      " total:8.0318499\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 630, train\n",
      " fgw:1.0187289\n",
      " conn_penalty:0.6978613\n",
      " val_penalty:0.2143872\n",
      " euler_penalty:2.3275582\n",
      " total:8.8393650\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 660, train\n",
      " fgw:1.0217159\n",
      " conn_penalty:0.7141282\n",
      " val_penalty:0.2183911\n",
      " euler_penalty:2.3751173\n",
      " total:9.0062907\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=21 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Epoch 21, train\n",
      " fgw:1.0242713\n",
      " conn_penalty:0.7070801\n",
      " val_penalty:0.2137698\n",
      " euler_penalty:2.3420342\n",
      " total:8.8984292\n",
      "Losses Batch 0, val\n",
      " fgw:1.1277803\n",
      " conn_penalty:0.6216183\n",
      " val_penalty:0.4804112\n",
      " euler_penalty:2.9742141\n",
      " total:11.3431191\n",
      "Losses Batch 30, val\n",
      " fgw:1.0247276\n",
      " conn_penalty:0.5892004\n",
      " val_penalty:0.1296238\n",
      " euler_penalty:1.7481752\n",
      " total:6.9367982\n",
      "Losses Batch 60, val\n",
      " fgw:1.0198617\n",
      " conn_penalty:0.6001512\n",
      " val_penalty:0.1170267\n",
      " euler_penalty:1.6426115\n",
      " total:6.6906717\n",
      "Losses Epoch 21, val\n",
      " fgw:1.0238216\n",
      " conn_penalty:0.6345592\n",
      " val_penalty:0.2187090\n",
      " euler_penalty:2.1596964\n",
      " total:8.3404372\n",
      "Epoch duration: 19148.80526161194\n",
      "Saving model, do not interrupt...\n",
      "Saved at mol_opt/output_dev3/deepsets-chembl1/model_deepsets-chembl1_21\n",
      "Epoch: 22\n",
      "Losses Batch 0, train\n",
      " fgw:1.1555731\n",
      " conn_penalty:0.8004548\n",
      " val_penalty:0.4995034\n",
      " euler_penalty:2.9345024\n",
      " total:11.9234590\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 30, train\n",
      " fgw:1.1221778\n",
      " conn_penalty:1.0775685\n",
      " val_penalty:0.4040370\n",
      " euler_penalty:3.0629064\n",
      " total:12.5008814\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 60, train\n",
      " fgw:1.0919459\n",
      " conn_penalty:0.8473266\n",
      " val_penalty:0.3004578\n",
      " euler_penalty:2.6287557\n",
      " total:10.3937259\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 90, train\n",
      " fgw:1.0630075\n",
      " conn_penalty:0.7289350\n",
      " val_penalty:0.2382663\n",
      " euler_penalty:2.2370661\n",
      " total:8.9152760\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 120, train\n",
      " fgw:1.0519992\n",
      " conn_penalty:0.6418197\n",
      " val_penalty:0.2013846\n",
      " euler_penalty:1.9915534\n",
      " total:7.9674882\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 150, train\n",
      " fgw:1.0413279\n",
      " conn_penalty:0.6080644\n",
      " val_penalty:0.1870668\n",
      " euler_penalty:2.0277347\n",
      " total:7.8563247\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses Batch 180, train\n",
      " fgw:1.0309995\n",
      " conn_penalty:0.5760163\n",
      " val_penalty:0.1679201\n",
      " euler_penalty:1.9240298\n",
      " total:7.4467086\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 210, train\n",
      " fgw:1.0208259\n",
      " conn_penalty:0.5518266\n",
      " val_penalty:0.1534692\n",
      " euler_penalty:1.8285105\n",
      " total:7.1006727\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 240, train\n",
      " fgw:1.0135193\n",
      " conn_penalty:0.5279674\n",
      " val_penalty:0.1437293\n",
      " euler_penalty:1.7604831\n",
      " total:6.8370341\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 270, train\n",
      " fgw:1.0075917\n",
      " conn_penalty:0.4982947\n",
      " val_penalty:0.1370229\n",
      " euler_penalty:1.6854112\n",
      " total:6.5584129\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 300, train\n",
      " fgw:1.0080645\n",
      " conn_penalty:0.4771225\n",
      " val_penalty:0.1360515\n",
      " euler_penalty:1.6890268\n",
      " total:6.4977429\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 330, train\n",
      " fgw:1.0046979\n",
      " conn_penalty:0.4768615\n",
      " val_penalty:0.1329730\n",
      " euler_penalty:1.6729043\n",
      " total:6.4459560\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 360, train\n",
      " fgw:1.0002409\n",
      " conn_penalty:0.4647546\n",
      " val_penalty:0.1273632\n",
      " euler_penalty:1.6490834\n",
      " total:6.3294877\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 390, train\n",
      " fgw:0.9963771\n",
      " conn_penalty:0.4529226\n",
      " val_penalty:0.1222147\n",
      " euler_penalty:1.6084410\n",
      " total:6.1831006\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 420, train\n",
      " fgw:0.9922567\n",
      " conn_penalty:0.4388509\n",
      " val_penalty:0.1192602\n",
      " euler_penalty:1.5690532\n",
      " total:6.0432171\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 450, train\n",
      " fgw:0.9870248\n",
      " conn_penalty:0.4292842\n",
      " val_penalty:0.1172095\n",
      " euler_penalty:1.5565743\n",
      " total:5.9740736\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 480, train\n",
      " fgw:0.9829130\n",
      " conn_penalty:0.4176445\n",
      " val_penalty:0.1151424\n",
      " euler_penalty:1.5204076\n",
      " total:5.8523739\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 510, train\n",
      " fgw:0.9802916\n",
      " conn_penalty:0.4146181\n",
      " val_penalty:0.1153245\n",
      " euler_penalty:1.5376558\n",
      " total:5.8760800\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 540, train\n",
      " fgw:0.9779200\n",
      " conn_penalty:0.4170216\n",
      " val_penalty:0.1146467\n",
      " euler_penalty:1.5427509\n",
      " total:5.8877201\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 570, train\n",
      " fgw:0.9755049\n",
      " conn_penalty:0.4129216\n",
      " val_penalty:0.1128514\n",
      " euler_penalty:1.5270568\n",
      " total:5.8326403\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 600, train\n",
      " fgw:0.9953022\n",
      " conn_penalty:0.5760433\n",
      " val_penalty:0.2448408\n",
      " euler_penalty:1.9013651\n",
      " total:7.7503660\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 630, train\n",
      " fgw:1.0396638\n",
      " conn_penalty:0.7919156\n",
      " val_penalty:0.3249139\n",
      " euler_penalty:2.2558233\n",
      " total:9.5516268\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 660, train\n",
      " fgw:1.0595873\n",
      " conn_penalty:0.8809210\n",
      " val_penalty:0.3367338\n",
      " euler_penalty:2.4569928\n",
      " total:10.3000049\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=22 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Epoch 22, train\n",
      " fgw:1.0763863\n",
      " conn_penalty:0.8975024\n",
      " val_penalty:0.3310947\n",
      " euler_penalty:2.4832286\n",
      " total:10.3908239\n",
      "Losses Batch 0, val\n",
      " fgw:1.4831027\n",
      " conn_penalty:1.1338450\n",
      " val_penalty:0.5183525\n",
      " euler_penalty:4.6886226\n",
      " total:16.8536445\n",
      "Losses Batch 30, val\n",
      " fgw:1.4147813\n",
      " conn_penalty:1.1326718\n",
      " val_penalty:0.1966893\n",
      " euler_penalty:4.1526545\n",
      " total:14.1015519\n",
      "Losses Batch 60, val\n",
      " fgw:1.4119012\n",
      " conn_penalty:1.1142309\n",
      " val_penalty:0.1993719\n",
      " euler_penalty:4.0751765\n",
      " total:13.9018063\n",
      "Losses Epoch 22, val\n",
      " fgw:1.4104720\n",
      " conn_penalty:1.1500250\n",
      " val_penalty:0.3770168\n",
      " euler_penalty:4.7761920\n",
      " total:16.2980149\n",
      "Epoch duration: 18815.189496040344\n",
      "Saving model, do not interrupt...\n",
      "Saved at mol_opt/output_dev3/deepsets-chembl1/model_deepsets-chembl1_22\n",
      "Epoch: 23\n",
      "Losses Batch 0, train\n",
      " fgw:1.4937487\n",
      " conn_penalty:0.9502023\n",
      " val_penalty:0.7193015\n",
      " euler_penalty:4.8906787\n",
      " total:17.7222207\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=23 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 30, train\n",
      " fgw:1.4823054\n",
      " conn_penalty:1.8314812\n",
      " val_penalty:0.5796066\n",
      " euler_penalty:4.8329112\n",
      " total:19.5406045\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=23 mode=[0 0 0] conn=True val=True euler=True\n",
      "Losses Batch 60, train\n",
      " fgw:1.4630914\n",
      " conn_penalty:1.6814752\n",
      " val_penalty:0.4587663\n",
      " euler_penalty:4.7324849\n",
      " total:18.2663185\n",
      "Penalty params: tau=0.01000 conn_l=3.00000 val_l=5.00000 euler_l=2.00000 epoch=23 mode=[0 0 0] conn=True val=True euler=True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-837c2f4f84a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# run the training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         run_func(molopt, molopt_decoder, optimizer, scheduler, train_data_loader, \"train\", \n\u001b[0;32m--> 115\u001b[0;31m                 args, pen_loss, recpen_loss, crossatt, epoch)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# compute the validation loss as well, at the end of the epoch?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mrun_func\u001b[0;34m(mol_opt, mol_opt_decoder, optim, scheduler, data_loader, data_type, args, pen_loss, recpen_loss, crossatt, epoch_idx)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgw_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_plans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_mats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgw_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;31m# compute the lambdas and losses, based on this fgw loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mcon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meul_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpen_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/ot_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prediction, target_batch, tau, ot_plans)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mot_plan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot_plans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmol_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mot_plans\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0matom_gw_dist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbond_gw_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mfused_gw_torch\u001b[0;34m(M, C1, C2, p1, p2, dist_type, alpha, nce_reg, ot_plan, device)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         ot_mat = np_fused_gw(M=M_detach, C1 = C1_detach, C2 = C2_detach,\n\u001b[0;32m--> 362\u001b[0;31m                             p1 = p1, p2 = p2, dist_type=dist_type, alpha=alpha)\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mot_mat_attached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mnp_fused_gw\u001b[0;34m(M, C1, C2, p1, p2, dist_type, alpha)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mG0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mot_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0msanity_check_ot_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mot_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mmy_cg\u001b[0;34m(a, b, M, reg, f, df, G0, numItermax, stopThr, stopThr2, verbose, log, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# problem linearization (gradient of the cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mMi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mold_Mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mdf\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp_gwggrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mG0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mnp_gwggrad\u001b[0;34m(C1, C2, ot_mat)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m#############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnp_gwggrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mtens\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp_tensor_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mtens_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_tensor_product_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtens_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mnp_tensor_product\u001b[0;34m(C1, C2, ot_mat)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m\\\u001b[0m\u001b[0msum_\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mC1_\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mik\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2_\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mjl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mT_\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_ikd_kl_to_ild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_mat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# C1_ijk, T_jl-> X_ilk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_ild_jld_to_ij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# X_ilk, C2_jlk-> A_ij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mnp_ikd_kl_to_ild\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "molopt, molopt_decoder = main(args, train_data_loader = train_data_loader, val_data_loader = val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "molopt, molopt_decoder = main(args, train_data_loader = train_data_loader, val_data_loader = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in train_data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break\n",
    "    \n",
    "x_embedding = molopt.forward(X)\n",
    "yhat_logits = molopt_decoder.forward(x_embedding, X, Y)\n",
    "yhat_labels = molopt_decoder.discretize_argmax(*yhat_logits)\n",
    "# yhat_labels = molopt_decoder.discretize(*yhat_logits)\n",
    "pred_pack = (yhat_labels, yhat_logits, Y.scope), Y \n",
    "\n",
    "target = Y.get_graph_outputs()\n",
    "symbols_labels, charges_labels, bonds_labels = yhat_labels\n",
    "symbols_logits, charges_logits, bonds_logits = yhat_logits\n",
    "\n",
    "from mol_opt.ot_utils import FGW \n",
    "fgw_loss = FGW(alpha = 0.5)\n",
    "fgw_loss(*pred_pack, tau = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.optim.Adam([torch.autograd.Variable(torch.Tensor([0.]))]).param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9 ** (1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(\"/home/octav/gitrepos/tum-thesis/mol_opt/dev7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    \"pointwise10-dev8/train_avg_euler_error/mean\",\n",
    "    \"pointwise10-dev8/train_avg_euler_error/bot_band\",\n",
    "    \"pointwise10-dev8/train_avg_euler_error/top_band\"\n",
    "]\n",
    "# writer.add_custom_scalars_marginchart(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_scalar(\"plm2/plm2\", 0, 1)\n",
    "# writer.add_scalar(\"plm2/plm2\", 1, 2)\n",
    "# writer.add_scalar(\"plm2/plm2\", 0, 3)\n",
    "# writer.add_scalar(\"plm2/plm2\", 1, 4)\n",
    "tags = [\"plm\", \"plm\", \"plm\"]\n",
    "# layout = {\"plm\" : {\"plm\" : [\"Margin\", tags]}}\n",
    "layout = {\"plm1\" : {\"plm\" : [\"Margin\", tags], \"plm2\": [\"Multiline\", tags]},\n",
    "          \"plm2\": {\"plm\" : [\"Margin\", tags], \"plm2\": [\"Multiline\", tags]}}\n",
    "writer.add_custom_scalars(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer._get_file_writer().add_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX\n",
    "tensorboardX.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX.summary import custom_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer._get_file_writer().add_summary(custom_scalars(layout), global_step = 3)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars('plm', {'plm0' : 0.0, 'plmt' : 0.1, 'plmb' : -0.1}, 3)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "symbols_nll, charges_nll, bonds_nll = F.gumbel_softmax(tau = tau, dim=1, logits = symbols_logits), F.gumbel_softmax(tau=tau,dim=1,logits=charges_logits), F.gumbel_softmax(tau=tau,dim=1, logits = bonds_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(symbols_nll.mean(axis = 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "molopt.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load('mol_opt/output_pointwise10-onebatch/model_pointwise10-onebatch_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"model\"]['opt0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt2 = MolOpt(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt2.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt2.load_state_dict(model_dict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt2.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt3,args3 = load_model('mol_opt/output_pointwise10-onebatch/model_pointwise10-onebatch_8', MolOpt, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt3.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgw_loss(*pred_pack, tau = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
