{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/octavdragoi/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"molgen\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"iclr19-graph2graph/props\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN\n",
    "# from molgen.dataloading.MolGraphBatchPreprocessor import MolGraph\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "from otgnn.graph import SYMBOLS, FORMAL_CHARGES, BOND_TYPES\n",
    "\n",
    "\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, load_checkpoint, initialize_models\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.decoder_mol_opt import MolOptDecoder\n",
    "from mol_opt.ot_utils import encode_target\n",
    "from mol_opt.ot_utils import FGW \n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "\n",
    "from molgen.dataloading.feat2smiles import feat2smiles\n",
    "from molgen.dataloading.mol_drawer import MolDrawer\n",
    "from molgen.metrics.Penalty import Penalty, RecPenalty\n",
    "from molgen.metrics.mol_metrics import MolMetrics\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import time\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from molgen.metrics.Penalty import Penalty as PenaltyNew\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"molemb\"\n",
    "sys.argv = [\"\", \"-model_type\", model_type, \"-one_batch_train\"]\n",
    "args = get_args()\n",
    "args.n_epochs = 100 \n",
    "args.init_model = \"{}-chembl1\".format(model_type)\n",
    "args.output_dir = \"/Users/octavdragoi/Dropbox/tum-thesis/{}/\".format(args.init_model)\n",
    "args.tb_logs_dir = \"/Users/octavdragoi/Dropbox/tum-thesis/logs_dev3/{}\".format(args.init_model)\n",
    "args.batch_size = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/octavdragoi/Dropbox/tum-thesis/molemb-chembl1/model_molemb-chembl1_16\n",
      "MolOpt(\n",
      "  (GCN): GCN(\n",
      "    (W_message_i): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (W_message_h): Linear(in_features=200, out_features=200, bias=False)\n",
      "    (W_message_o): Linear(in_features=293, out_features=150, bias=True)\n",
      "    (W_mol_h): Linear(in_features=150, out_features=100, bias=True)\n",
      "    (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
      "    (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
      "    (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (opt0): Linear(in_features=150, out_features=14000, bias=True)\n",
      "  (opt1): Linear(in_features=14000, out_features=10500, bias=True)\n",
      ")\n",
      "MolOptDecoder(\n",
      "  (fc1_SYMBOLS): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (fc2_SYMBOLS): Linear(in_features=150, out_features=64, bias=True)\n",
      "  (fc1_CHARGES): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (fc2_CHARGES): Linear(in_features=150, out_features=5, bias=True)\n",
      "  (fc1_BONDS): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (fc2_BONDS): Linear(in_features=300, out_features=5, bias=True)\n",
      ")\n",
      "molemb\n",
      "Penalty params: tau=0.02069 conn_l=0.62835 val_l=0.86468 euler_l=0.48769 epoch=16 mode=[1 1 1] conn=True euler=True val=True\n"
     ]
    }
   ],
   "source": [
    "model = args.init_model\n",
    "model_iter = 16 \n",
    "\n",
    "model_name = \"model_{}_{}\".format(model, model_iter)\n",
    "print(args.output_dir + model_name)\n",
    "\n",
    "molopt, molopt_decoder, _, pen, _, config, _ = load_checkpoint(args.output_dir + model_name ,init_fc = initialize_models, cpu = True)\n",
    "\n",
    "metrics = MolMetrics(SYMBOLS, FORMAL_CHARGES, BOND_TYPES, False, device = 'cpu')\n",
    "fgw_loss = FGW(alpha = 0.5)\n",
    "# pen = PenaltyNew(config, model_iter)\n",
    "\n",
    "molopt_module_list = torch.nn.ModuleList([molopt, molopt_decoder])\n",
    "\n",
    "# molopt = MolOpt(args)\n",
    "# molopt_decoder = MolOptDecoder(args)\n",
    "print (molopt)\n",
    "print (molopt_decoder)\n",
    "print(molopt.args.model_type)\n",
    "pen.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recpen = RecPenalty(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train_pairs\", args.batch_size, True)\n",
    "datatype = \"val_split\"\n",
    "train_data_loader = get_loader(\"molgen/data/chembl50\", datatype, 50, same_number_atoms = True)\n",
    "\n",
    "for i in train_data_loader:\n",
    "#     X = (MolGraph(i[0]))\n",
    "#     Y = (MolGraph(i[1]))\n",
    "    X = MolGraph(i)\n",
    "    Y = X\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/octavdragoi/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:394: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGW torch.Size([23439, 5]) 0.000147338054375723\n",
      "0.3594107818603516\n",
      "(tensor(8.0064, grad_fn=<DivBackward0>), tensor(3.3244, grad_fn=<DivBackward0>), tensor(0.8394, grad_fn=<DivBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_molecular_validity': 96.0,\n",
       "  'batch_correctness': 0.0,\n",
       "  'batch_symbol_accuracy': 98.01390268123139,\n",
       "  'batch_molecular_disconnected_validity': 96.0,\n",
       "  'batch_connected_components': 1.02,\n",
       "  'batch_invalid_valency_nodes': 0.29791459781529295,\n",
       "  'batch_nodes_0degree': 1,\n",
       "  'batch_nodes_7plus_degree': 0,\n",
       "  'invalid_euler_toofew': 0.0,\n",
       "  'invalid_euler_toomany': 0.0},\n",
       " {'avg_euler_error': (-0.36, 50, 0.43040000000000006),\n",
       "  'batch_node_degree': (1.9821251241310822, 1007, 0.724606010163217)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding = molopt.forward(X)\n",
    "yhat_logits = molopt_decoder.forward(x_embedding, X, Y)\n",
    "yhat_labels = molopt_decoder.discretize_argmax(*yhat_logits)\n",
    "# yhat_labels = molopt_decoder.discretize_gumbel(*yhat_logits, tau = pen.tau)\n",
    "pred_pack = (yhat_labels, yhat_logits, Y.scope), Y \n",
    "\n",
    "target = Y.get_graph_outputs()\n",
    "symbols_labels, charges_labels, bonds_labels = yhat_labels\n",
    "symbols_logits, charges_logits, bonds_logits = yhat_logits\n",
    "\n",
    "pen.mirror = \"\"\n",
    "\n",
    "pen.tau = 0.05\n",
    "fgw_loss_item = fgw_loss(*pred_pack, tau = 1)\n",
    "print (fgw_loss_item.item()/args.batch_size)\n",
    "pen_loss = pen(*pred_pack, model_iter)\n",
    "print (pen_loss)\n",
    "metrics.measure_batch(pred_pack[0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 70, 150])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_embedding = molopt.encode(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_embedding = recpen(mol_embedding).view(args.batch_size, args.max_num_atoms, args.pc_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 70, 150])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 70, 150])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (st, le) in enumerate(X.scope):\n",
    "    recpen.loss(x_embedding[idx,:le], xhat_embedding[idx,:le])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(115.6115, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recpen.calculate_loss(x_embedding, xhat_embedding, X.scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0519,  0.0592,  0.0685,  ..., -0.0065, -0.0630,  0.0449],\n",
      "        [-0.0725, -0.0410,  0.0373,  ...,  0.0696,  0.0031,  0.0048],\n",
      "        [-0.0535, -0.0358,  0.0290,  ..., -0.0292,  0.0568,  0.0433],\n",
      "        ...,\n",
      "        [ 0.0791, -0.0786, -0.0793,  ...,  0.0662,  0.0619, -0.0784],\n",
      "        [-0.0589,  0.0470, -0.0022,  ..., -0.0074, -0.0285,  0.0492],\n",
      "        [ 0.0277,  0.0193, -0.0569,  ...,  0.0493,  0.0252,  0.0788]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0540, -0.0172, -0.0362,  ..., -0.0435,  0.0807,  0.0447],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-6.6515e-03,  5.0721e-04, -6.8333e-03,  ..., -3.6763e-03,\n",
      "         -4.0087e-03,  7.3221e-04],\n",
      "        [-2.5205e-03,  6.7956e-03, -3.7455e-03,  ..., -4.2382e-03,\n",
      "         -3.7348e-03, -5.6535e-03],\n",
      "        [-5.5820e-03,  6.1213e-03, -5.0610e-03,  ...,  1.9947e-03,\n",
      "         -5.6051e-04,  5.6556e-03],\n",
      "        ...,\n",
      "        [-6.5154e-03, -4.6620e-03,  3.7811e-03,  ..., -5.6445e-03,\n",
      "         -5.0327e-04,  3.9808e-03],\n",
      "        [-2.1571e-03,  4.3418e-03, -9.3508e-05,  ...,  6.4421e-03,\n",
      "         -2.8188e-03,  9.3386e-04],\n",
      "        [-3.7060e-03, -2.1740e-03,  6.1241e-03,  ...,  6.4880e-03,\n",
      "          6.0162e-03, -2.7917e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0080,  0.0081,  0.0036,  ...,  0.0061, -0.0017, -0.0025],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in recpen.parameters():\n",
    "    print (x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tum-thesis': conda)",
   "language": "python",
   "name": "python37764bittumthesisconda7e6696dd8c0f4792824001247d7af840"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
