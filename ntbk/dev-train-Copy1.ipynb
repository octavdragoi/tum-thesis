{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, get_latest_model\n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(N_transformer=6, agg_func='sum', batch_norm=False, batch_size=50, conn_lambda_end=25, conn_lambda_epochs_end=8000, conn_lambda_epochs_start=4001, conn_lambda_start=0.001, conn_penalty_function='capped_logdet', connectivity=False, connectivity_hard=False, cuda=True, device='cuda:0', dim_tangent_space=40, dropout_ffn=0.0, dropout_gcn=0.0, dropout_transformer=0.1, euler_characteristic_penalty=False, euler_lambda_end=100, euler_lambda_epochs_end=50, euler_lambda_epochs_start=1, euler_lambda_start=1, ffn_activation='LeakyReLU', init_decoder_model='ffn-base-nopen-gumbel1_decode', init_model='ffn-base-nopen-gumbel1', linear_out=False, model_type='ffn', n_epochs=4000, n_ffn_hidden=100, n_ffn_transformer=100, n_heads_transformer=10, n_hidden=300, n_labels=1, n_layers=5, one_batch_train=True, ot_solver='emd', output_dir='mol_opt/output_dev2/ffn-base-nopen-gumbel1', pc_hidden=100, penalty_gumbel=True, pred_hidden=150, scale_lambdas=True, sinkhorn_entropy=0.1, sinkhorn_max_it=10000, task='qed', tau_end=0.01, tau_epochs_end=10000, tau_epochs_start=1, tau_start=1, tb_logs_dir='mol_opt/logs_dev2/ffn-base-nopen-gumbel1', valency=False, valency_hard=False, valency_lambda_end=100, valency_lambda_epochs_end=14000, valency_lambda_epochs_start=8000, valency_lambda_start=0.001) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = \"ffn\"\n",
    "sys.argv = [\"\", \"-cuda\", \"-model_type\", model_type, \"-one_batch_train\"]\n",
    "args = get_args()\n",
    "outdir_suffix = \"dev2\"\n",
    "args.n_epochs = 4000 \n",
    "args.init_model = \"{}-base-nopen-gumbel1\".format(model_type)\n",
    "args.init_decoder_model = \"{}_decode\".format(args.init_model)\n",
    "args.output_dir = \"mol_opt/output_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "args.tb_logs_dir = \"mol_opt/logs_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "args.batch_size = 50 \n",
    "\n",
    "args.penalty_gumbel = True \n",
    "\n",
    "args.scale_lambdas = True\n",
    "args.connectivity = False \n",
    "args.valency = False \n",
    "args.euler_characteristic_penalty = False\n",
    "\n",
    "args.conn_lambda_start = 0.001\n",
    "args.conn_lambda_end = 25\n",
    "args.conn_lambda_epochs_start = 4001\n",
    "args.conn_lambda_epochs_end = 8000\n",
    "args.valency_lambda_start = 0.001\n",
    "args.valency_lambda_end = 100\n",
    "args.valency_lambda_epochs_start = 8000\n",
    "args.valency_lambda_epochs_end = 14000\n",
    "args.euler_characteristic_penalty = False\n",
    "args.tau_start = 1\n",
    "args.tau_end = 0.01\n",
    "args.tau_epochs_start = 1\n",
    "args.tau_epochs_end = 10000\n",
    "\n",
    "\n",
    "args.conn_penalty_function = \"capped_logdet\" \n",
    "\n",
    "print(args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train_pairs\", args.batch_size, same_number_atoms = True)\n",
    "train_data_loader = get_loader(\"molgen/data/chembl50\", \"train\", args.batch_size, same_number_atoms = True)\n",
    "# val_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"valid\", 36, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found previous model mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1113, epoch 1113. Overwriting args.\n",
      "Epoch: 1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:394: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGW torch.Size([29508, 5]) 7.678664405830204e-05\n",
      "Penalty params: tau=0.59866 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1114 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1114, train\n",
      " fgw:0.2151746\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2151746\n",
      "Measure Epoch 1114, train\n",
      " similarity:0.0274192\n",
      " penlog:-92.2122034\n",
      "Metrics Epoch 1114, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.7200000\n",
      " batch_invalid_valency_nodes:30.4347826\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.6200000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:4.0400000\n",
      " batch_node_degree:3.1095652\n",
      "Logits [20.261760711669922, 2.3889834880828857, 68.16580963134766]\n",
      "Epoch duration: 3.1865692138671875\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1114\n",
      "Epoch: 1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:394: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGW torch.Size([29508, 5]) 6.966375804040581e-05\n",
      "Penalty params: tau=0.59838 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1115 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1115, train\n",
      " fgw:0.2152536\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2152536\n",
      "Measure Epoch 1115, train\n",
      " similarity:0.0282638\n",
      " penlog:-90.1507009\n",
      "Metrics Epoch 1115, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8400000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:1.7800000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.2900000\n",
      " batch_node_degree:2.4713043\n",
      "Logits [20.291175842285156, 2.3867151737213135, 68.3794174194336]\n",
      "Epoch duration: 2.410834312438965\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1115\n",
      "Epoch: 1116\n",
      "FGW torch.Size([29508, 5]) 7.647037273272872e-05\n",
      "Penalty params: tau=0.59811 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1116 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1116, train\n",
      " fgw:0.2185508\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2185508\n",
      "Measure Epoch 1116, train\n",
      " similarity:0.0209677\n",
      " penlog:-96.1374683\n",
      "Metrics Epoch 1116, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.4800000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:4.0300000\n",
      " batch_node_degree:2.9565217\n",
      "Logits [20.263858795166016, 2.38030743598938, 68.41836547851562]\n",
      "Epoch duration: 2.3099732398986816\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1116\n",
      "Epoch: 1117\n",
      "FGW torch.Size([29508, 5]) 7.398545858450234e-05\n",
      "Penalty params: tau=0.59783 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1117 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1117, train\n",
      " fgw:0.2262075\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2262075\n",
      "Measure Epoch 1117, train\n",
      " similarity:0.0241176\n",
      " penlog:-96.0677295\n",
      "Metrics Epoch 1117, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1000000\n",
      " batch_invalid_valency_nodes:27.2173913\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.2000000\n",
      " batch_node_degree:2.8304348\n",
      "Logits [20.325071334838867, 2.402083158493042, 68.4062271118164]\n",
      "Epoch duration: 2.4754931926727295\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1117\n",
      "Epoch: 1118\n",
      "FGW torch.Size([29508, 5]) 7.427651871694252e-05\n",
      "Penalty params: tau=0.59755 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1118 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1118, train\n",
      " fgw:0.2164040\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2164040\n",
      "Measure Epoch 1118, train\n",
      " similarity:0.0225532\n",
      " penlog:-96.0198006\n",
      "Metrics Epoch 1118, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:28.4347826\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.7500000\n",
      " batch_node_degree:2.9286957\n",
      "Logits [20.308446884155273, 2.3904387950897217, 68.2839584350586]\n",
      "Epoch duration: 2.5860822200775146\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1118\n",
      "Epoch: 1119\n",
      "FGW torch.Size([29508, 5]) 7.489329436793923e-05\n",
      "Penalty params: tau=0.59728 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1119 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1119, train\n",
      " fgw:0.2193417\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2193417\n",
      "Measure Epoch 1119, train\n",
      " similarity:0.0068415\n",
      " penlog:-93.9880386\n",
      "Metrics Epoch 1119, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:25.3043478\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.3800000\n",
      " batch_node_degree:2.7478261\n",
      "Logits [20.20992088317871, 2.3839380741119385, 68.26313781738281]\n",
      "Epoch duration: 2.2714974880218506\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1119\n",
      "Epoch: 1120\n",
      "FGW torch.Size([29508, 5]) 7.196982187451795e-05\n",
      "Penalty params: tau=0.59700 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1120 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1120, train\n",
      " fgw:0.2202447\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2202447\n",
      "Measure Epoch 1120, train\n",
      " similarity:0.0256092\n",
      " penlog:-92.0791958\n",
      "Metrics Epoch 1120, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.9200000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:1.9000000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:44.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.6100000\n",
      " batch_node_degree:2.5382609\n",
      "Logits [19.998029708862305, 2.352051258087158, 67.76908874511719]\n",
      "Epoch duration: 2.489884376525879\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1120\n",
      "Epoch: 1121\n",
      "FGW torch.Size([29508, 5]) 7.813354022800922e-05\n",
      "Penalty params: tau=0.59673 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1121 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1121, train\n",
      " fgw:0.2142523\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2142523\n",
      "Measure Epoch 1121, train\n",
      " similarity:0.0043478\n",
      " penlog:-98.0169192\n",
      "Metrics Epoch 1121, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.3400000\n",
      " batch_invalid_valency_nodes:31.6521739\n",
      " batch_nodes_0degree:0.8400000\n",
      " batch_nodes_7plus_degree:1.7000000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:40.0000000\n",
      " avg_euler_error:5.0400000\n",
      " batch_node_degree:3.2408696\n",
      "Logits [19.797256469726562, 2.3301074504852295, 67.57352447509766]\n",
      "Epoch duration: 2.311368942260742\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1121\n",
      "Epoch: 1122\n",
      "FGW torch.Size([29508, 5]) 6.818737892899662e-05\n",
      "Penalty params: tau=0.59645 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1122 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1122, train\n",
      " fgw:0.2191649\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2191649\n",
      "Measure Epoch 1122, train\n",
      " similarity:0.0338219\n",
      " penlog:-88.2084970\n",
      "Metrics Epoch 1122, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:4.4000000\n",
      " batch_invalid_valency_nodes:22.3478261\n",
      " batch_nodes_0degree:2.1600000\n",
      " batch_nodes_7plus_degree:0.5600000\n",
      " invalid_euler_toofew:54.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-1.6000000\n",
      " batch_node_degree:2.3243478\n",
      "Logits [19.784236907958984, 2.3299272060394287, 67.2343978881836]\n",
      "Epoch duration: 2.3814404010772705\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1122\n",
      "Epoch: 1123\n",
      "FGW torch.Size([29508, 5]) 7.538751378888264e-05\n",
      "Penalty params: tau=0.59618 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1123 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1123, train\n",
      " fgw:0.2206805\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2206805\n",
      "Measure Epoch 1123, train\n",
      " similarity:0.0238298\n",
      " penlog:-96.1485418\n",
      "Metrics Epoch 1123, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6200000\n",
      " batch_invalid_valency_nodes:26.3478261\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:4.1800000\n",
      " batch_node_degree:2.9339130\n",
      "Logits [19.663904190063477, 2.2999656200408936, 66.4857406616211]\n",
      "Epoch duration: 2.4219470024108887\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1124\n",
      "FGW torch.Size([29508, 5]) 7.767710485495627e-05\n",
      "Penalty params: tau=0.59591 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1124 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1124, train\n",
      " fgw:0.2155773\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2155773\n",
      "Measure Epoch 1124, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1124, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.0200000\n",
      " batch_invalid_valency_nodes:30.2608696\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.4800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:3.1000000\n",
      " batch_node_degree:3.0486957\n",
      "Logits [19.58537483215332, 2.258669853210449, 65.8935546875]\n",
      "Epoch duration: 2.4802911281585693\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1124\n",
      "Epoch: 1125\n",
      "FGW torch.Size([29508, 5]) 7.04157937434502e-05\n",
      "Penalty params: tau=0.59563 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1125 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1125, train\n",
      " fgw:0.2067658\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2067658\n",
      "Measure Epoch 1125, train\n",
      " similarity:0.0291444\n",
      " penlog:-84.2084397\n",
      "Metrics Epoch 1125, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:4.3200000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.8800000\n",
      " batch_nodes_7plus_degree:0.6400000\n",
      " invalid_euler_toofew:50.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.6200000\n",
      " batch_node_degree:2.5260870\n",
      "Logits [19.65213966369629, 2.2331085205078125, 65.6859130859375]\n",
      "Epoch duration: 2.395472764968872\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1125\n",
      "Epoch: 1126\n",
      "FGW torch.Size([29508, 5]) 7.875981827965006e-05\n",
      "Penalty params: tau=0.59536 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1126 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1126, train\n",
      " fgw:0.2362707\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2362707\n",
      "Measure Epoch 1126, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1126, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.1400000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:3.5700000\n",
      " batch_node_degree:2.8826087\n",
      "Logits [19.794025421142578, 2.2355690002441406, 66.02345275878906]\n",
      "Epoch duration: 2.4684247970581055\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1126\n",
      "Epoch: 1127\n",
      "FGW torch.Size([29508, 5]) 7.376732537522912e-05\n",
      "Penalty params: tau=0.59508 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1127 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1127, train\n",
      " fgw:0.2205056\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2205056\n",
      "Measure Epoch 1127, train\n",
      " similarity:0.0268825\n",
      " penlog:-94.1727507\n",
      "Metrics Epoch 1127, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.4000000\n",
      " batch_invalid_valency_nodes:25.4782609\n",
      " batch_nodes_0degree:1.7000000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:0.9900000\n",
      " batch_node_degree:2.7200000\n",
      "Logits [20.13194465637207, 2.3162426948547363, 66.87911224365234]\n",
      "Epoch duration: 2.540860176086426\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1127\n",
      "Epoch: 1128\n",
      "FGW torch.Size([29508, 5]) 7.409015961457044e-05\n",
      "Penalty params: tau=0.59481 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1128 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1128, train\n",
      " fgw:0.2186062\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2186062\n",
      "Measure Epoch 1128, train\n",
      " similarity:0.0261914\n",
      " penlog:-92.3347970\n",
      "Metrics Epoch 1128, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.6000000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.6200000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.0900000\n",
      " batch_node_degree:2.8052174\n",
      "Logits [20.39859390258789, 2.382235527038574, 67.53145599365234]\n",
      "Epoch duration: 2.48637056350708\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1128\n",
      "Epoch: 1129\n",
      "FGW torch.Size([29508, 5]) 7.497805927414447e-05\n",
      "Penalty params: tau=0.59453 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1129 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1129, train\n",
      " fgw:0.2154839\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2154839\n",
      "Measure Epoch 1129, train\n",
      " similarity:0.0297198\n",
      " penlog:-94.1655280\n",
      "Metrics Epoch 1129, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:0.9600000\n",
      " batch_nodes_7plus_degree:0.7000000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.4900000\n",
      " batch_node_degree:2.8747826\n",
      "Logits [20.59312629699707, 2.4200284481048584, 68.02849578857422]\n",
      "Epoch duration: 2.3669164180755615\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1129\n",
      "Epoch: 1130\n",
      "FGW torch.Size([29508, 5]) 6.970753747737035e-05\n",
      "Penalty params: tau=0.59426 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1130 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1130, train\n",
      " fgw:0.2172395\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2172395\n",
      "Measure Epoch 1130, train\n",
      " similarity:0.0282649\n",
      " penlog:-88.2640678\n",
      "Metrics Epoch 1130, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:4.3000000\n",
      " batch_invalid_valency_nodes:22.3478261\n",
      " batch_nodes_0degree:1.8800000\n",
      " batch_nodes_7plus_degree:0.5800000\n",
      " invalid_euler_toofew:46.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-0.9300000\n",
      " batch_node_degree:2.4347826\n",
      "Logits [20.651735305786133, 2.4248573780059814, 68.18352508544922]\n",
      "Epoch duration: 2.522068500518799\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1130\n",
      "Epoch: 1131\n",
      "FGW torch.Size([29508, 5]) 7.663438009331003e-05\n",
      "Penalty params: tau=0.59399 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1131 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1131, train\n",
      " fgw:0.2192831\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2192831\n",
      "Measure Epoch 1131, train\n",
      " similarity:0.0242553\n",
      " penlog:-96.3074351\n",
      "Metrics Epoch 1131, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.3600000\n",
      " batch_invalid_valency_nodes:34.3478261\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:1.8600000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:42.0000000\n",
      " avg_euler_error:4.8200000\n",
      " batch_node_degree:3.2643478\n",
      "Logits [20.64202880859375, 2.4102516174316406, 68.410400390625]\n",
      "Epoch duration: 2.605412483215332\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1131\n",
      "Epoch: 1132\n",
      "FGW torch.Size([29508, 5]) 7.11056127329357e-05\n",
      "Penalty params: tau=0.59371 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1132 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1132, train\n",
      " fgw:0.2259246\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2259246\n",
      "Measure Epoch 1132, train\n",
      " similarity:0.0340874\n",
      " penlog:-86.3039267\n",
      "Metrics Epoch 1132, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.4347826\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.6400000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.7800000\n",
      " batch_node_degree:2.5773913\n",
      "Logits [20.61377716064453, 2.4053053855895996, 68.1433334350586]\n",
      "Epoch duration: 2.3307595252990723\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1133\n",
      "FGW torch.Size([29508, 5]) 7.20983007340692e-05\n",
      "Penalty params: tau=0.59344 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1133 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1133, train\n",
      " fgw:0.2149547\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2149547\n",
      "Measure Epoch 1133, train\n",
      " similarity:0.0253608\n",
      " penlog:-94.3771757\n",
      "Metrics Epoch 1133, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.4000000\n",
      " batch_invalid_valency_nodes:23.7391304\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.7000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.4900000\n",
      " batch_node_degree:2.6695652\n",
      "Logits [20.503080368041992, 2.4135890007019043, 67.43412017822266]\n",
      "Epoch duration: 2.389568567276001\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1133\n",
      "Epoch: 1134\n",
      "FGW torch.Size([29508, 5]) 7.327959610847756e-05\n",
      "Penalty params: tau=0.59317 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1134 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1134, train\n",
      " fgw:0.2106238\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2106238\n",
      "Measure Epoch 1134, train\n",
      " similarity:0.0303829\n",
      " penlog:-92.4785177\n",
      "Metrics Epoch 1134, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:30.3478261\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.5000000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.7400000\n",
      " batch_node_degree:2.9800000\n",
      "Logits [20.528505325317383, 2.4519388675689697, 67.51416778564453]\n",
      "Epoch duration: 2.532823324203491\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1134\n",
      "Epoch: 1135\n",
      "FGW torch.Size([29508, 5]) 7.163012924138457e-05\n",
      "Penalty params: tau=0.59289 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1135 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1135, train\n",
      " fgw:0.2196697\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2196697\n",
      "Measure Epoch 1135, train\n",
      " similarity:0.0034568\n",
      " penlog:-98.0901547\n",
      "Metrics Epoch 1135, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.8000000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.7400000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.6800000\n",
      " batch_node_degree:2.6756522\n",
      "Logits [20.614105224609375, 2.480494499206543, 68.01040649414062]\n",
      "Epoch duration: 2.597583770751953\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1135\n",
      "Epoch: 1136\n",
      "FGW torch.Size([29508, 5]) 7.122646638890728e-05\n",
      "Penalty params: tau=0.59262 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1136 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1136, train\n",
      " fgw:0.2081932\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2081932\n",
      "Measure Epoch 1136, train\n",
      " similarity:0.0026087\n",
      " penlog:-95.9835419\n",
      "Metrics Epoch 1136, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:25.7391304\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.2300000\n",
      " batch_node_degree:2.7626087\n",
      "Logits [20.603527069091797, 2.4886345863342285, 68.12207794189453]\n",
      "Epoch duration: 2.2321724891662598\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1136\n",
      "Epoch: 1137\n",
      "FGW torch.Size([29508, 5]) 7.015571463853121e-05\n",
      "Penalty params: tau=0.59235 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1137 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1137, train\n",
      " fgw:0.2085737\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2085737\n",
      "Measure Epoch 1137, train\n",
      " similarity:0.0092507\n",
      " penlog:-90.3043567\n",
      "Metrics Epoch 1137, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8400000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.4000000\n",
      " batch_node_degree:2.6252174\n",
      "Logits [20.46687126159668, 2.466564178466797, 67.58641815185547]\n",
      "Epoch duration: 2.461909294128418\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1137\n",
      "Epoch: 1138\n",
      "FGW torch.Size([29508, 5]) 7.31404434191063e-05\n",
      "Penalty params: tau=0.59208 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1138 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1138, train\n",
      " fgw:0.2007302\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2007302\n",
      "Measure Epoch 1138, train\n",
      " similarity:0.0062419\n",
      " penlog:-92.1401282\n",
      "Metrics Epoch 1138, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:27.3913043\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.2800000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.6900000\n",
      " batch_node_degree:2.9547826\n",
      "Logits [20.427274703979492, 2.463803291320801, 67.32015991210938]\n",
      "Epoch duration: 2.4201385974884033\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1138\n",
      "Epoch: 1139\n",
      "FGW torch.Size([29508, 5]) 6.9910500315018e-05\n",
      "Penalty params: tau=0.59180 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1139 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1139, train\n",
      " fgw:0.2059932\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2059932\n",
      "Measure Epoch 1139, train\n",
      " similarity:0.0049212\n",
      " penlog:-92.3224231\n",
      "Metrics Epoch 1139, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.8800000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:1.6400000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.6500000\n",
      " batch_node_degree:2.6173913\n",
      "Logits [20.475540161132812, 2.4569191932678223, 67.17696380615234]\n",
      "Epoch duration: 2.4662559032440186\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1139\n",
      "Epoch: 1140\n",
      "FGW torch.Size([29508, 5]) 6.976231816224754e-05\n",
      "Penalty params: tau=0.59153 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1140 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1140, train\n",
      " fgw:0.2034837\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2034837\n",
      "Measure Epoch 1140, train\n",
      " similarity:0.0206452\n",
      " penlog:-96.0194863\n",
      "Metrics Epoch 1140, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:24.0000000\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:1.4800000\n",
      " batch_node_degree:2.7217391\n",
      "Logits [20.615699768066406, 2.466932773590088, 67.48051452636719]\n",
      "Epoch duration: 2.4087021350860596\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1140\n",
      "Epoch: 1141\n",
      "FGW torch.Size([29508, 5]) 7.222647400340065e-05\n",
      "Penalty params: tau=0.59126 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1141 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1141, train\n",
      " fgw:0.2107265\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2107265\n",
      "Measure Epoch 1141, train\n",
      " similarity:0.0080465\n",
      " penlog:-96.1351191\n",
      "Metrics Epoch 1141, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.2600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:2.6400000\n",
      " batch_node_degree:2.9356522\n",
      "Logits [20.735248565673828, 2.48417329788208, 67.79444122314453]\n",
      "Epoch duration: 2.460062265396118\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1142\n",
      "FGW torch.Size([29508, 5]) 7.092489249771461e-05\n",
      "Penalty params: tau=0.59099 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1142 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1142, train\n",
      " fgw:0.2077715\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2077715\n",
      "Measure Epoch 1142, train\n",
      " similarity:0.0260465\n",
      " penlog:-96.1608626\n",
      "Metrics Epoch 1142, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.5200000\n",
      " batch_invalid_valency_nodes:23.5652174\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.0100000\n",
      " batch_node_degree:2.7000000\n",
      "Logits [20.812604904174805, 2.4985270500183105, 67.8268814086914]\n",
      "Epoch duration: 2.2464702129364014\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1142\n",
      "Epoch: 1143\n",
      "FGW torch.Size([29508, 5]) 7.246479071909562e-05\n",
      "Penalty params: tau=0.59071 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1143 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1143, train\n",
      " fgw:0.2525926\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2525926\n",
      "Measure Epoch 1143, train\n",
      " similarity:0.0012500\n",
      " penlog:-98.0555512\n",
      "Metrics Epoch 1143, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.2000000\n",
      " batch_invalid_valency_nodes:23.0434783\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.4700000\n",
      " batch_node_degree:2.6826087\n",
      "Logits [20.81555938720703, 2.495164632797241, 67.70467376708984]\n",
      "Epoch duration: 2.351154327392578\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1143\n",
      "Epoch: 1144\n",
      "FGW torch.Size([29508, 5]) 7.162545080063865e-05\n",
      "Penalty params: tau=0.59044 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1144 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1144, train\n",
      " fgw:0.2248084\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2248084\n",
      "Measure Epoch 1144, train\n",
      " similarity:0.0027451\n",
      " penlog:-98.1513600\n",
      "Metrics Epoch 1144, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.3000000\n",
      " batch_invalid_valency_nodes:27.5652174\n",
      " batch_nodes_0degree:1.6000000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.9700000\n",
      " batch_node_degree:2.8243478\n",
      "Logits [20.954042434692383, 2.5095925331115723, 67.85669708251953]\n",
      "Epoch duration: 2.270670175552368\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1144\n",
      "Epoch: 1145\n",
      "FGW torch.Size([29508, 5]) 7.144164555938914e-05\n",
      "Penalty params: tau=0.59017 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1145 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1145, train\n",
      " fgw:0.2304258\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2304258\n",
      "Measure Epoch 1145, train\n",
      " similarity:0.0043563\n",
      " penlog:-94.0397966\n",
      "Metrics Epoch 1145, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:23.6521739\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.4000000\n",
      " batch_node_degree:2.7365217\n",
      "Logits [21.099504470825195, 2.5297367572784424, 68.12953186035156]\n",
      "Epoch duration: 2.4181323051452637\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1145\n",
      "Epoch: 1146\n",
      "FGW torch.Size([29508, 5]) 7.075633766362444e-05\n",
      "Penalty params: tau=0.58990 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1146 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1146, train\n",
      " fgw:0.2245247\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2245247\n",
      "Measure Epoch 1146, train\n",
      " similarity:0.0036995\n",
      " penlog:-96.2993802\n",
      "Metrics Epoch 1146, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.4900000\n",
      " batch_node_degree:2.7400000\n",
      "Logits [21.12077522277832, 2.5371437072753906, 68.22269439697266]\n",
      "Epoch duration: 2.3526906967163086\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1146\n",
      "Epoch: 1147\n",
      "FGW torch.Size([29508, 5]) 7.245470624184236e-05\n",
      "Penalty params: tau=0.58963 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1147 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1147, train\n",
      " fgw:0.2160187\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2160187\n",
      "Measure Epoch 1147, train\n",
      " similarity:0.0057283\n",
      " penlog:-96.0304918\n",
      "Metrics Epoch 1147, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:27.4782609\n",
      " batch_nodes_0degree:1.7400000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.5500000\n",
      " batch_node_degree:2.7608696\n",
      "Logits [20.94141387939453, 2.510979175567627, 67.94979858398438]\n",
      "Epoch duration: 2.402068614959717\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1147\n",
      "Epoch: 1148\n",
      "FGW torch.Size([29508, 5]) 7.209867180790752e-05\n",
      "Penalty params: tau=0.58936 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1148 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1148, train\n",
      " fgw:0.2080981\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2080981\n",
      "Measure Epoch 1148, train\n",
      " similarity:0.0038889\n",
      " penlog:-96.0196442\n",
      "Metrics Epoch 1148, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1600000\n",
      " batch_invalid_valency_nodes:28.4347826\n",
      " batch_nodes_0degree:1.7400000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.5300000\n",
      " batch_node_degree:2.7965217\n",
      "Logits [20.802587509155273, 2.4992034435272217, 67.75598907470703]\n",
      "Epoch duration: 2.3363654613494873\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1148\n",
      "Epoch: 1149\n",
      "FGW torch.Size([29508, 5]) 7.235411612782627e-05\n",
      "Penalty params: tau=0.58908 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1149 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1149, train\n",
      " fgw:0.2106464\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2106464\n",
      "Measure Epoch 1149, train\n",
      " similarity:0.0023529\n",
      " penlog:-98.1217862\n",
      "Metrics Epoch 1149, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.3600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.3800000\n",
      " batch_node_degree:2.9782609\n",
      "Logits [20.59436798095703, 2.4828720092773438, 67.48514556884766]\n",
      "Epoch duration: 2.156219959259033\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1149\n",
      "Epoch: 1150\n",
      "FGW torch.Size([29508, 5]) 7.293116505024955e-05\n",
      "Penalty params: tau=0.58881 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1150 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1150, train\n",
      " fgw:0.2225028\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2225028\n",
      "Measure Epoch 1150, train\n",
      " similarity:0.0038624\n",
      " penlog:-95.9068618\n",
      "Metrics Epoch 1150, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8400000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.0400000\n",
      " batch_node_degree:2.9104348\n",
      "Logits [20.422286987304688, 2.4683754444122314, 67.14321899414062]\n",
      "Epoch duration: 2.8300399780273438\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1151\n",
      "FGW torch.Size([29508, 5]) 7.330485823331401e-05\n",
      "Penalty params: tau=0.58854 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1151 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1151, train\n",
      " fgw:0.2165425\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2165425\n",
      "Measure Epoch 1151, train\n",
      " similarity:0.0139489\n",
      " penlog:-92.0924012\n",
      "Metrics Epoch 1151, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:27.8260870\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.9900000\n",
      " batch_node_degree:2.8269565\n",
      "Logits [20.31367301940918, 2.47306489944458, 67.00537872314453]\n",
      "Epoch duration: 2.3179116249084473\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1151\n",
      "Epoch: 1152\n",
      "FGW torch.Size([29508, 5]) 7.602814730489627e-05\n",
      "Penalty params: tau=0.58827 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1152 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1152, train\n",
      " fgw:0.2069261\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2069261\n",
      "Measure Epoch 1152, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1152, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.5800000\n",
      " batch_invalid_valency_nodes:32.6086957\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:1.6600000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:40.0000000\n",
      " avg_euler_error:5.1100000\n",
      " batch_node_degree:3.2243478\n",
      "Logits [20.240495681762695, 2.480005979537964, 66.73319244384766]\n",
      "Epoch duration: 2.2379767894744873\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1152\n",
      "Epoch: 1153\n",
      "FGW torch.Size([29508, 5]) 6.9904446718283e-05\n",
      "Penalty params: tau=0.58800 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1153 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1153, train\n",
      " fgw:0.2202275\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2202275\n",
      "Measure Epoch 1153, train\n",
      " similarity:0.0076042\n",
      " penlog:-92.2046245\n",
      "Metrics Epoch 1153, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.8200000\n",
      " batch_invalid_valency_nodes:23.4782609\n",
      " batch_nodes_0degree:1.8200000\n",
      " batch_nodes_7plus_degree:0.6000000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.0400000\n",
      " batch_node_degree:2.5365217\n",
      "Logits [20.17341423034668, 2.4762330055236816, 66.29077911376953]\n",
      "Epoch duration: 2.6499550342559814\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1153\n",
      "Epoch: 1154\n",
      "FGW torch.Size([29508, 5]) 7.342981552938e-05\n",
      "Penalty params: tau=0.58773 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1154 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1154, train\n",
      " fgw:0.2085251\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2085251\n",
      "Measure Epoch 1154, train\n",
      " similarity:0.0145950\n",
      " penlog:-92.0210682\n",
      "Metrics Epoch 1154, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:22.9565217\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.8500000\n",
      " batch_node_degree:2.7426087\n",
      "Logits [20.06044578552246, 2.4593987464904785, 66.02305603027344]\n",
      "Epoch duration: 2.2810401916503906\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1154\n",
      "Epoch: 1155\n",
      "FGW torch.Size([29508, 5]) 7.423752686008811e-05\n",
      "Penalty params: tau=0.58746 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1155 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1155, train\n",
      " fgw:0.2081464\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2081464\n",
      "Measure Epoch 1155, train\n",
      " similarity:0.0031240\n",
      " penlog:-96.0955756\n",
      "Metrics Epoch 1155, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0200000\n",
      " batch_invalid_valency_nodes:28.2608696\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:1.2200000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.1500000\n",
      " batch_node_degree:2.8721739\n",
      "Logits [20.067306518554688, 2.459012269973755, 66.15966033935547]\n",
      "Epoch duration: 2.368651866912842\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1155\n",
      "Epoch: 1156\n",
      "FGW torch.Size([29508, 5]) 7.052585715427995e-05\n",
      "Penalty params: tau=0.58719 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1156 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1156, train\n",
      " fgw:0.2207792\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2207792\n",
      "Measure Epoch 1156, train\n",
      " similarity:0.0088689\n",
      " penlog:-88.8400133\n",
      "Metrics Epoch 1156, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.9600000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:1.9200000\n",
      " batch_nodes_7plus_degree:0.7000000\n",
      " invalid_euler_toofew:48.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.8100000\n",
      " batch_node_degree:2.4921739\n",
      "Logits [20.183019638061523, 2.461526393890381, 66.44335174560547]\n",
      "Epoch duration: 2.3996036052703857\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1156\n",
      "Epoch: 1157\n",
      "FGW torch.Size([29508, 5]) 7.453149009961635e-05\n",
      "Penalty params: tau=0.58692 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1157 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1157, train\n",
      " fgw:0.2112424\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2112424\n",
      "Measure Epoch 1157, train\n",
      " similarity:0.0020158\n",
      " penlog:-96.1059889\n",
      "Metrics Epoch 1157, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6800000\n",
      " batch_invalid_valency_nodes:28.0000000\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.4300000\n",
      " batch_node_degree:2.9139130\n",
      "Logits [20.186302185058594, 2.435624361038208, 66.4446029663086]\n",
      "Epoch duration: 2.1314454078674316\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1157\n",
      "Epoch: 1158\n",
      "FGW torch.Size([29508, 5]) 7.130210724426433e-05\n",
      "Penalty params: tau=0.58665 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1158 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1158, train\n",
      " fgw:0.2178594\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2178594\n",
      "Measure Epoch 1158, train\n",
      " similarity:0.0049397\n",
      " penlog:-96.1781176\n",
      "Metrics Epoch 1158, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.4400000\n",
      " batch_invalid_valency_nodes:27.3043478\n",
      " batch_nodes_0degree:1.7800000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.0300000\n",
      " batch_node_degree:2.7069565\n",
      "Logits [20.241024017333984, 2.443613290786743, 66.31021881103516]\n",
      "Epoch duration: 2.5093777179718018\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1158\n",
      "Epoch: 1159\n",
      "FGW torch.Size([29508, 5]) 7.034037844277918e-05\n",
      "Penalty params: tau=0.58638 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1159 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1159, train\n",
      " fgw:0.2072372\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2072372\n",
      "Measure Epoch 1159, train\n",
      " similarity:0.0031548\n",
      " penlog:-96.2968267\n",
      "Metrics Epoch 1159, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.7400000\n",
      " batch_invalid_valency_nodes:27.3043478\n",
      " batch_nodes_0degree:1.6800000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.6700000\n",
      " batch_node_degree:2.7095652\n",
      "Logits [20.272062301635742, 2.440216064453125, 65.91229248046875]\n",
      "Epoch duration: 2.5173916816711426\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1160\n",
      "FGW torch.Size([29508, 5]) 7.223059219541028e-05\n",
      "Penalty params: tau=0.58611 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1160 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1160, train\n",
      " fgw:0.2146158\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2146158\n",
      "Measure Epoch 1160, train\n",
      " similarity:0.0000000\n",
      " penlog:-100.0000000\n",
      "Metrics Epoch 1160, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:0.0000000\n",
      " batch_connected_components:2.7200000\n",
      " batch_invalid_valency_nodes:27.2173913\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.2300000\n",
      " batch_node_degree:2.9260870\n",
      "Logits [20.279752731323242, 2.4150230884552, 65.54290771484375]\n",
      "Epoch duration: 2.8756215572357178\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1160\n",
      "Epoch: 1161\n",
      "FGW torch.Size([29508, 5]) 7.124061085050926e-05\n",
      "Penalty params: tau=0.58584 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1161 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1161, train\n",
      " fgw:0.2166234\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2166234\n",
      "Measure Epoch 1161, train\n",
      " similarity:0.0237294\n",
      " penlog:-92.1915830\n",
      "Metrics Epoch 1161, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.3600000\n",
      " batch_invalid_valency_nodes:23.2173913\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.6500000\n",
      " batch_node_degree:2.6104348\n",
      "Logits [20.482698440551758, 2.444784164428711, 66.09870147705078]\n",
      "Epoch duration: 2.4077558517456055\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1161\n",
      "Epoch: 1162\n",
      "FGW torch.Size([29508, 5]) 7.041252683848143e-05\n",
      "Penalty params: tau=0.58557 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1162 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1162, train\n",
      " fgw:0.2026762\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2026762\n",
      "Measure Epoch 1162, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1162, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.4400000\n",
      " batch_invalid_valency_nodes:25.6521739\n",
      " batch_nodes_0degree:1.6800000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.6500000\n",
      " batch_node_degree:2.6373913\n",
      "Logits [20.517946243286133, 2.4438223838806152, 66.17366027832031]\n",
      "Epoch duration: 2.9423367977142334\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1162\n",
      "Epoch: 1163\n",
      "FGW torch.Size([29508, 5]) 7.355631532846019e-05\n",
      "Penalty params: tau=0.58530 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1163 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1163, train\n",
      " fgw:0.2073297\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2073297\n",
      "Measure Epoch 1163, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1163, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:29.1304348\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.7900000\n",
      " batch_node_degree:2.9017391\n",
      "Logits [20.399694442749023, 2.4284896850585938, 65.81653594970703]\n",
      "Epoch duration: 2.8275058269500732\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1163\n",
      "Epoch: 1164\n",
      "FGW torch.Size([29508, 5]) 6.999276229180396e-05\n",
      "Penalty params: tau=0.58503 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1164 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1164, train\n",
      " fgw:0.2067336\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2067336\n",
      "Measure Epoch 1164, train\n",
      " similarity:0.0314961\n",
      " penlog:-88.0914672\n",
      "Metrics Epoch 1164, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.8800000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.8200000\n",
      " batch_node_degree:2.6130435\n",
      "Logits [20.192710876464844, 2.421208143234253, 65.1773910522461]\n",
      "Epoch duration: 2.4549241065979004\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1164\n",
      "Epoch: 1165\n",
      "FGW torch.Size([29508, 5]) 7.045560050755739e-05\n",
      "Penalty params: tau=0.58476 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1165 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1165, train\n",
      " fgw:0.2072096\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2072096\n",
      "Measure Epoch 1165, train\n",
      " similarity:0.0234201\n",
      " penlog:-94.2221922\n",
      "Metrics Epoch 1165, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.3800000\n",
      " batch_invalid_valency_nodes:27.0434783\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.2900000\n",
      " batch_node_degree:2.6965217\n",
      "Logits [20.459197998046875, 2.4745123386383057, 66.38858795166016]\n",
      "Epoch duration: 2.5451769828796387\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1165\n",
      "Epoch: 1166\n",
      "FGW torch.Size([29508, 5]) 7.273544906638563e-05\n",
      "Penalty params: tau=0.58449 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1166 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1166, train\n",
      " fgw:0.2011712\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2011712\n",
      "Measure Epoch 1166, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1166, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.8000000\n",
      " batch_invalid_valency_nodes:31.0434783\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:1.4400000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:3.5400000\n",
      " batch_node_degree:3.0069565\n",
      "Logits [20.440797805786133, 2.485131025314331, 66.56857299804688]\n",
      "Epoch duration: 2.3138537406921387\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1166\n",
      "Epoch: 1167\n",
      "FGW torch.Size([29508, 5]) 6.862035661470145e-05\n",
      "Penalty params: tau=0.58422 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1167 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1167, train\n",
      " fgw:0.2141647\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2141647\n",
      "Measure Epoch 1167, train\n",
      " similarity:0.0258395\n",
      " penlog:-94.1242792\n",
      "Metrics Epoch 1167, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.8600000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.9200000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:42.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:-0.3200000\n",
      " batch_node_degree:2.5565217\n",
      "Logits [20.369977951049805, 2.491072177886963, 66.54642486572266]\n",
      "Epoch duration: 2.285675525665283\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1167\n",
      "Epoch: 1168\n",
      "FGW torch.Size([29508, 5]) 7.30354295228608e-05\n",
      "Penalty params: tau=0.58395 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1168 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1168, train\n",
      " fgw:0.2198414\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2198414\n",
      "Measure Epoch 1168, train\n",
      " similarity:0.0106408\n",
      " penlog:-92.1229955\n",
      "Metrics Epoch 1168, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:1.3200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.6300000\n",
      " batch_node_degree:2.9660870\n",
      "Logits [20.003076553344727, 2.445227861404419, 65.52546691894531]\n",
      "Epoch duration: 2.9015066623687744\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1169\n",
      "FGW torch.Size([29508, 5]) 7.116356573533267e-05\n",
      "Penalty params: tau=0.58368 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1169 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1169, train\n",
      " fgw:0.2068419\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2068419\n",
      "Measure Epoch 1169, train\n",
      " similarity:0.0110903\n",
      " penlog:-92.0978616\n",
      "Metrics Epoch 1169, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:25.4782609\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.6100000\n",
      " batch_node_degree:2.7704348\n",
      "Logits [19.724788665771484, 2.4037251472473145, 64.43011474609375]\n",
      "Epoch duration: 3.76815128326416\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1169\n",
      "Epoch: 1170\n",
      "FGW torch.Size([29508, 5]) 7.010395347606391e-05\n",
      "Penalty params: tau=0.58341 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1170 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1170, train\n",
      " fgw:0.2005695\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2005695\n",
      "Measure Epoch 1170, train\n",
      " similarity:0.0099784\n",
      " penlog:-92.3113218\n",
      "Metrics Epoch 1170, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.6200000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:1.8000000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.7500000\n",
      " batch_node_degree:2.7391304\n",
      "Logits [19.412860870361328, 2.3733034133911133, 63.72208023071289]\n",
      "Epoch duration: 3.259453058242798\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1170\n",
      "Epoch: 1171\n",
      "FGW torch.Size([29508, 5]) 7.25026402506046e-05\n",
      "Penalty params: tau=0.58315 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1171 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1171, train\n",
      " fgw:0.2038142\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2038142\n",
      "Measure Epoch 1171, train\n",
      " similarity:0.0285272\n",
      " penlog:-90.5693430\n",
      "Metrics Epoch 1171, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.4200000\n",
      " batch_invalid_valency_nodes:27.0434783\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:1.1800000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.1100000\n",
      " batch_node_degree:2.8486957\n",
      "Logits [19.419240951538086, 2.3819258213043213, 64.13601684570312]\n",
      "Epoch duration: 3.072995185852051\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1171\n",
      "Epoch: 1172\n",
      "FGW torch.Size([29508, 5]) 7.12658220436424e-05\n",
      "Penalty params: tau=0.58288 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1172 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1172, train\n",
      " fgw:0.2049066\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2049066\n",
      "Measure Epoch 1172, train\n",
      " similarity:0.0290306\n",
      " penlog:-92.4446024\n",
      "Metrics Epoch 1172, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.3000000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.1900000\n",
      " batch_node_degree:2.7904348\n",
      "Logits [19.832460403442383, 2.4501113891601562, 65.72897338867188]\n",
      "Epoch duration: 2.8307464122772217\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1172\n",
      "Epoch: 1173\n",
      "FGW torch.Size([29508, 5]) 6.805733573855832e-05\n",
      "Penalty params: tau=0.58261 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1173 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1173, train\n",
      " fgw:0.2070877\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2070877\n",
      "Measure Epoch 1173, train\n",
      " similarity:0.0292417\n",
      " penlog:-90.1378680\n",
      "Metrics Epoch 1173, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:21.4782609\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.4600000\n",
      " batch_node_degree:2.6060870\n",
      "Logits [20.1667423248291, 2.4990763664245605, 66.26031494140625]\n",
      "Epoch duration: 2.5478782653808594\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1173\n",
      "Epoch: 1174\n",
      "FGW torch.Size([29508, 5]) 7.084138633217663e-05\n",
      "Penalty params: tau=0.58234 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1174 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1174, train\n",
      " fgw:0.2014845\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2014845\n",
      "Measure Epoch 1174, train\n",
      " similarity:0.0223256\n",
      " penlog:-96.1697773\n",
      "Metrics Epoch 1174, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:25.8260870\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:2.3700000\n",
      " batch_node_degree:2.8373913\n",
      "Logits [20.264850616455078, 2.494507312774658, 66.14168548583984]\n",
      "Epoch duration: 2.5259644985198975\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1174\n",
      "Epoch: 1175\n",
      "FGW torch.Size([29508, 5]) 6.849066267022863e-05\n",
      "Penalty params: tau=0.58207 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1175 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1175, train\n",
      " fgw:0.2011573\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2011573\n",
      "Measure Epoch 1175, train\n",
      " similarity:0.0323527\n",
      " penlog:-88.8113303\n",
      "Metrics Epoch 1175, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.6800000\n",
      " batch_invalid_valency_nodes:24.7826087\n",
      " batch_nodes_0degree:1.7400000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.5500000\n",
      " batch_node_degree:2.6452174\n",
      "Logits [20.24020767211914, 2.4619247913360596, 65.60624694824219]\n",
      "Epoch duration: 2.4971635341644287\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1175\n",
      "Epoch: 1176\n",
      "FGW torch.Size([29508, 5]) 6.96164061082527e-05\n",
      "Penalty params: tau=0.58180 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1176 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1176, train\n",
      " fgw:0.2144054\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2144054\n",
      "Measure Epoch 1176, train\n",
      " similarity:0.0032000\n",
      " penlog:-98.1350180\n",
      "Metrics Epoch 1176, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.7800000\n",
      " batch_invalid_valency_nodes:25.5652174\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:1.3200000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.4400000\n",
      " batch_node_degree:2.8721739\n",
      "Logits [20.180631637573242, 2.4329798221588135, 65.30107116699219]\n",
      "Epoch duration: 2.532660722732544\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1176\n",
      "Epoch: 1177\n",
      "FGW torch.Size([29508, 5]) 7.112549792509526e-05\n",
      "Penalty params: tau=0.58154 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1177 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1177, train\n",
      " fgw:0.2142527\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2142527\n",
      "Measure Epoch 1177, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1177, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.3000000\n",
      " batch_invalid_valency_nodes:28.8695652\n",
      " batch_nodes_0degree:1.5600000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.5100000\n",
      " batch_node_degree:2.8991304\n",
      "Logits [20.26107406616211, 2.447303533554077, 65.8490982055664]\n",
      "Epoch duration: 3.178858757019043\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1178\n",
      "FGW torch.Size([29508, 5]) 6.984313949942589e-05\n",
      "Penalty params: tau=0.58127 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1178 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1178, train\n",
      " fgw:0.2063569\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2063569\n",
      "Measure Epoch 1178, train\n",
      " similarity:0.0056988\n",
      " penlog:-96.1070381\n",
      "Metrics Epoch 1178, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.7000000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.7600000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.5100000\n",
      " batch_node_degree:2.6704348\n",
      "Logits [20.447547912597656, 2.486717939376831, 66.60526275634766]\n",
      "Epoch duration: 2.699538469314575\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1178\n",
      "Epoch: 1179\n",
      "FGW torch.Size([29508, 5]) 6.84971091686748e-05\n",
      "Penalty params: tau=0.58100 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1179 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1179, train\n",
      " fgw:0.2036220\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2036220\n",
      "Measure Epoch 1179, train\n",
      " similarity:0.0005405\n",
      " penlog:-98.0103221\n",
      "Metrics Epoch 1179, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.1300000\n",
      " batch_node_degree:2.7947826\n",
      "Logits [20.581462860107422, 2.5286457538604736, 67.2790298461914]\n",
      "Epoch duration: 2.6136929988861084\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1179\n",
      "Epoch: 1180\n",
      "FGW torch.Size([29508, 5]) 6.965076318010688e-05\n",
      "Penalty params: tau=0.58073 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1180 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1180, train\n",
      " fgw:0.2079564\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2079564\n",
      "Measure Epoch 1180, train\n",
      " similarity:0.0356971\n",
      " penlog:-90.1938123\n",
      "Metrics Epoch 1180, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.3400000\n",
      " batch_invalid_valency_nodes:24.3478261\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.5500000\n",
      " batch_node_degree:2.7782609\n",
      "Logits [20.67156219482422, 2.548736333847046, 67.60171508789062]\n",
      "Epoch duration: 2.8659090995788574\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1180\n",
      "Epoch: 1181\n",
      "FGW torch.Size([29508, 5]) 7.313577953027561e-05\n",
      "Penalty params: tau=0.58047 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1181 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1181, train\n",
      " fgw:0.2312877\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2312877\n",
      "Measure Epoch 1181, train\n",
      " similarity:0.0151530\n",
      " penlog:-90.4117679\n",
      "Metrics Epoch 1181, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.2800000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.9000000\n",
      " batch_node_degree:2.8182609\n",
      "Logits [20.502347946166992, 2.494173049926758, 67.08352661132812]\n",
      "Epoch duration: 2.5667879581451416\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1181\n",
      "Epoch: 1182\n",
      "FGW torch.Size([29508, 5]) 7.148736040107906e-05\n",
      "Penalty params: tau=0.58020 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1182 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1182, train\n",
      " fgw:0.2084113\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2084113\n",
      "Measure Epoch 1182, train\n",
      " similarity:0.0026923\n",
      " penlog:-98.1112737\n",
      "Metrics Epoch 1182, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.7200000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:0.9600000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:3.0100000\n",
      " batch_node_degree:2.9295652\n",
      "Logits [20.359878540039062, 2.448776960372925, 66.67095184326172]\n",
      "Epoch duration: 2.8276267051696777\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1182\n",
      "Epoch: 1183\n",
      "FGW torch.Size([29508, 5]) 6.780801777495071e-05\n",
      "Penalty params: tau=0.57993 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1183 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1183, train\n",
      " fgw:0.2075381\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2075381\n",
      "Measure Epoch 1183, train\n",
      " similarity:0.0269610\n",
      " penlog:-90.1976640\n",
      "Metrics Epoch 1183, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.6800000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.6400000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:36.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.8400000\n",
      " batch_node_degree:2.6591304\n",
      "Logits [20.33372688293457, 2.4230644702911377, 66.47998809814453]\n",
      "Epoch duration: 2.7407233715057373\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1183\n",
      "Epoch: 1184\n",
      "FGW torch.Size([29508, 5]) 7.05609199940227e-05\n",
      "Penalty params: tau=0.57966 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1184 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1184, train\n",
      " fgw:0.1935718\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1935718\n",
      "Measure Epoch 1184, train\n",
      " similarity:0.0051064\n",
      " penlog:-97.9974143\n",
      "Metrics Epoch 1184, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:28.0869565\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.2700000\n",
      " batch_node_degree:2.8339130\n",
      "Logits [20.40060043334961, 2.419527053833008, 66.50872802734375]\n",
      "Epoch duration: 2.435361862182617\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1184\n",
      "Epoch: 1185\n",
      "FGW torch.Size([29508, 5]) 7.108286081347615e-05\n",
      "Penalty params: tau=0.57940 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1185 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1185, train\n",
      " fgw:0.2032389\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2032389\n",
      "Measure Epoch 1185, train\n",
      " similarity:0.0035833\n",
      " penlog:-96.0581988\n",
      "Metrics Epoch 1185, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.8000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:2.0800000\n",
      " batch_node_degree:2.8182609\n",
      "Logits [20.514406204223633, 2.4361095428466797, 66.76329040527344]\n",
      "Epoch duration: 2.4473578929901123\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1185\n",
      "Epoch: 1186\n",
      "FGW torch.Size([29508, 5]) 6.960073369555175e-05\n",
      "Penalty params: tau=0.57913 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1186 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1186, train\n",
      " fgw:0.1996012\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1996012\n",
      "Measure Epoch 1186, train\n",
      " similarity:0.0108293\n",
      " penlog:-94.2161131\n",
      "Metrics Epoch 1186, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:23.4782609\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.9100000\n",
      " batch_node_degree:2.6739130\n",
      "Logits [20.662513732910156, 2.469597816467285, 67.27034759521484]\n",
      "Epoch duration: 2.3934013843536377\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1187\n",
      "FGW torch.Size([29508, 5]) 7.222670683404431e-05\n",
      "Penalty params: tau=0.57886 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1187 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1187, train\n",
      " fgw:0.2039090\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2039090\n",
      "Measure Epoch 1187, train\n",
      " similarity:0.0084422\n",
      " penlog:-94.3098626\n",
      "Metrics Epoch 1187, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1000000\n",
      " batch_invalid_valency_nodes:28.6086957\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.2200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.3800000\n",
      " batch_node_degree:2.9713043\n",
      "Logits [20.806781768798828, 2.5127391815185547, 67.93412780761719]\n",
      "Epoch duration: 2.650984764099121\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1187\n",
      "Epoch: 1188\n",
      "FGW torch.Size([29508, 5]) 6.868888158351183e-05\n",
      "Penalty params: tau=0.57860 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1188 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1188, train\n",
      " fgw:0.1991738\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1991738\n",
      "Measure Epoch 1188, train\n",
      " similarity:0.0188968\n",
      " penlog:-84.5746326\n",
      "Metrics Epoch 1188, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:3.9400000\n",
      " batch_invalid_valency_nodes:25.4782609\n",
      " batch_nodes_0degree:1.7400000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.2800000\n",
      " batch_node_degree:2.6373913\n",
      "Logits [20.883413314819336, 2.5469512939453125, 68.35179138183594]\n",
      "Epoch duration: 2.5455214977264404\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1188\n",
      "Epoch: 1189\n",
      "FGW torch.Size([29508, 5]) 7.246946188388392e-05\n",
      "Penalty params: tau=0.57833 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1189 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1189, train\n",
      " fgw:0.2028095\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2028095\n",
      "Measure Epoch 1189, train\n",
      " similarity:0.0108478\n",
      " penlog:-94.1316813\n",
      "Metrics Epoch 1189, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:30.4347826\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.4000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.5100000\n",
      " batch_node_degree:3.0304348\n",
      "Logits [20.753793716430664, 2.5250890254974365, 67.96783447265625]\n",
      "Epoch duration: 2.3779494762420654\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1189\n",
      "Epoch: 1190\n",
      "FGW torch.Size([29508, 5]) 7.126158743631095e-05\n",
      "Penalty params: tau=0.57806 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1190 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1190, train\n",
      " fgw:0.2236268\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2236268\n",
      "Measure Epoch 1190, train\n",
      " similarity:0.0253310\n",
      " penlog:-94.1209236\n",
      "Metrics Epoch 1190, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:24.7826087\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:0.8000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.8700000\n",
      " batch_node_degree:2.7513043\n",
      "Logits [20.549137115478516, 2.4876253604888916, 67.06159210205078]\n",
      "Epoch duration: 2.8711159229278564\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1190\n",
      "Epoch: 1191\n",
      "FGW torch.Size([29508, 5]) 6.934244447620586e-05\n",
      "Penalty params: tau=0.57780 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1191 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1191, train\n",
      " fgw:0.2056384\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2056384\n",
      "Measure Epoch 1191, train\n",
      " similarity:0.0307396\n",
      " penlog:-90.3012726\n",
      "Metrics Epoch 1191, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.6800000\n",
      " batch_invalid_valency_nodes:23.5652174\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:36.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.5400000\n",
      " batch_node_degree:2.6226087\n",
      "Logits [20.221529006958008, 2.4315881729125977, 65.79328155517578]\n",
      "Epoch duration: 2.9385101795196533\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1191\n",
      "Epoch: 1192\n",
      "FGW torch.Size([29508, 5]) 7.31458276277408e-05\n",
      "Penalty params: tau=0.57753 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1192 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1192, train\n",
      " fgw:0.2054334\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2054334\n",
      "Measure Epoch 1192, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1192, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.3400000\n",
      " batch_invalid_valency_nodes:31.0434783\n",
      " batch_nodes_0degree:0.9800000\n",
      " batch_nodes_7plus_degree:1.4400000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.4400000\n",
      " batch_node_degree:3.1600000\n",
      "Logits [19.963560104370117, 2.38429856300354, 64.74756622314453]\n",
      "Epoch duration: 2.57893705368042\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1192\n",
      "Epoch: 1193\n",
      "FGW torch.Size([29508, 5]) 6.78620272083208e-05\n",
      "Penalty params: tau=0.57727 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1193 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1193, train\n",
      " fgw:0.2060958\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2060958\n",
      "Measure Epoch 1193, train\n",
      " similarity:0.0064096\n",
      " penlog:-96.2139851\n",
      "Metrics Epoch 1193, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.5600000\n",
      " batch_invalid_valency_nodes:23.8260870\n",
      " batch_nodes_0degree:1.7600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.0000000\n",
      " batch_node_degree:2.5582609\n",
      "Logits [19.889915466308594, 2.3592662811279297, 64.21724700927734]\n",
      "Epoch duration: 2.471803903579712\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1193\n",
      "Epoch: 1194\n",
      "FGW torch.Size([29508, 5]) 7.05976490280591e-05\n",
      "Penalty params: tau=0.57700 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1194 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1194, train\n",
      " fgw:0.2058880\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2058880\n",
      "Measure Epoch 1194, train\n",
      " similarity:0.0272461\n",
      " penlog:-90.1808657\n",
      "Metrics Epoch 1194, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.8200000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.7300000\n",
      " batch_node_degree:2.8069565\n",
      "Logits [20.04174041748047, 2.3847339153289795, 64.81845092773438]\n",
      "Epoch duration: 2.1827075481414795\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1194\n",
      "Epoch: 1195\n",
      "FGW torch.Size([29508, 5]) 7.053516310406849e-05\n",
      "Penalty params: tau=0.57673 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1195 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1195, train\n",
      " fgw:0.1990366\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1990366\n",
      "Measure Epoch 1195, train\n",
      " similarity:0.0083042\n",
      " penlog:-94.2161617\n",
      "Metrics Epoch 1195, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0200000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.0300000\n",
      " batch_node_degree:2.8113043\n",
      "Logits [20.33003044128418, 2.443129539489746, 65.88467407226562]\n",
      "Epoch duration: 2.354614019393921\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1196\n",
      "FGW torch.Size([29508, 5]) 6.734079215675592e-05\n",
      "Penalty params: tau=0.57647 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1196 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1196, train\n",
      " fgw:0.1971038\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1971038\n",
      "Measure Epoch 1196, train\n",
      " similarity:0.0094737\n",
      " penlog:-98.0219921\n",
      "Metrics Epoch 1196, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.4000000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:1.5800000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.8800000\n",
      " batch_node_degree:2.6660870\n",
      "Logits [20.58934211730957, 2.5032784938812256, 66.74248504638672]\n",
      "Epoch duration: 2.1450722217559814\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1196\n",
      "Epoch: 1197\n",
      "FGW torch.Size([29508, 5]) 7.021320925559849e-05\n",
      "Penalty params: tau=0.57620 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1197 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1197, train\n",
      " fgw:0.2133550\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2133550\n",
      "Measure Epoch 1197, train\n",
      " similarity:0.0283175\n",
      " penlog:-92.4200478\n",
      "Metrics Epoch 1197, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:25.7391304\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.1800000\n",
      " batch_node_degree:2.8173913\n",
      "Logits [20.736610412597656, 2.5352675914764404, 67.42298889160156]\n",
      "Epoch duration: 2.2929940223693848\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1197\n",
      "Epoch: 1198\n",
      "FGW torch.Size([29508, 5]) 6.960201426409185e-05\n",
      "Penalty params: tau=0.57594 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1198 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1198, train\n",
      " fgw:0.2009746\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2009746\n",
      "Measure Epoch 1198, train\n",
      " similarity:0.0280373\n",
      " penlog:-94.2533011\n",
      "Metrics Epoch 1198, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0000000\n",
      " batch_invalid_valency_nodes:26.0869565\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.6200000\n",
      " batch_node_degree:2.7582609\n",
      "Logits [20.78763771057129, 2.5252010822296143, 67.80685424804688]\n",
      "Epoch duration: 2.3467724323272705\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1198\n",
      "Epoch: 1199\n",
      "FGW torch.Size([29508, 5]) 6.918865256011486e-05\n",
      "Penalty params: tau=0.57567 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1199 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1199, train\n",
      " fgw:0.2106141\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2106141\n",
      "Measure Epoch 1199, train\n",
      " similarity:0.0306099\n",
      " penlog:-90.6567569\n",
      "Metrics Epoch 1199, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8200000\n",
      " batch_invalid_valency_nodes:27.0434783\n",
      " batch_nodes_0degree:1.8600000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:0.4300000\n",
      " batch_node_degree:2.6521739\n",
      "Logits [20.693988800048828, 2.48753023147583, 67.70481872558594]\n",
      "Epoch duration: 2.449159622192383\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1199\n",
      "Epoch: 1200\n",
      "FGW torch.Size([29508, 5]) 7.881151395849884e-05\n",
      "Penalty params: tau=0.57541 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1200 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1200, train\n",
      " fgw:0.2425665\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2425665\n",
      "Measure Epoch 1200, train\n",
      " similarity:0.0053333\n",
      " penlog:-98.1153760\n",
      "Metrics Epoch 1200, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.4000000\n",
      " batch_invalid_valency_nodes:32.1739130\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.5600000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:42.0000000\n",
      " avg_euler_error:4.6500000\n",
      " batch_node_degree:3.1191304\n",
      "Logits [20.590299606323242, 2.4378838539123535, 67.62222290039062]\n",
      "Epoch duration: 2.3017683029174805\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1200\n",
      "Epoch: 1201\n",
      "FGW torch.Size([29508, 5]) 7.13090630597435e-05\n",
      "Penalty params: tau=0.57514 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1201 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1201, train\n",
      " fgw:0.2343533\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2343533\n",
      "Measure Epoch 1201, train\n",
      " similarity:0.0137377\n",
      " penlog:-86.2697249\n",
      "Metrics Epoch 1201, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:4.0600000\n",
      " batch_invalid_valency_nodes:23.5652174\n",
      " batch_nodes_0degree:1.8800000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.1500000\n",
      " batch_node_degree:2.5147826\n",
      "Logits [20.441884994506836, 2.4029719829559326, 67.19312286376953]\n",
      "Epoch duration: 2.420334815979004\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1201\n",
      "Epoch: 1202\n",
      "FGW torch.Size([29508, 5]) 7.472807919839397e-05\n",
      "Penalty params: tau=0.57488 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1202 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1202, train\n",
      " fgw:0.2249160\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2249160\n",
      "Measure Epoch 1202, train\n",
      " similarity:0.0042062\n",
      " penlog:-96.2963597\n",
      "Metrics Epoch 1202, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.1739130\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:30.2608696\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.6300000\n",
      " batch_node_degree:2.8913043\n",
      "Logits [20.167280197143555, 2.3658599853515625, 65.96215057373047]\n",
      "Epoch duration: 2.173065185546875\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1202\n",
      "Epoch: 1203\n",
      "FGW torch.Size([29508, 5]) 7.53492713556625e-05\n",
      "Penalty params: tau=0.57461 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1203 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1203, train\n",
      " fgw:0.2316911\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2316911\n",
      "Measure Epoch 1203, train\n",
      " similarity:0.0054493\n",
      " penlog:-96.6351092\n",
      "Metrics Epoch 1203, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:31.9130435\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.4000000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:3.2900000\n",
      " batch_node_degree:3.0086957\n",
      "Logits [20.207412719726562, 2.4116790294647217, 66.06974792480469]\n",
      "Epoch duration: 2.7489051818847656\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1203\n",
      "Epoch: 1204\n",
      "FGW torch.Size([29508, 5]) 6.822019349783659e-05\n",
      "Penalty params: tau=0.57435 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1204 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1204, train\n",
      " fgw:0.2174625\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2174625\n",
      "Measure Epoch 1204, train\n",
      " similarity:0.0287319\n",
      " penlog:-90.1249181\n",
      "Metrics Epoch 1204, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8800000\n",
      " batch_invalid_valency_nodes:26.4347826\n",
      " batch_nodes_0degree:1.8000000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.4900000\n",
      " batch_node_degree:2.6582609\n",
      "Logits [20.297494888305664, 2.45513653755188, 66.331787109375]\n",
      "Epoch duration: 2.5287013053894043\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1205\n",
      "FGW torch.Size([29508, 5]) 7.275540701812133e-05\n",
      "Penalty params: tau=0.57408 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1205 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1205, train\n",
      " fgw:0.2141871\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2141871\n",
      "Measure Epoch 1205, train\n",
      " similarity:0.0211765\n",
      " penlog:-96.5104091\n",
      "Metrics Epoch 1205, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:28.4347826\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.5200000\n",
      " batch_node_degree:2.8495652\n",
      "Logits [20.29451560974121, 2.4784040451049805, 66.49937438964844]\n",
      "Epoch duration: 2.4273862838745117\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1205\n",
      "Epoch: 1206\n",
      "FGW torch.Size([29508, 5]) 7.40101677365601e-05\n",
      "Penalty params: tau=0.57382 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1206 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1206, train\n",
      " fgw:0.2123199\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2123199\n",
      "Measure Epoch 1206, train\n",
      " similarity:0.0000000\n",
      " penlog:-100.0000000\n",
      "Metrics Epoch 1206, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:0.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:30.8695652\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:1.3000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.9100000\n",
      " batch_node_degree:2.9678261\n",
      "Logits [20.320571899414062, 2.499166965484619, 67.18598175048828]\n",
      "Epoch duration: 2.6895530223846436\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1206\n",
      "Epoch: 1207\n",
      "FGW torch.Size([29508, 5]) 6.703920371364802e-05\n",
      "Penalty params: tau=0.57356 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1207 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1207, train\n",
      " fgw:0.2094348\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2094348\n",
      "Measure Epoch 1207, train\n",
      " similarity:0.0176509\n",
      " penlog:-84.3505948\n",
      "Metrics Epoch 1207, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:4.6800000\n",
      " batch_invalid_valency_nodes:22.4347826\n",
      " batch_nodes_0degree:1.9600000\n",
      " batch_nodes_7plus_degree:0.5600000\n",
      " invalid_euler_toofew:62.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-1.8000000\n",
      " batch_node_degree:2.3617391\n",
      "Logits [20.407316207885742, 2.5273725986480713, 67.98146057128906]\n",
      "Epoch duration: 2.2476553916931152\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1207\n",
      "Epoch: 1208\n",
      "FGW torch.Size([29508, 5]) 7.594206545036286e-05\n",
      "Penalty params: tau=0.57329 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1208 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1208, train\n",
      " fgw:0.2229902\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2229902\n",
      "Measure Epoch 1208, train\n",
      " similarity:0.0000000\n",
      " penlog:-100.0000000\n",
      "Metrics Epoch 1208, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:0.0000000\n",
      " batch_connected_components:2.5000000\n",
      " batch_invalid_valency_nodes:34.2608696\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:1.7400000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:40.0000000\n",
      " avg_euler_error:4.8800000\n",
      " batch_node_degree:3.1347826\n",
      "Logits [20.518634796142578, 2.5222997665405273, 68.46443939208984]\n",
      "Epoch duration: 2.5265462398529053\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1208\n",
      "Epoch: 1209\n",
      "FGW torch.Size([29508, 5]) 6.921185558894649e-05\n",
      "Penalty params: tau=0.57303 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1209 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1209, train\n",
      " fgw:0.2235405\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2235405\n",
      "Measure Epoch 1209, train\n",
      " similarity:0.0088380\n",
      " penlog:-94.1879461\n",
      "Metrics Epoch 1209, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:4.0200000\n",
      " batch_invalid_valency_nodes:24.0000000\n",
      " batch_nodes_0degree:2.0400000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:54.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.8600000\n",
      " batch_node_degree:2.4678261\n",
      "Logits [20.447874069213867, 2.4812543392181396, 67.7963638305664]\n",
      "Epoch duration: 2.6600911617279053\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1209\n",
      "Epoch: 1210\n",
      "FGW torch.Size([29508, 5]) 7.373063999693841e-05\n",
      "Penalty params: tau=0.57276 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1210 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1210, train\n",
      " fgw:0.2144442\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2144442\n",
      "Measure Epoch 1210, train\n",
      " similarity:0.0069563\n",
      " penlog:-94.2199267\n",
      "Metrics Epoch 1210, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.4347826\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:30.3478261\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:1.2800000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.2500000\n",
      " batch_node_degree:2.9773913\n",
      "Logits [20.26891326904297, 2.4255964756011963, 66.7093276977539]\n",
      "Epoch duration: 2.438288688659668\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1210\n",
      "Epoch: 1211\n",
      "FGW torch.Size([29508, 5]) 7.432044367305934e-05\n",
      "Penalty params: tau=0.57250 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1211 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1211, train\n",
      " fgw:0.2187708\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2187708\n",
      "Measure Epoch 1211, train\n",
      " similarity:0.0057204\n",
      " penlog:-94.0683226\n",
      "Metrics Epoch 1211, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:28.5217391\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.3200000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:3.9800000\n",
      " batch_node_degree:3.0269565\n",
      "Logits [20.0631160736084, 2.3638012409210205, 65.53213500976562]\n",
      "Epoch duration: 2.5558557510375977\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1211\n",
      "Epoch: 1212\n",
      "FGW torch.Size([29508, 5]) 7.359801384154707e-05\n",
      "Penalty params: tau=0.57224 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1212 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1212, train\n",
      " fgw:0.2312175\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2312175\n",
      "Measure Epoch 1212, train\n",
      " similarity:0.0062593\n",
      " penlog:-95.9518770\n",
      "Metrics Epoch 1212, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.7600000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:0.7000000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.3500000\n",
      " batch_node_degree:2.6426087\n",
      "Logits [19.85164451599121, 2.328632116317749, 64.55895233154297]\n",
      "Epoch duration: 2.421908140182495\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1212\n",
      "Epoch: 1213\n",
      "FGW torch.Size([29508, 5]) 7.528946298407391e-05\n",
      "Penalty params: tau=0.57197 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1213 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1213, train\n",
      " fgw:0.2226808\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2226808\n",
      "Measure Epoch 1213, train\n",
      " similarity:0.0056699\n",
      " penlog:-94.1621546\n",
      "Metrics Epoch 1213, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.4347826\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:27.9130435\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:1.3400000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.7500000\n",
      " batch_node_degree:2.9286957\n",
      "Logits [19.8283634185791, 2.3632781505584717, 64.78611755371094]\n",
      "Epoch duration: 2.3967673778533936\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1214\n",
      "FGW torch.Size([29508, 5]) 7.601454126415774e-05\n",
      "Penalty params: tau=0.57171 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1214 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1214, train\n",
      " fgw:0.2178261\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2178261\n",
      "Measure Epoch 1214, train\n",
      " similarity:0.0029630\n",
      " penlog:-98.0271653\n",
      "Metrics Epoch 1214, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.8200000\n",
      " batch_invalid_valency_nodes:28.5217391\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.8500000\n",
      " batch_node_degree:2.9078261\n",
      "Logits [19.926475524902344, 2.408231496810913, 65.4913558959961]\n",
      "Epoch duration: 2.2536232471466064\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1214\n",
      "Epoch: 1215\n",
      "FGW torch.Size([29508, 5]) 7.236698002088815e-05\n",
      "Penalty params: tau=0.57145 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1215 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1215, train\n",
      " fgw:0.2170764\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2170764\n",
      "Measure Epoch 1215, train\n",
      " similarity:0.0113485\n",
      " penlog:-94.2097964\n",
      "Metrics Epoch 1215, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:25.9130435\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.5900000\n",
      " batch_node_degree:2.7443478\n",
      "Logits [19.94492530822754, 2.4440999031066895, 65.7528076171875]\n",
      "Epoch duration: 2.455465078353882\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1215\n",
      "Epoch: 1216\n",
      "FGW torch.Size([29508, 5]) 7.268501212820411e-05\n",
      "Penalty params: tau=0.57118 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1216 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1216, train\n",
      " fgw:0.2090099\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2090099\n",
      "Measure Epoch 1216, train\n",
      " similarity:0.0290581\n",
      " penlog:-92.3376553\n",
      "Metrics Epoch 1216, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0000000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.6000000\n",
      " batch_node_degree:2.7460870\n",
      "Logits [19.845245361328125, 2.442305564880371, 65.6362075805664]\n",
      "Epoch duration: 2.473376989364624\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1216\n",
      "Epoch: 1217\n",
      "FGW torch.Size([29508, 5]) 7.298158743651584e-05\n",
      "Penalty params: tau=0.57092 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1217 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1217, train\n",
      " fgw:0.2018812\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2018812\n",
      "Measure Epoch 1217, train\n",
      " similarity:0.0050648\n",
      " penlog:-96.1221190\n",
      "Metrics Epoch 1217, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.2200000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:1.4200000\n",
      " batch_nodes_7plus_degree:1.3800000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.2600000\n",
      " batch_node_degree:2.8530435\n",
      "Logits [19.76077651977539, 2.4333581924438477, 65.4878158569336]\n",
      "Epoch duration: 2.3168914318084717\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1217\n",
      "Epoch: 1218\n",
      "FGW torch.Size([29508, 5]) 7.015180017333478e-05\n",
      "Penalty params: tau=0.57066 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1218 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1218, train\n",
      " fgw:0.2028051\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2028051\n",
      "Measure Epoch 1218, train\n",
      " similarity:0.0019879\n",
      " penlog:-95.9576766\n",
      "Metrics Epoch 1218, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.6200000\n",
      " batch_invalid_valency_nodes:24.3478261\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.8000000\n",
      " invalid_euler_toofew:42.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.0200000\n",
      " batch_node_degree:2.5747826\n",
      "Logits [19.952476501464844, 2.461027145385742, 66.07611083984375]\n",
      "Epoch duration: 2.560427188873291\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1218\n",
      "Epoch: 1219\n",
      "FGW torch.Size([29508, 5]) 7.27011647541076e-05\n",
      "Penalty params: tau=0.57039 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1219 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1219, train\n",
      " fgw:0.2060323\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2060323\n",
      "Measure Epoch 1219, train\n",
      " similarity:0.0116375\n",
      " penlog:-92.0286687\n",
      "Metrics Epoch 1219, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.4400000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.4900000\n",
      " batch_node_degree:2.8469565\n",
      "Logits [20.190793991088867, 2.4877822399139404, 66.85093688964844]\n",
      "Epoch duration: 2.3277406692504883\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1219\n",
      "Epoch: 1220\n",
      "FGW torch.Size([29508, 5]) 7.082313095452264e-05\n",
      "Penalty params: tau=0.57013 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1220 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1220, train\n",
      " fgw:0.1971252\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1971252\n",
      "Measure Epoch 1220, train\n",
      " similarity:0.0243077\n",
      " penlog:-96.0925454\n",
      "Metrics Epoch 1220, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8600000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.7100000\n",
      " batch_node_degree:2.8486957\n",
      "Logits [20.38346290588379, 2.5127615928649902, 67.36559295654297]\n",
      "Epoch duration: 2.4569759368896484\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1220\n",
      "Epoch: 1221\n",
      "FGW torch.Size([29508, 5]) 6.954614218557253e-05\n",
      "Penalty params: tau=0.56987 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1221 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1221, train\n",
      " fgw:0.2015177\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2015177\n",
      "Measure Epoch 1221, train\n",
      " similarity:0.0244444\n",
      " penlog:-96.0867584\n",
      "Metrics Epoch 1221, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.3600000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.7000000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:0.8800000\n",
      " batch_node_degree:2.6739130\n",
      "Logits [20.431474685668945, 2.5194568634033203, 67.45347595214844]\n",
      "Epoch duration: 2.251291275024414\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1221\n",
      "Epoch: 1222\n",
      "FGW torch.Size([29508, 5]) 7.172214827733114e-05\n",
      "Penalty params: tau=0.56961 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1222 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1222, train\n",
      " fgw:0.2107869\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2107869\n",
      "Measure Epoch 1222, train\n",
      " similarity:0.0227273\n",
      " penlog:-96.0846165\n",
      "Metrics Epoch 1222, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1800000\n",
      " batch_invalid_valency_nodes:26.0869565\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.6300000\n",
      " batch_node_degree:2.7513043\n",
      "Logits [20.394607543945312, 2.5325369834899902, 67.56623077392578]\n",
      "Epoch duration: 2.1789090633392334\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1223\n",
      "FGW torch.Size([29508, 5]) 6.98325238772668e-05\n",
      "Penalty params: tau=0.56935 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1223 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1223, train\n",
      " fgw:0.2157050\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2157050\n",
      "Measure Epoch 1223, train\n",
      " similarity:0.0100228\n",
      " penlog:-90.1839404\n",
      "Metrics Epoch 1223, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.4400000\n",
      " batch_invalid_valency_nodes:25.5652174\n",
      " batch_nodes_0degree:1.7200000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.3800000\n",
      " batch_node_degree:2.6452174\n",
      "Logits [20.299644470214844, 2.512789249420166, 67.32161712646484]\n",
      "Epoch duration: 2.6084842681884766\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1223\n",
      "Epoch: 1224\n",
      "FGW torch.Size([29508, 5]) 7.300846482394263e-05\n",
      "Penalty params: tau=0.56908 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1224 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1224, train\n",
      " fgw:0.2046587\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2046587\n",
      "Measure Epoch 1224, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1224, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.8400000\n",
      " batch_invalid_valency_nodes:27.4782609\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.1600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.7500000\n",
      " batch_node_degree:2.9234783\n",
      "Logits [20.352401733398438, 2.501336097717285, 67.1775131225586]\n",
      "Epoch duration: 2.2729110717773438\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1224\n",
      "Epoch: 1225\n",
      "FGW torch.Size([29508, 5]) 7.13986373739317e-05\n",
      "Penalty params: tau=0.56882 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1225 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1225, train\n",
      " fgw:0.2122029\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2122029\n",
      "Measure Epoch 1225, train\n",
      " similarity:0.0170187\n",
      " penlog:-90.1812444\n",
      "Metrics Epoch 1225, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.0000000\n",
      " batch_invalid_valency_nodes:23.2173913\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:0.6400000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.5800000\n",
      " batch_node_degree:2.7878261\n",
      "Logits [20.372562408447266, 2.494767665863037, 66.71575164794922]\n",
      "Epoch duration: 2.3370704650878906\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1225\n",
      "Epoch: 1226\n",
      "FGW torch.Size([29508, 5]) 7.096448098309338e-05\n",
      "Penalty params: tau=0.56856 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1226 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1226, train\n",
      " fgw:0.2191857\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2191857\n",
      "Measure Epoch 1226, train\n",
      " similarity:0.0303258\n",
      " penlog:-90.1612362\n",
      "Metrics Epoch 1226, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.7800000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:1.7200000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:36.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:0.3600000\n",
      " batch_node_degree:2.6756522\n",
      "Logits [20.232515335083008, 2.4686520099639893, 65.96575927734375]\n",
      "Epoch duration: 2.567331075668335\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1226\n",
      "Epoch: 1227\n",
      "FGW torch.Size([29508, 5]) 7.549794827355072e-05\n",
      "Penalty params: tau=0.56830 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1227 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1227, train\n",
      " fgw:0.2130767\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2130767\n",
      "Measure Epoch 1227, train\n",
      " similarity:0.0222642\n",
      " penlog:-96.1878095\n",
      "Metrics Epoch 1227, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.4347826\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8400000\n",
      " batch_invalid_valency_nodes:32.6086957\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:1.6000000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.2000000\n",
      " batch_node_degree:3.1617391\n",
      "Logits [19.946577072143555, 2.4173331260681152, 65.10050201416016]\n",
      "Epoch duration: 2.2308173179626465\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1227\n",
      "Epoch: 1228\n",
      "FGW torch.Size([29508, 5]) 7.060711504891515e-05\n",
      "Penalty params: tau=0.56804 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1228 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1228, train\n",
      " fgw:0.2116893\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2116893\n",
      "Measure Epoch 1228, train\n",
      " similarity:0.0205882\n",
      " penlog:-96.0455387\n",
      "Metrics Epoch 1228, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:22.4347826\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:0.6400000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.1500000\n",
      " batch_node_degree:2.6026087\n",
      "Logits [19.772130966186523, 2.38394832611084, 64.58011627197266]\n",
      "Epoch duration: 2.315664768218994\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1228\n",
      "Epoch: 1229\n",
      "FGW torch.Size([29508, 5]) 6.942253821762279e-05\n",
      "Penalty params: tau=0.56777 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1229 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1229, train\n",
      " fgw:0.2216039\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2216039\n",
      "Measure Epoch 1229, train\n",
      " similarity:0.0279355\n",
      " penlog:-90.8641079\n",
      "Metrics Epoch 1229, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8600000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.9000000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:40.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.1400000\n",
      " batch_node_degree:2.5295652\n",
      "Logits [19.860536575317383, 2.3974149227142334, 64.90796661376953]\n",
      "Epoch duration: 2.508808135986328\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1229\n",
      "Epoch: 1230\n",
      "FGW torch.Size([29508, 5]) 7.672047649975866e-05\n",
      "Penalty params: tau=0.56751 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1230 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1230, train\n",
      " fgw:0.2220517\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2220517\n",
      "Measure Epoch 1230, train\n",
      " similarity:0.0242857\n",
      " penlog:-96.1941369\n",
      "Metrics Epoch 1230, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.0000000\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:34.0869565\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:1.7600000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.5000000\n",
      " batch_node_degree:3.2382609\n",
      "Logits [19.96441078186035, 2.405790090560913, 65.25019836425781]\n",
      "Epoch duration: 2.415985345840454\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1230\n",
      "Epoch: 1231\n",
      "FGW torch.Size([29508, 5]) 6.911200034664944e-05\n",
      "Penalty params: tau=0.56725 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1231 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1231, train\n",
      " fgw:0.2166795\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2166795\n",
      "Measure Epoch 1231, train\n",
      " similarity:0.0264359\n",
      " penlog:-94.1669656\n",
      "Metrics Epoch 1231, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.6400000\n",
      " batch_invalid_valency_nodes:22.6086957\n",
      " batch_nodes_0degree:1.5000000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.2900000\n",
      " batch_node_degree:2.5913043\n",
      "Logits [20.159706115722656, 2.4249796867370605, 65.75639343261719]\n",
      "Epoch duration: 2.3790202140808105\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1232\n",
      "FGW torch.Size([29508, 5]) 7.015980372671038e-05\n",
      "Penalty params: tau=0.56699 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1232 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1232, train\n",
      " fgw:0.2004201\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2004201\n",
      "Measure Epoch 1232, train\n",
      " similarity:0.0124498\n",
      " penlog:-90.3314497\n",
      "Metrics Epoch 1232, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.1000000\n",
      " batch_invalid_valency_nodes:24.6086957\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.6800000\n",
      " batch_node_degree:2.6652174\n",
      "Logits [20.290687561035156, 2.4485816955566406, 66.25455474853516]\n",
      "Epoch duration: 2.43808913230896\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1232\n",
      "Epoch: 1233\n",
      "FGW torch.Size([29508, 5]) 7.45613215258345e-05\n",
      "Penalty params: tau=0.56673 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1233 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1233, train\n",
      " fgw:0.2177466\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2177466\n",
      "Measure Epoch 1233, train\n",
      " similarity:0.0233948\n",
      " penlog:-94.2183192\n",
      "Metrics Epoch 1233, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:31.8260870\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.5600000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.9400000\n",
      " batch_node_degree:3.0886957\n",
      "Logits [20.397565841674805, 2.4762394428253174, 66.77072143554688]\n",
      "Epoch duration: 2.6575000286102295\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1233\n",
      "Epoch: 1234\n",
      "FGW torch.Size([29508, 5]) 6.780569674447179e-05\n",
      "Penalty params: tau=0.56647 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1234 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1234, train\n",
      " fgw:0.2057351\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2057351\n",
      "Measure Epoch 1234, train\n",
      " similarity:0.0239538\n",
      " penlog:-94.1351844\n",
      "Metrics Epoch 1234, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:4.1000000\n",
      " batch_invalid_valency_nodes:23.8260870\n",
      " batch_nodes_0degree:1.8200000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:52.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.9300000\n",
      " batch_node_degree:2.4904348\n",
      "Logits [20.3746395111084, 2.4804584980010986, 66.62666320800781]\n",
      "Epoch duration: 2.591815710067749\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1234\n",
      "Epoch: 1235\n",
      "FGW torch.Size([29508, 5]) 7.471787102986127e-05\n",
      "Penalty params: tau=0.56621 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1235 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1235, train\n",
      " fgw:0.2106833\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2106833\n",
      "Measure Epoch 1235, train\n",
      " similarity:0.0223256\n",
      " penlog:-96.1078888\n",
      "Metrics Epoch 1235, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.5600000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:38.0000000\n",
      " avg_euler_error:4.4000000\n",
      " batch_node_degree:3.0208696\n",
      "Logits [20.237686157226562, 2.4583630561828613, 66.0666732788086]\n",
      "Epoch duration: 2.302089214324951\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1235\n",
      "Epoch: 1236\n",
      "FGW torch.Size([29508, 5]) 6.912343087606132e-05\n",
      "Penalty params: tau=0.56595 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1236 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1236, train\n",
      " fgw:0.2147921\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2147921\n",
      "Measure Epoch 1236, train\n",
      " similarity:0.0249973\n",
      " penlog:-90.0178019\n",
      "Metrics Epoch 1236, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.4347826\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8200000\n",
      " batch_invalid_valency_nodes:25.5652174\n",
      " batch_nodes_0degree:2.0000000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.1700000\n",
      " batch_node_degree:2.5460870\n",
      "Logits [20.106245040893555, 2.4377520084381104, 65.5730209350586]\n",
      "Epoch duration: 2.9836361408233643\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1236\n",
      "Epoch: 1237\n",
      "FGW torch.Size([29508, 5]) 7.247453322634101e-05\n",
      "Penalty params: tau=0.56569 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1237 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1237, train\n",
      " fgw:0.2082133\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2082133\n",
      "Measure Epoch 1237, train\n",
      " similarity:0.0219048\n",
      " penlog:-96.0950643\n",
      "Metrics Epoch 1237, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8600000\n",
      " batch_invalid_valency_nodes:29.1304348\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.2600000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.5100000\n",
      " batch_node_degree:3.0147826\n",
      "Logits [19.97056007385254, 2.413276195526123, 65.3053970336914]\n",
      "Epoch duration: 2.200479745864868\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1237\n",
      "Epoch: 1238\n",
      "FGW torch.Size([29508, 5]) 6.961349572520703e-05\n",
      "Penalty params: tau=0.56543 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1238 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1238, train\n",
      " fgw:0.1962200\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1962200\n",
      "Measure Epoch 1238, train\n",
      " similarity:0.0244862\n",
      " penlog:-94.2447408\n",
      "Metrics Epoch 1238, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.7900000\n",
      " batch_node_degree:2.8547826\n",
      "Logits [19.85256576538086, 2.397735595703125, 65.07524871826172]\n",
      "Epoch duration: 2.336545944213867\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1238\n",
      "Epoch: 1239\n",
      "FGW torch.Size([29508, 5]) 7.030120468698442e-05\n",
      "Penalty params: tau=0.56516 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1239 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1239, train\n",
      " fgw:0.2107351\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2107351\n",
      "Measure Epoch 1239, train\n",
      " similarity:0.0233986\n",
      " penlog:-94.1255082\n",
      "Metrics Epoch 1239, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2200000\n",
      " batch_invalid_valency_nodes:24.6086957\n",
      " batch_nodes_0degree:1.5000000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.1600000\n",
      " batch_node_degree:2.6678261\n",
      "Logits [19.709627151489258, 2.371556043624878, 64.8729476928711]\n",
      "Epoch duration: 2.379404306411743\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1239\n",
      "Epoch: 1240\n",
      "FGW torch.Size([29508, 5]) 7.3070521466434e-05\n",
      "Penalty params: tau=0.56490 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1240 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1240, train\n",
      " fgw:0.2156812\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2156812\n",
      "Measure Epoch 1240, train\n",
      " similarity:0.0261199\n",
      " penlog:-94.1927448\n",
      "Metrics Epoch 1240, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:27.4782609\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:3.1100000\n",
      " batch_node_degree:2.9504348\n",
      "Logits [19.641658782958984, 2.348090887069702, 64.94530487060547]\n",
      "Epoch duration: 2.659714698791504\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1241\n",
      "FGW torch.Size([29508, 5]) 7.135332998586819e-05\n",
      "Penalty params: tau=0.56464 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1241 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1241, train\n",
      " fgw:0.2104454\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2104454\n",
      "Measure Epoch 1241, train\n",
      " similarity:0.0259957\n",
      " penlog:-94.1408159\n",
      "Metrics Epoch 1241, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1800000\n",
      " batch_invalid_valency_nodes:23.8260870\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.7000000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.5600000\n",
      " batch_node_degree:2.7304348\n",
      "Logits [19.65235710144043, 2.331792116165161, 65.2325668334961]\n",
      "Epoch duration: 2.306795120239258\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1241\n",
      "Epoch: 1242\n",
      "FGW torch.Size([29508, 5]) 7.19770832802169e-05\n",
      "Penalty params: tau=0.56438 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1242 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1242, train\n",
      " fgw:0.2124117\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2124117\n",
      "Measure Epoch 1242, train\n",
      " similarity:0.0051200\n",
      " penlog:-94.2123915\n",
      "Metrics Epoch 1242, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2200000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.7400000\n",
      " batch_node_degree:2.8313043\n",
      "Logits [19.655065536499023, 2.322117805480957, 65.46710205078125]\n",
      "Epoch duration: 2.4269697666168213\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1242\n",
      "Epoch: 1243\n",
      "FGW torch.Size([29508, 5]) 7.02451216056943e-05\n",
      "Penalty params: tau=0.56412 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1243 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1243, train\n",
      " fgw:0.2054676\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2054676\n",
      "Measure Epoch 1243, train\n",
      " similarity:0.0222222\n",
      " penlog:-96.0710296\n",
      "Metrics Epoch 1243, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.5400000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.3100000\n",
      " batch_node_degree:2.7869565\n",
      "Logits [20.026147842407227, 2.387420415878296, 66.74358367919922]\n",
      "Epoch duration: 2.435776948928833\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1243\n",
      "Epoch: 1244\n",
      "FGW torch.Size([29508, 5]) 7.403177733067423e-05\n",
      "Penalty params: tau=0.56386 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1244 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1244, train\n",
      " fgw:0.2072202\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2072202\n",
      "Measure Epoch 1244, train\n",
      " similarity:0.0245833\n",
      " penlog:-94.2862882\n",
      "Metrics Epoch 1244, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.5200000\n",
      " batch_invalid_valency_nodes:29.6521739\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.4400000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:4.0600000\n",
      " batch_node_degree:3.0373913\n",
      "Logits [20.379209518432617, 2.4745616912841797, 67.95297241210938]\n",
      "Epoch duration: 2.318347930908203\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1244\n",
      "Epoch: 1245\n",
      "FGW torch.Size([29508, 5]) 6.799688708269969e-05\n",
      "Penalty params: tau=0.56361 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1245 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1245, train\n",
      " fgw:0.2156891\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2156891\n",
      "Measure Epoch 1245, train\n",
      " similarity:0.0350249\n",
      " penlog:-82.6829939\n",
      "Metrics Epoch 1245, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:4.1000000\n",
      " batch_invalid_valency_nodes:23.6521739\n",
      " batch_nodes_0degree:1.7600000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:44.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.4600000\n",
      " batch_node_degree:2.4539130\n",
      "Logits [20.507354736328125, 2.4978160858154297, 68.16749572753906]\n",
      "Epoch duration: 2.2827370166778564\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1245\n",
      "Epoch: 1246\n",
      "FGW torch.Size([29508, 5]) 7.456663297489285e-05\n",
      "Penalty params: tau=0.56335 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1246 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1246, train\n",
      " fgw:0.2132742\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2132742\n",
      "Measure Epoch 1246, train\n",
      " similarity:0.0228986\n",
      " penlog:-96.0785680\n",
      "Metrics Epoch 1246, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.3000000\n",
      " batch_invalid_valency_nodes:31.2173913\n",
      " batch_nodes_0degree:0.9800000\n",
      " batch_nodes_7plus_degree:1.7600000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.9300000\n",
      " batch_node_degree:3.1434783\n",
      "Logits [20.613821029663086, 2.5136513710021973, 68.4662857055664]\n",
      "Epoch duration: 2.4056949615478516\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1246\n",
      "Epoch: 1247\n",
      "FGW torch.Size([29508, 5]) 6.766070873709396e-05\n",
      "Penalty params: tau=0.56309 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1247 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1247, train\n",
      " fgw:0.2085458\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2085458\n",
      "Measure Epoch 1247, train\n",
      " similarity:0.0326305\n",
      " penlog:-84.3306142\n",
      "Metrics Epoch 1247, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:4.4600000\n",
      " batch_invalid_valency_nodes:24.4347826\n",
      " batch_nodes_0degree:1.9200000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:52.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-1.1800000\n",
      " batch_node_degree:2.5060870\n",
      "Logits [20.553586959838867, 2.48745059967041, 68.06930541992188]\n",
      "Epoch duration: 2.554048538208008\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1247\n",
      "Epoch: 1248\n",
      "FGW torch.Size([29508, 5]) 7.142347749322653e-05\n",
      "Penalty params: tau=0.56283 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1248 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1248, train\n",
      " fgw:0.2102208\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2102208\n",
      "Measure Epoch 1248, train\n",
      " similarity:0.0212308\n",
      " penlog:-96.3678795\n",
      "Metrics Epoch 1248, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.8100000\n",
      " batch_node_degree:2.8704348\n",
      "Logits [20.53772735595703, 2.4798824787139893, 67.79234313964844]\n",
      "Epoch duration: 2.428096294403076\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1248\n",
      "Epoch: 1249\n",
      "FGW torch.Size([29508, 5]) 6.785630830563605e-05\n",
      "Penalty params: tau=0.56257 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1249 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1249, train\n",
      " fgw:0.1994674\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1994674\n",
      "Measure Epoch 1249, train\n",
      " similarity:0.0280005\n",
      " penlog:-92.4043760\n",
      "Metrics Epoch 1249, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.1800000\n",
      " batch_node_degree:2.7713043\n",
      "Logits [20.579504013061523, 2.4834067821502686, 67.67814636230469]\n",
      "Epoch duration: 2.292571783065796\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1250\n",
      "FGW torch.Size([29508, 5]) 6.80366501910612e-05\n",
      "Penalty params: tau=0.56231 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1250 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1250, train\n",
      " fgw:0.2029917\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2029917\n",
      "Measure Epoch 1250, train\n",
      " similarity:0.0265789\n",
      " penlog:-90.2450225\n",
      "Metrics Epoch 1250, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.5800000\n",
      " batch_invalid_valency_nodes:24.5217391\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.8300000\n",
      " batch_node_degree:2.7191304\n",
      "Logits [20.46112060546875, 2.4603707790374756, 66.99073028564453]\n",
      "Epoch duration: 2.4286746978759766\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1250\n",
      "Epoch: 1251\n",
      "FGW torch.Size([29508, 5]) 7.18037917977199e-05\n",
      "Penalty params: tau=0.56205 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1251 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1251, train\n",
      " fgw:0.2049028\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2049028\n",
      "Measure Epoch 1251, train\n",
      " similarity:0.0209524\n",
      " penlog:-96.1038928\n",
      "Metrics Epoch 1251, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:31.9130435\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:1.5800000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:38.0000000\n",
      " avg_euler_error:4.1500000\n",
      " batch_node_degree:3.1026087\n",
      "Logits [20.326427459716797, 2.4366753101348877, 66.27477264404297]\n",
      "Epoch duration: 2.64392352104187\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1251\n",
      "Epoch: 1252\n",
      "FGW torch.Size([29508, 5]) 6.726030551362783e-05\n",
      "Penalty params: tau=0.56179 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1252 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1252, train\n",
      " fgw:0.2211566\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2211566\n",
      "Measure Epoch 1252, train\n",
      " similarity:0.0270250\n",
      " penlog:-90.0336914\n",
      "Metrics Epoch 1252, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.3000000\n",
      " batch_invalid_valency_nodes:21.3913043\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.9700000\n",
      " batch_node_degree:2.6113043\n",
      "Logits [20.260292053222656, 2.4293134212493896, 65.81535339355469]\n",
      "Epoch duration: 2.644963264465332\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1252\n",
      "Epoch: 1253\n",
      "FGW torch.Size([29508, 5]) 6.985932122915983e-05\n",
      "Penalty params: tau=0.56153 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1253 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1253, train\n",
      " fgw:0.2094860\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2094860\n",
      "Measure Epoch 1253, train\n",
      " similarity:0.0217391\n",
      " penlog:-96.3245121\n",
      "Metrics Epoch 1253, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7000000\n",
      " batch_invalid_valency_nodes:25.9130435\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:1.2600000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.4500000\n",
      " batch_node_degree:2.8347826\n",
      "Logits [20.216543197631836, 2.4106242656707764, 65.51848602294922]\n",
      "Epoch duration: 2.7157628536224365\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1253\n",
      "Epoch: 1254\n",
      "FGW torch.Size([29508, 5]) 7.256742537720129e-05\n",
      "Penalty params: tau=0.56127 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1254 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1254, train\n",
      " fgw:0.2085810\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2085810\n",
      "Measure Epoch 1254, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1254, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.6000000\n",
      " batch_invalid_valency_nodes:32.9565217\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.4400000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:4.0200000\n",
      " batch_node_degree:3.1400000\n",
      "Logits [20.192468643188477, 2.386704683303833, 65.32608032226562]\n",
      "Epoch duration: 2.4823694229125977\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1254\n",
      "Epoch: 1255\n",
      "FGW torch.Size([29508, 5]) 6.614024459850043e-05\n",
      "Penalty params: tau=0.56102 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1255 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1255, train\n",
      " fgw:0.2059576\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2059576\n",
      "Measure Epoch 1255, train\n",
      " similarity:0.0223188\n",
      " penlog:-96.0259750\n",
      "Metrics Epoch 1255, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.6000000\n",
      " batch_invalid_valency_nodes:23.3043478\n",
      " batch_nodes_0degree:1.9600000\n",
      " batch_nodes_7plus_degree:0.6000000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.2600000\n",
      " batch_node_degree:2.4782609\n",
      "Logits [20.221946716308594, 2.389406442642212, 65.37986755371094]\n",
      "Epoch duration: 2.556208610534668\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1255\n",
      "Epoch: 1256\n",
      "FGW torch.Size([29508, 5]) 7.080625800881535e-05\n",
      "Penalty params: tau=0.56076 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1256 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1256, train\n",
      " fgw:0.2062789\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2062789\n",
      "Measure Epoch 1256, train\n",
      " similarity:0.0231099\n",
      " penlog:-94.1248331\n",
      "Metrics Epoch 1256, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7000000\n",
      " batch_invalid_valency_nodes:26.5217391\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.4000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.8000000\n",
      " batch_node_degree:2.9321739\n",
      "Logits [20.32184600830078, 2.4225451946258545, 65.87623596191406]\n",
      "Epoch duration: 2.35082745552063\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1256\n",
      "Epoch: 1257\n",
      "FGW torch.Size([29508, 5]) 6.97039213264361e-05\n",
      "Penalty params: tau=0.56050 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1257 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1257, train\n",
      " fgw:0.1959559\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1959559\n",
      "Measure Epoch 1257, train\n",
      " similarity:0.0307619\n",
      " penlog:-92.4065502\n",
      "Metrics Epoch 1257, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:29.7391304\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:1.2600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.7100000\n",
      " batch_node_degree:2.8721739\n",
      "Logits [20.36933135986328, 2.439617872238159, 66.2158203125]\n",
      "Epoch duration: 2.520400047302246\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1257\n",
      "Epoch: 1258\n",
      "FGW torch.Size([29508, 5]) 6.678975478280336e-05\n",
      "Penalty params: tau=0.56024 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1258 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1258, train\n",
      " fgw:0.1978340\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1978340\n",
      "Measure Epoch 1258, train\n",
      " similarity:0.0314271\n",
      " penlog:-86.3389210\n",
      "Metrics Epoch 1258, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.7000000\n",
      " batch_invalid_valency_nodes:23.2173913\n",
      " batch_nodes_0degree:1.5000000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.2300000\n",
      " batch_node_degree:2.6069565\n",
      "Logits [20.386323928833008, 2.4452826976776123, 66.26897430419922]\n",
      "Epoch duration: 2.9165751934051514\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1259\n",
      "FGW torch.Size([29508, 5]) 7.303867459995672e-05\n",
      "Penalty params: tau=0.55998 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1259 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1259, train\n",
      " fgw:0.1948073\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1948073\n",
      "Measure Epoch 1259, train\n",
      " similarity:0.0239355\n",
      " penlog:-94.1649533\n",
      "Metrics Epoch 1259, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.2400000\n",
      " batch_invalid_valency_nodes:28.7826087\n",
      " batch_nodes_0degree:0.9200000\n",
      " batch_nodes_7plus_degree:1.6000000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:44.0000000\n",
      " avg_euler_error:5.6400000\n",
      " batch_node_degree:3.1156522\n",
      "Logits [20.327007293701172, 2.4304213523864746, 66.20709991455078]\n",
      "Epoch duration: 2.351026773452759\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1259\n",
      "Epoch: 1260\n",
      "FGW torch.Size([29508, 5]) 6.574996950803325e-05\n",
      "Penalty params: tau=0.55973 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1260 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1260, train\n",
      " fgw:0.2057522\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2057522\n",
      "Measure Epoch 1260, train\n",
      " similarity:0.0270781\n",
      " penlog:-90.1517848\n",
      "Metrics Epoch 1260, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:4.2800000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:2.0200000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:46.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-0.8600000\n",
      " batch_node_degree:2.5582609\n",
      "Logits [20.316831588745117, 2.415064573287964, 65.96243286132812]\n",
      "Epoch duration: 2.582214593887329\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1260\n",
      "Epoch: 1261\n",
      "FGW torch.Size([29508, 5]) 7.206221198430285e-05\n",
      "Penalty params: tau=0.55947 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1261 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1261, train\n",
      " fgw:0.2111139\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2111139\n",
      "Measure Epoch 1261, train\n",
      " similarity:0.0228519\n",
      " penlog:-94.1012663\n",
      "Metrics Epoch 1261, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8400000\n",
      " batch_invalid_valency_nodes:29.3043478\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:1.5200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:3.4800000\n",
      " batch_node_degree:3.0547826\n",
      "Logits [20.31561851501465, 2.4222092628479004, 65.9716796875]\n",
      "Epoch duration: 2.353184700012207\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1261\n",
      "Epoch: 1262\n",
      "FGW torch.Size([29508, 5]) 7.108483259798959e-05\n",
      "Penalty params: tau=0.55921 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1262 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1262, train\n",
      " fgw:0.2156673\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2156673\n",
      "Measure Epoch 1262, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1262, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.4400000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.2600000\n",
      " batch_node_degree:2.8773913\n",
      "Logits [20.322694778442383, 2.4339559078216553, 65.94219970703125]\n",
      "Epoch duration: 2.368593215942383\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1262\n",
      "Epoch: 1263\n",
      "FGW torch.Size([29508, 5]) 6.660236249445006e-05\n",
      "Penalty params: tau=0.55895 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1263 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1263, train\n",
      " fgw:0.2201879\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2201879\n",
      "Measure Epoch 1263, train\n",
      " similarity:0.0367569\n",
      " penlog:-76.3763180\n",
      "Metrics Epoch 1263, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:24.0000000\n",
      " batch_connected_components:4.3400000\n",
      " batch_invalid_valency_nodes:22.7826087\n",
      " batch_nodes_0degree:2.2800000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:56.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-1.7800000\n",
      " batch_node_degree:2.3652174\n",
      "Logits [20.33425521850586, 2.4470133781433105, 65.88809967041016]\n",
      "Epoch duration: 2.6907618045806885\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1263\n",
      "Epoch: 1264\n",
      "FGW torch.Size([29508, 5]) 7.719051791355014e-05\n",
      "Penalty params: tau=0.55869 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1264 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1264, train\n",
      " fgw:0.2082204\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2082204\n",
      "Measure Epoch 1264, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1264, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.4800000\n",
      " batch_invalid_valency_nodes:35.3043478\n",
      " batch_nodes_0degree:1.0000000\n",
      " batch_nodes_7plus_degree:2.2200000\n",
      " invalid_euler_toofew:0.0000000\n",
      " invalid_euler_toomany:48.0000000\n",
      " avg_euler_error:6.2200000\n",
      " batch_node_degree:3.3878261\n",
      "Logits [20.272680282592773, 2.442439556121826, 65.85797119140625]\n",
      "Epoch duration: 2.2177696228027344\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1264\n",
      "Epoch: 1265\n",
      "FGW torch.Size([29508, 5]) 6.599171319976449e-05\n",
      "Penalty params: tau=0.55844 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1265 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1265, train\n",
      " fgw:0.2019685\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2019685\n",
      "Measure Epoch 1265, train\n",
      " similarity:0.0353271\n",
      " penlog:-86.1708779\n",
      "Metrics Epoch 1265, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:4.1600000\n",
      " batch_invalid_valency_nodes:20.6956522\n",
      " batch_nodes_0degree:1.8400000\n",
      " batch_nodes_7plus_degree:0.4200000\n",
      " invalid_euler_toofew:48.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-1.0800000\n",
      " batch_node_degree:2.3617391\n",
      "Logits [20.293254852294922, 2.4359781742095947, 65.8533935546875]\n",
      "Epoch duration: 2.3499948978424072\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1265\n",
      "Epoch: 1266\n",
      "FGW torch.Size([29508, 5]) 7.126577838789672e-05\n",
      "Penalty params: tau=0.55818 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1266 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1266, train\n",
      " fgw:0.2079585\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2079585\n",
      "Measure Epoch 1266, train\n",
      " similarity:0.0259796\n",
      " penlog:-94.2546377\n",
      "Metrics Epoch 1266, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8600000\n",
      " batch_invalid_valency_nodes:24.9565217\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.4900000\n",
      " batch_node_degree:2.8208696\n",
      "Logits [20.352275848388672, 2.4416253566741943, 66.28751373291016]\n",
      "Epoch duration: 2.36228346824646\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1266\n",
      "Epoch: 1267\n",
      "FGW torch.Size([29508, 5]) 7.409082900267094e-05\n",
      "Penalty params: tau=0.55792 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1267 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1267, train\n",
      " fgw:0.2083826\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2083826\n",
      "Measure Epoch 1267, train\n",
      " similarity:0.0257038\n",
      " penlog:-92.3625020\n",
      "Metrics Epoch 1267, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:31.5652174\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:1.8800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.7000000\n",
      " batch_node_degree:3.1773913\n",
      "Logits [20.444137573242188, 2.480560779571533, 66.73004150390625]\n",
      "Epoch duration: 2.4729225635528564\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1268\n",
      "FGW torch.Size([29508, 5]) 6.31688890280202e-05\n",
      "Penalty params: tau=0.55767 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1268 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1268, train\n",
      " fgw:0.2024031\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2024031\n",
      "Measure Epoch 1268, train\n",
      " similarity:0.0367664\n",
      " penlog:-82.0808807\n",
      "Metrics Epoch 1268, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:4.5200000\n",
      " batch_invalid_valency_nodes:22.1739130\n",
      " batch_nodes_0degree:2.2000000\n",
      " batch_nodes_7plus_degree:0.4400000\n",
      " invalid_euler_toofew:64.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-2.1500000\n",
      " batch_node_degree:2.2660870\n",
      "Logits [20.474611282348633, 2.5061392784118652, 66.73600006103516]\n",
      "Epoch duration: 2.3736343383789062\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1268\n",
      "Epoch: 1269\n",
      "FGW torch.Size([29508, 5]) 7.36851361580193e-05\n",
      "Penalty params: tau=0.55741 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1269 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1269, train\n",
      " fgw:0.2153510\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2153510\n",
      "Measure Epoch 1269, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1269, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.2400000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:0.8600000\n",
      " batch_nodes_7plus_degree:1.3200000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:48.0000000\n",
      " avg_euler_error:5.5300000\n",
      " batch_node_degree:3.1069565\n",
      "Logits [20.447769165039062, 2.5197184085845947, 66.66984558105469]\n",
      "Epoch duration: 2.4903225898742676\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1269\n",
      "Epoch: 1270\n",
      "FGW torch.Size([29508, 5]) 6.811259663663805e-05\n",
      "Penalty params: tau=0.55715 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1270 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1270, train\n",
      " fgw:0.2073905\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2073905\n",
      "Measure Epoch 1270, train\n",
      " similarity:0.0249976\n",
      " penlog:-92.2936496\n",
      "Metrics Epoch 1270, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.9000000\n",
      " batch_invalid_valency_nodes:28.1739130\n",
      " batch_nodes_0degree:1.9600000\n",
      " batch_nodes_7plus_degree:1.2200000\n",
      " invalid_euler_toofew:36.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:-0.4100000\n",
      " batch_node_degree:2.7252174\n",
      "Logits [20.358192443847656, 2.510357618331909, 66.17083740234375]\n",
      "Epoch duration: 2.4251480102539062\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1270\n",
      "Epoch: 1271\n",
      "FGW torch.Size([29508, 5]) 6.696813215967268e-05\n",
      "Penalty params: tau=0.55690 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1271 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1271, train\n",
      " fgw:0.1931887\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1931887\n",
      "Measure Epoch 1271, train\n",
      " similarity:0.0310997\n",
      " penlog:-92.3332350\n",
      "Metrics Epoch 1271, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:26.3478261\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.1800000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.1000000\n",
      " batch_node_degree:2.8573913\n",
      "Logits [20.206947326660156, 2.4941794872283936, 65.77565002441406]\n",
      "Epoch duration: 2.2319648265838623\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1271\n",
      "Epoch: 1272\n",
      "FGW torch.Size([29508, 5]) 7.34076602384448e-05\n",
      "Penalty params: tau=0.55664 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1272 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1272, train\n",
      " fgw:0.2127004\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2127004\n",
      "Measure Epoch 1272, train\n",
      " similarity:0.0226667\n",
      " penlog:-96.1946760\n",
      "Metrics Epoch 1272, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.3000000\n",
      " batch_invalid_valency_nodes:28.6956522\n",
      " batch_nodes_0degree:0.9000000\n",
      " batch_nodes_7plus_degree:1.1600000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:48.0000000\n",
      " avg_euler_error:5.5300000\n",
      " batch_node_degree:3.0547826\n",
      "Logits [20.024309158325195, 2.4661595821380615, 65.20781707763672]\n",
      "Epoch duration: 2.4085936546325684\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1272\n",
      "Epoch: 1273\n",
      "FGW torch.Size([29508, 5]) 6.391241186065599e-05\n",
      "Penalty params: tau=0.55638 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1273 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1273, train\n",
      " fgw:0.1981549\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1981549\n",
      "Measure Epoch 1273, train\n",
      " similarity:0.0284346\n",
      " penlog:-90.0500968\n",
      "Metrics Epoch 1273, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:4.4400000\n",
      " batch_invalid_valency_nodes:24.4347826\n",
      " batch_nodes_0degree:2.2200000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:64.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-2.1700000\n",
      " batch_node_degree:2.3652174\n",
      "Logits [19.844486236572266, 2.4264121055603027, 64.3413314819336]\n",
      "Epoch duration: 2.449927806854248\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1273\n",
      "Epoch: 1274\n",
      "FGW torch.Size([29508, 5]) 7.306965562747791e-05\n",
      "Penalty params: tau=0.55613 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1274 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1274, train\n",
      " fgw:0.2016077\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2016077\n",
      "Measure Epoch 1274, train\n",
      " similarity:0.0255358\n",
      " penlog:-94.1885094\n",
      "Metrics Epoch 1274, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:32.5217391\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:1.8600000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.8400000\n",
      " batch_node_degree:3.1669565\n",
      "Logits [19.89019012451172, 2.4506168365478516, 64.96592712402344]\n",
      "Epoch duration: 2.885528326034546\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1274\n",
      "Epoch: 1275\n",
      "FGW torch.Size([29508, 5]) 6.693258910672739e-05\n",
      "Penalty params: tau=0.55587 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1275 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1275, train\n",
      " fgw:0.1966922\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1966922\n",
      "Measure Epoch 1275, train\n",
      " similarity:0.0276729\n",
      " penlog:-90.4928309\n",
      "Metrics Epoch 1275, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.2600000\n",
      " batch_invalid_valency_nodes:24.8695652\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.6400000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.4900000\n",
      " batch_node_degree:2.6391304\n",
      "Logits [20.00836944580078, 2.46308970451355, 65.37882232666016]\n",
      "Epoch duration: 2.750101089477539\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1275\n",
      "Epoch: 1276\n",
      "FGW torch.Size([29508, 5]) 6.483064498752356e-05\n",
      "Penalty params: tau=0.55562 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1276 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1276, train\n",
      " fgw:0.1957998\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1957998\n",
      "Measure Epoch 1276, train\n",
      " similarity:0.0273040\n",
      " penlog:-90.1376435\n",
      "Metrics Epoch 1276, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.5600000\n",
      " batch_invalid_valency_nodes:22.4347826\n",
      " batch_nodes_0degree:1.6200000\n",
      " batch_nodes_7plus_degree:0.5800000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.1500000\n",
      " batch_node_degree:2.5295652\n",
      "Logits [19.947914123535156, 2.449880361557007, 65.16140747070312]\n",
      "Epoch duration: 2.300475835800171\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1277\n",
      "FGW torch.Size([29508, 5]) 7.174904749263078e-05\n",
      "Penalty params: tau=0.55536 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1277 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1277, train\n",
      " fgw:0.1909207\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1909207\n",
      "Measure Epoch 1277, train\n",
      " similarity:0.0237711\n",
      " penlog:-94.2034210\n",
      "Metrics Epoch 1277, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.2600000\n",
      " batch_invalid_valency_nodes:32.6086957\n",
      " batch_nodes_0degree:1.0200000\n",
      " batch_nodes_7plus_degree:1.7600000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.6000000\n",
      " batch_node_degree:3.2321739\n",
      "Logits [19.880794525146484, 2.435316324234009, 64.96971893310547]\n",
      "Epoch duration: 2.3814852237701416\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1277\n",
      "Epoch: 1278\n",
      "FGW torch.Size([29508, 5]) 6.651089643128216e-05\n",
      "Penalty params: tau=0.55510 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1278 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1278, train\n",
      " fgw:0.1981554\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1981554\n",
      "Measure Epoch 1278, train\n",
      " similarity:0.0275111\n",
      " penlog:-88.2322221\n",
      "Metrics Epoch 1278, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.4000000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.7100000\n",
      " batch_node_degree:2.7886957\n",
      "Logits [19.68603515625, 2.386259078979492, 64.2570571899414]\n",
      "Epoch duration: 2.7751569747924805\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1278\n",
      "Epoch: 1279\n",
      "FGW torch.Size([29508, 5]) 6.629219569731504e-05\n",
      "Penalty params: tau=0.55485 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1279 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1279, train\n",
      " fgw:0.1995265\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1995265\n",
      "Measure Epoch 1279, train\n",
      " similarity:0.0241392\n",
      " penlog:-94.1078956\n",
      "Metrics Epoch 1279, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2600000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.4900000\n",
      " batch_node_degree:2.6808696\n",
      "Logits [19.476743698120117, 2.3488008975982666, 63.53791427612305]\n",
      "Epoch duration: 3.4997148513793945\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1279\n",
      "Epoch: 1280\n",
      "FGW torch.Size([29508, 5]) 7.065522368066013e-05\n",
      "Penalty params: tau=0.55459 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1280 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1280, train\n",
      " fgw:0.2015093\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2015093\n",
      "Measure Epoch 1280, train\n",
      " similarity:0.0247619\n",
      " penlog:-96.2173442\n",
      "Metrics Epoch 1280, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:26.6086957\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.4900000\n",
      " batch_node_degree:2.8426087\n",
      "Logits [19.649425506591797, 2.3968162536621094, 64.67947387695312]\n",
      "Epoch duration: 2.872882604598999\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1280\n",
      "Epoch: 1281\n",
      "FGW torch.Size([29508, 5]) 6.796560774091631e-05\n",
      "Penalty params: tau=0.55434 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1281 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1281, train\n",
      " fgw:0.2002743\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2002743\n",
      "Measure Epoch 1281, train\n",
      " similarity:0.0272971\n",
      " penlog:-92.1942807\n",
      "Metrics Epoch 1281, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.7400000\n",
      " batch_invalid_valency_nodes:24.9565217\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.3200000\n",
      " batch_node_degree:2.6973913\n",
      "Logits [19.71773338317871, 2.4379000663757324, 65.3359375]\n",
      "Epoch duration: 2.5508580207824707\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1281\n",
      "Epoch: 1282\n",
      "FGW torch.Size([29508, 5]) 6.816375389462337e-05\n",
      "Penalty params: tau=0.55408 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1282 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1282, train\n",
      " fgw:0.2013439\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2013439\n",
      "Measure Epoch 1282, train\n",
      " similarity:0.0247619\n",
      " penlog:-96.1289488\n",
      "Metrics Epoch 1282, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.6000000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.3500000\n",
      " batch_node_degree:2.7547826\n",
      "Logits [19.659685134887695, 2.4314191341400146, 65.35974884033203]\n",
      "Epoch duration: 2.4991774559020996\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1282\n",
      "Epoch: 1283\n",
      "FGW torch.Size([29508, 5]) 6.84134938637726e-05\n",
      "Penalty params: tau=0.55383 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1283 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1283, train\n",
      " fgw:0.1925557\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1925557\n",
      "Measure Epoch 1283, train\n",
      " similarity:0.0273956\n",
      " penlog:-92.1476184\n",
      "Metrics Epoch 1283, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.1800000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.4000000\n",
      " batch_node_degree:2.7739130\n",
      "Logits [19.57905387878418, 2.440584897994995, 65.3935546875]\n",
      "Epoch duration: 2.6472556591033936\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1283\n",
      "Epoch: 1284\n",
      "FGW torch.Size([29508, 5]) 6.941801257198676e-05\n",
      "Penalty params: tau=0.55357 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1284 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1284, train\n",
      " fgw:0.1999374\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1999374\n",
      "Measure Epoch 1284, train\n",
      " similarity:0.0253571\n",
      " penlog:-91.9966569\n",
      "Metrics Epoch 1284, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.3800000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.6800000\n",
      " batch_node_degree:2.7791304\n",
      "Logits [19.3614501953125, 2.409118890762329, 64.98907470703125]\n",
      "Epoch duration: 2.336840867996216\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1284\n",
      "Epoch: 1285\n",
      "FGW torch.Size([29508, 5]) 6.985654181335121e-05\n",
      "Penalty params: tau=0.55332 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1285 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1285, train\n",
      " fgw:0.1992922\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1992922\n",
      "Measure Epoch 1285, train\n",
      " similarity:0.0213889\n",
      " penlog:-96.0638509\n",
      "Metrics Epoch 1285, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8800000\n",
      " batch_invalid_valency_nodes:27.6521739\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.1100000\n",
      " batch_node_degree:2.8704348\n",
      "Logits [19.572660446166992, 2.460540771484375, 65.86307525634766]\n",
      "Epoch duration: 2.4023683071136475\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1286\n",
      "FGW torch.Size([29508, 5]) 6.952562398510054e-05\n",
      "Penalty params: tau=0.55306 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1286 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1286, train\n",
      " fgw:0.2007367\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2007367\n",
      "Measure Epoch 1286, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1286, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:25.5652174\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.4600000\n",
      " batch_node_degree:2.8295652\n",
      "Logits [19.69927978515625, 2.4959192276000977, 66.1929702758789]\n",
      "Epoch duration: 2.1263303756713867\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1286\n",
      "Epoch: 1287\n",
      "FGW torch.Size([29508, 5]) 6.820685666752979e-05\n",
      "Penalty params: tau=0.55281 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1287 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1287, train\n",
      " fgw:0.2100863\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2100863\n",
      "Measure Epoch 1287, train\n",
      " similarity:0.0273026\n",
      " penlog:-88.4613637\n",
      "Metrics Epoch 1287, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.5000000\n",
      " batch_invalid_valency_nodes:23.0434783\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.5600000\n",
      " batch_node_degree:2.5930435\n",
      "Logits [19.741878509521484, 2.497392416000366, 66.28678131103516]\n",
      "Epoch duration: 2.4445371627807617\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1287\n",
      "Epoch: 1288\n",
      "FGW torch.Size([29508, 5]) 6.883420428493991e-05\n",
      "Penalty params: tau=0.55255 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1288 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1288, train\n",
      " fgw:0.2004108\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2004108\n",
      "Measure Epoch 1288, train\n",
      " similarity:0.0248032\n",
      " penlog:-92.1627943\n",
      "Metrics Epoch 1288, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:25.8260870\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.6100000\n",
      " batch_node_degree:2.7930435\n",
      "Logits [19.789215087890625, 2.497532606124878, 66.39712524414062]\n",
      "Epoch duration: 2.2800025939941406\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1288\n",
      "Epoch: 1289\n",
      "FGW torch.Size([29508, 5]) 6.75215560477227e-05\n",
      "Penalty params: tau=0.55230 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1289 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1289, train\n",
      " fgw:0.1944185\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1944185\n",
      "Measure Epoch 1289, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1289, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:25.4782609\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.6600000\n",
      " batch_node_degree:2.7582609\n",
      "Logits [19.699535369873047, 2.458621025085449, 65.97782897949219]\n",
      "Epoch duration: 2.369011402130127\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1289\n",
      "Epoch: 1290\n",
      "FGW torch.Size([29508, 5]) 6.868552736705169e-05\n",
      "Penalty params: tau=0.55204 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1290 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1290, train\n",
      " fgw:0.2002935\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2002935\n",
      "Measure Epoch 1290, train\n",
      " similarity:0.0232401\n",
      " penlog:-94.2791780\n",
      "Metrics Epoch 1290, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:24.9565217\n",
      " batch_nodes_0degree:1.5000000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.2100000\n",
      " batch_node_degree:2.6808696\n",
      "Logits [19.705121994018555, 2.433832883834839, 65.57122802734375]\n",
      "Epoch duration: 2.5456557273864746\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1290\n",
      "Epoch: 1291\n",
      "FGW torch.Size([29508, 5]) 6.892989040352404e-05\n",
      "Penalty params: tau=0.55179 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1291 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1291, train\n",
      " fgw:0.1952806\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1952806\n",
      "Measure Epoch 1291, train\n",
      " similarity:0.0263081\n",
      " penlog:-92.2040802\n",
      "Metrics Epoch 1291, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.2800000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.7000000\n",
      " batch_node_degree:2.7895652\n",
      "Logits [19.81230926513672, 2.449599504470825, 65.42264556884766]\n",
      "Epoch duration: 2.3061821460723877\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1291\n",
      "Epoch: 1292\n",
      "FGW torch.Size([29508, 5]) 6.854059029137716e-05\n",
      "Penalty params: tau=0.55154 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1292 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1292, train\n",
      " fgw:0.2022613\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2022613\n",
      "Measure Epoch 1292, train\n",
      " similarity:0.0275425\n",
      " penlog:-92.1295378\n",
      "Metrics Epoch 1292, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.2200000\n",
      " batch_invalid_valency_nodes:25.8260870\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.1500000\n",
      " batch_node_degree:2.7295652\n",
      "Logits [19.890623092651367, 2.4670660495758057, 65.14823150634766]\n",
      "Epoch duration: 2.6081433296203613\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1292\n",
      "Epoch: 1293\n",
      "FGW torch.Size([29508, 5]) 6.796027446398512e-05\n",
      "Penalty params: tau=0.55128 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1293 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1293, train\n",
      " fgw:0.1972017\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1972017\n",
      "Measure Epoch 1293, train\n",
      " similarity:0.0331859\n",
      " penlog:-86.2072005\n",
      "Metrics Epoch 1293, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:24.6086957\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.8600000\n",
      " batch_node_degree:2.7460870\n",
      "Logits [19.911970138549805, 2.4642558097839355, 64.6271743774414]\n",
      "Epoch duration: 2.423273801803589\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1293\n",
      "Epoch: 1294\n",
      "FGW torch.Size([29508, 5]) 6.970584217924625e-05\n",
      "Penalty params: tau=0.55103 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1294 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1294, train\n",
      " fgw:0.2076669\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2076669\n",
      "Measure Epoch 1294, train\n",
      " similarity:0.0277778\n",
      " penlog:-96.1534274\n",
      "Metrics Epoch 1294, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:25.0434783\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.1600000\n",
      " batch_node_degree:2.7078261\n",
      "Logits [19.768386840820312, 2.456148862838745, 63.814544677734375]\n",
      "Epoch duration: 2.174499273300171\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1295\n",
      "FGW torch.Size([29508, 5]) 6.745831342414021e-05\n",
      "Penalty params: tau=0.55077 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1295 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1295, train\n",
      " fgw:0.1963081\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1963081\n",
      "Measure Epoch 1295, train\n",
      " similarity:0.0266667\n",
      " penlog:-96.1632103\n",
      "Metrics Epoch 1295, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1600000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.0400000\n",
      " batch_node_degree:2.7121739\n",
      "Logits [19.581392288208008, 2.453084707260132, 62.98161697387695]\n",
      "Epoch duration: 2.242570400238037\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1295\n",
      "Epoch: 1296\n",
      "FGW torch.Size([29508, 5]) 7.038513285806403e-05\n",
      "Penalty params: tau=0.55052 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1296 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1296, train\n",
      " fgw:0.2144222\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2144222\n",
      "Measure Epoch 1296, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1296, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:25.6521739\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.6800000\n",
      " batch_node_degree:2.7582609\n",
      "Logits [19.45043182373047, 2.450016975402832, 62.56843566894531]\n",
      "Epoch duration: 2.3363778591156006\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1296\n",
      "Epoch: 1297\n",
      "FGW torch.Size([29508, 5]) 6.832309009041637e-05\n",
      "Penalty params: tau=0.55027 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1297 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1297, train\n",
      " fgw:0.2068618\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2068618\n",
      "Measure Epoch 1297, train\n",
      " similarity:0.0278335\n",
      " penlog:-94.2183357\n",
      "Metrics Epoch 1297, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1600000\n",
      " batch_invalid_valency_nodes:24.9565217\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.3300000\n",
      " batch_node_degree:2.7182609\n",
      "Logits [19.62270164489746, 2.4814677238464355, 63.53861999511719]\n",
      "Epoch duration: 2.5049562454223633\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1297\n",
      "Epoch: 1298\n",
      "FGW torch.Size([29508, 5]) 6.837453838670626e-05\n",
      "Penalty params: tau=0.55001 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1298 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1298, train\n",
      " fgw:0.2103606\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2103606\n",
      "Measure Epoch 1298, train\n",
      " similarity:0.0240909\n",
      " penlog:-96.1531998\n",
      "Metrics Epoch 1298, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:26.0869565\n",
      " batch_nodes_0degree:1.5600000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.0200000\n",
      " batch_node_degree:2.6982609\n",
      "Logits [19.99287986755371, 2.5421862602233887, 65.24638366699219]\n",
      "Epoch duration: 2.5301151275634766\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1298\n",
      "Epoch: 1299\n",
      "FGW torch.Size([29508, 5]) 6.998588651185855e-05\n",
      "Penalty params: tau=0.54976 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1299 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1299, train\n",
      " fgw:0.2079839\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2079839\n",
      "Measure Epoch 1299, train\n",
      " similarity:0.0285167\n",
      " penlog:-92.1786931\n",
      "Metrics Epoch 1299, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.2600000\n",
      " batch_invalid_valency_nodes:24.6086957\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.4700000\n",
      " batch_node_degree:2.7591304\n",
      "Logits [20.147254943847656, 2.557558298110962, 66.3670654296875]\n",
      "Epoch duration: 2.4394161701202393\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1299\n",
      "Epoch: 1300\n",
      "FGW torch.Size([29508, 5]) 6.923094770172611e-05\n",
      "Penalty params: tau=0.54951 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1300 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1300, train\n",
      " fgw:0.1981216\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1981216\n",
      "Measure Epoch 1300, train\n",
      " similarity:0.0232123\n",
      " penlog:-92.1878335\n",
      "Metrics Epoch 1300, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:27.0434783\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.1600000\n",
      " batch_node_degree:2.9426087\n",
      "Logits [20.03369903564453, 2.504772186279297, 66.26971435546875]\n",
      "Epoch duration: 2.479060173034668\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1300\n",
      "Epoch: 1301\n",
      "FGW torch.Size([29508, 5]) 6.768517050659284e-05\n",
      "Penalty params: tau=0.54925 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1301 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1301, train\n",
      " fgw:0.2030358\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2030358\n",
      "Measure Epoch 1301, train\n",
      " similarity:0.0211594\n",
      " penlog:-96.3183073\n",
      "Metrics Epoch 1301, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.6400000\n",
      " batch_invalid_valency_nodes:27.3043478\n",
      " batch_nodes_0degree:1.8200000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.0700000\n",
      " batch_node_degree:2.6913043\n",
      "Logits [19.75771141052246, 2.4491429328918457, 65.79875183105469]\n",
      "Epoch duration: 2.322894334793091\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1301\n",
      "Epoch: 1302\n",
      "FGW torch.Size([29508, 5]) 6.977662997087464e-05\n",
      "Penalty params: tau=0.54900 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1302 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1302, train\n",
      " fgw:0.2065953\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2065953\n",
      "Measure Epoch 1302, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1302, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:27.9130435\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:2.7000000\n",
      " batch_node_degree:2.8869565\n",
      "Logits [20.006288528442383, 2.4830827713012695, 66.67086791992188]\n",
      "Epoch duration: 2.283599853515625\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1302\n",
      "Epoch: 1303\n",
      "FGW torch.Size([29508, 5]) 6.772106280550361e-05\n",
      "Penalty params: tau=0.54875 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1303 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1303, train\n",
      " fgw:0.2002434\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2002434\n",
      "Measure Epoch 1303, train\n",
      " similarity:0.0284179\n",
      " penlog:-90.1602843\n",
      "Metrics Epoch 1303, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8200000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:1.8400000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:0.8800000\n",
      " batch_node_degree:2.6956522\n",
      "Logits [20.0668888092041, 2.5088748931884766, 66.69206237792969]\n",
      "Epoch duration: 2.2552542686462402\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1304\n",
      "FGW torch.Size([29508, 5]) 6.909164949320257e-05\n",
      "Penalty params: tau=0.54850 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1304 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1304, train\n",
      " fgw:0.1914559\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1914559\n",
      "Measure Epoch 1304, train\n",
      " similarity:0.0256274\n",
      " penlog:-92.1006609\n",
      "Metrics Epoch 1304, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:28.6086957\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:1.2200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:2.7200000\n",
      " batch_node_degree:2.9304348\n",
      "Logits [20.06377410888672, 2.532463550567627, 66.72769165039062]\n",
      "Epoch duration: 2.5374057292938232\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1304\n",
      "Epoch: 1305\n",
      "FGW torch.Size([29508, 5]) 6.633986777160317e-05\n",
      "Penalty params: tau=0.54824 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1305 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1305, train\n",
      " fgw:0.1920696\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1920696\n",
      "Measure Epoch 1305, train\n",
      " similarity:0.0234412\n",
      " penlog:-94.0400704\n",
      "Metrics Epoch 1305, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2600000\n",
      " batch_invalid_valency_nodes:24.5217391\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.0200000\n",
      " batch_node_degree:2.8034783\n",
      "Logits [19.985509872436523, 2.5315864086151123, 66.42867279052734]\n",
      "Epoch duration: 2.3522756099700928\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1305\n",
      "Epoch: 1306\n",
      "FGW torch.Size([29508, 5]) 6.756415677955374e-05\n",
      "Penalty params: tau=0.54799 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1306 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1306, train\n",
      " fgw:0.1938743\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1938743\n",
      "Measure Epoch 1306, train\n",
      " similarity:0.0210714\n",
      " penlog:-96.0375394\n",
      "Metrics Epoch 1306, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.5600000\n",
      " batch_node_degree:2.8426087\n",
      "Logits [19.554887771606445, 2.4327919483184814, 64.32353210449219]\n",
      "Epoch duration: 2.3987042903900146\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1306\n",
      "Epoch: 1307\n",
      "FGW torch.Size([29508, 5]) 6.789361941628158e-05\n",
      "Penalty params: tau=0.54774 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1307 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1307, train\n",
      " fgw:0.1958084\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1958084\n",
      "Measure Epoch 1307, train\n",
      " similarity:0.0283723\n",
      " penlog:-94.1283109\n",
      "Metrics Epoch 1307, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2000000\n",
      " batch_invalid_valency_nodes:22.3478261\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.6700000\n",
      " batch_node_degree:2.7313043\n",
      "Logits [19.907997131347656, 2.5002007484436035, 65.07766723632812]\n",
      "Epoch duration: 2.2218005657196045\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1307\n",
      "Epoch: 1308\n",
      "FGW torch.Size([29508, 5]) 6.770439358660951e-05\n",
      "Penalty params: tau=0.54749 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1308 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1308, train\n",
      " fgw:0.1904241\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1904241\n",
      "Measure Epoch 1308, train\n",
      " similarity:0.0236364\n",
      " penlog:-96.0865328\n",
      "Metrics Epoch 1308, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.4100000\n",
      " batch_node_degree:2.9095652\n",
      "Logits [19.82105255126953, 2.4790842533111572, 64.45780181884766]\n",
      "Epoch duration: 2.577664852142334\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1308\n",
      "Epoch: 1309\n",
      "FGW torch.Size([29508, 5]) 6.508825026685372e-05\n",
      "Penalty params: tau=0.54723 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1309 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1309, train\n",
      " fgw:0.1792814\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1792814\n",
      "Measure Epoch 1309, train\n",
      " similarity:0.0346321\n",
      " penlog:-86.9621885\n",
      "Metrics Epoch 1309, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.1600000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.6300000\n",
      " batch_node_degree:2.7860870\n",
      "Logits [19.665180206298828, 2.4473636150360107, 63.822391510009766]\n",
      "Epoch duration: 2.6669294834136963\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1309\n",
      "Epoch: 1310\n",
      "FGW torch.Size([29508, 5]) 6.513216067105532e-05\n",
      "Penalty params: tau=0.54698 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1310 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1310, train\n",
      " fgw:0.1896324\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1896324\n",
      "Measure Epoch 1310, train\n",
      " similarity:0.0295556\n",
      " penlog:-86.4258756\n",
      "Metrics Epoch 1310, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:22.7826087\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.4000000\n",
      " batch_node_degree:2.7104348\n",
      "Logits [19.529773712158203, 2.4152896404266357, 63.65034484863281]\n",
      "Epoch duration: 2.443920612335205\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1310\n",
      "Epoch: 1311\n",
      "FGW torch.Size([29508, 5]) 6.508221122203395e-05\n",
      "Penalty params: tau=0.54673 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1311 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1311, train\n",
      " fgw:0.2002755\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2002755\n",
      "Measure Epoch 1311, train\n",
      " similarity:0.0255076\n",
      " penlog:-90.7328615\n",
      "Metrics Epoch 1311, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.1800000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.6800000\n",
      " batch_node_degree:2.7669565\n",
      "Logits [19.835649490356445, 2.461116313934326, 65.02267456054688]\n",
      "Epoch duration: 2.5158185958862305\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1311\n",
      "Epoch: 1312\n",
      "FGW torch.Size([29508, 5]) 6.574913277290761e-05\n",
      "Penalty params: tau=0.54648 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1312 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1312, train\n",
      " fgw:0.1872825\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1872825\n",
      "Measure Epoch 1312, train\n",
      " similarity:0.0284568\n",
      " penlog:-90.2961486\n",
      "Metrics Epoch 1312, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:24.9565217\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.2300000\n",
      " batch_node_degree:2.7513043\n",
      "Logits [20.197738647460938, 2.518724203109741, 66.36283874511719]\n",
      "Epoch duration: 2.435239315032959\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1313\n",
      "FGW torch.Size([29508, 5]) 6.763740384485573e-05\n",
      "Penalty params: tau=0.54623 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1313 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1313, train\n",
      " fgw:0.1990154\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1990154\n",
      "Measure Epoch 1313, train\n",
      " similarity:0.0227907\n",
      " penlog:-96.1731724\n",
      "Metrics Epoch 1313, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:25.4782609\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:2.1000000\n",
      " batch_node_degree:2.8400000\n",
      "Logits [20.35806655883789, 2.530384063720703, 66.96886444091797]\n",
      "Epoch duration: 2.5685689449310303\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1313\n",
      "Epoch: 1314\n",
      "FGW torch.Size([29508, 5]) 6.45379041088745e-05\n",
      "Penalty params: tau=0.54598 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1314 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1314, train\n",
      " fgw:0.1947674\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1947674\n",
      "Measure Epoch 1314, train\n",
      " similarity:0.0294385\n",
      " penlog:-88.4228892\n",
      "Metrics Epoch 1314, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:23.5652174\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.1900000\n",
      " batch_node_degree:2.6991304\n",
      "Logits [20.331634521484375, 2.510026454925537, 67.09858703613281]\n",
      "Epoch duration: 2.455674648284912\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1314\n",
      "Epoch: 1315\n",
      "FGW torch.Size([29508, 5]) 6.899709114804864e-05\n",
      "Penalty params: tau=0.54572 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1315 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1315, train\n",
      " fgw:0.2087955\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2087955\n",
      "Measure Epoch 1315, train\n",
      " similarity:0.0244427\n",
      " penlog:-94.1260973\n",
      "Metrics Epoch 1315, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.5800000\n",
      " batch_invalid_valency_nodes:27.2173913\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:3.0100000\n",
      " batch_node_degree:2.9095652\n",
      "Logits [20.27523422241211, 2.480226755142212, 67.0483627319336]\n",
      "Epoch duration: 2.397905111312866\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1315\n",
      "Epoch: 1316\n",
      "FGW torch.Size([29508, 5]) 6.647407280979678e-05\n",
      "Penalty params: tau=0.54547 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1316 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1316, train\n",
      " fgw:0.1994012\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1994012\n",
      "Measure Epoch 1316, train\n",
      " similarity:0.0289916\n",
      " penlog:-92.4014027\n",
      "Metrics Epoch 1316, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.4400000\n",
      " batch_invalid_valency_nodes:23.8260870\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:0.8000000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.7900000\n",
      " batch_node_degree:2.6600000\n",
      "Logits [20.22051239013672, 2.474978446960449, 66.9502182006836]\n",
      "Epoch duration: 2.4319097995758057\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1316\n",
      "Epoch: 1317\n",
      "FGW torch.Size([29508, 5]) 6.761155236745253e-05\n",
      "Penalty params: tau=0.54522 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1317 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1317, train\n",
      " fgw:0.2046951\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2046951\n",
      "Measure Epoch 1317, train\n",
      " similarity:0.0347601\n",
      " penlog:-90.1429994\n",
      "Metrics Epoch 1317, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.3700000\n",
      " batch_node_degree:2.7269565\n",
      "Logits [20.270231246948242, 2.505178928375244, 66.93769073486328]\n",
      "Epoch duration: 2.641373634338379\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1317\n",
      "Epoch: 1318\n",
      "FGW torch.Size([29508, 5]) 6.748649320797995e-05\n",
      "Penalty params: tau=0.54497 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1318 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1318, train\n",
      " fgw:0.2032429\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2032429\n",
      "Measure Epoch 1318, train\n",
      " similarity:0.0332094\n",
      " penlog:-92.6253153\n",
      "Metrics Epoch 1318, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0200000\n",
      " batch_invalid_valency_nodes:25.7391304\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.2400000\n",
      " batch_node_degree:2.8365217\n",
      "Logits [20.297557830810547, 2.5482282638549805, 66.99305725097656]\n",
      "Epoch duration: 2.219139814376831\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1318\n",
      "Epoch: 1319\n",
      "FGW torch.Size([29508, 5]) 6.693173781968653e-05\n",
      "Penalty params: tau=0.54472 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1319 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1319, train\n",
      " fgw:0.2053343\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2053343\n",
      "Measure Epoch 1319, train\n",
      " similarity:0.0311805\n",
      " penlog:-94.3694766\n",
      "Metrics Epoch 1319, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2600000\n",
      " batch_invalid_valency_nodes:24.4347826\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.2400000\n",
      " batch_node_degree:2.7165217\n",
      "Logits [20.22066307067871, 2.5643486976623535, 66.74967956542969]\n",
      "Epoch duration: 2.5265448093414307\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1319\n",
      "Epoch: 1320\n",
      "FGW torch.Size([29508, 5]) 7.033093424979597e-05\n",
      "Penalty params: tau=0.54447 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1320 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1320, train\n",
      " fgw:0.2064062\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2064062\n",
      "Measure Epoch 1320, train\n",
      " similarity:0.0269060\n",
      " penlog:-94.1940246\n",
      "Metrics Epoch 1320, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:28.9565217\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.6500000\n",
      " batch_node_degree:2.8973913\n",
      "Logits [20.02365493774414, 2.561182975769043, 66.30442810058594]\n",
      "Epoch duration: 2.4126715660095215\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1320\n",
      "Epoch: 1321\n",
      "FGW torch.Size([29508, 5]) 6.638417107751593e-05\n",
      "Penalty params: tau=0.54422 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1321 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1321, train\n",
      " fgw:0.1952668\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1952668\n",
      "Measure Epoch 1321, train\n",
      " similarity:0.0345863\n",
      " penlog:-90.3830858\n",
      "Metrics Epoch 1321, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.4200000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.0600000\n",
      " batch_node_degree:2.7147826\n",
      "Logits [19.924022674560547, 2.550844430923462, 66.01606750488281]\n",
      "Epoch duration: 2.4561355113983154\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1322\n",
      "FGW torch.Size([29508, 5]) 6.875769031466916e-05\n",
      "Penalty params: tau=0.54397 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1322 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1322, train\n",
      " fgw:0.2012526\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2012526\n",
      "Measure Epoch 1322, train\n",
      " similarity:0.0260000\n",
      " penlog:-96.1410504\n",
      "Metrics Epoch 1322, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:26.3478261\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.7800000\n",
      " batch_node_degree:2.7721739\n",
      "Logits [19.863788604736328, 2.543180227279663, 65.8498764038086]\n",
      "Epoch duration: 2.4022696018218994\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1322\n",
      "Epoch: 1323\n",
      "FGW torch.Size([29508, 5]) 6.908967043273151e-05\n",
      "Penalty params: tau=0.54372 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1323 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1323, train\n",
      " fgw:0.1964020\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1964020\n",
      "Measure Epoch 1323, train\n",
      " similarity:0.0256811\n",
      " penlog:-94.4352029\n",
      "Metrics Epoch 1323, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7200000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.4700000\n",
      " batch_node_degree:2.8600000\n",
      "Logits [19.88829231262207, 2.559110403060913, 65.98873138427734]\n",
      "Epoch duration: 2.3054468631744385\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1323\n",
      "Epoch: 1324\n",
      "FGW torch.Size([29508, 5]) 6.812869105488062e-05\n",
      "Penalty params: tau=0.54347 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1324 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1324, train\n",
      " fgw:0.1978938\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1978938\n",
      "Measure Epoch 1324, train\n",
      " similarity:0.0268156\n",
      " penlog:-90.1751558\n",
      "Metrics Epoch 1324, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.5400000\n",
      " batch_invalid_valency_nodes:26.1739130\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.4500000\n",
      " batch_node_degree:2.7260870\n",
      "Logits [19.988590240478516, 2.5644524097442627, 66.40601348876953]\n",
      "Epoch duration: 2.60843825340271\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1324\n",
      "Epoch: 1325\n",
      "FGW torch.Size([29508, 5]) 6.95449925842695e-05\n",
      "Penalty params: tau=0.54322 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1325 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1325, train\n",
      " fgw:0.2051685\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2051685\n",
      "Measure Epoch 1325, train\n",
      " similarity:0.0226829\n",
      " penlog:-96.2495367\n",
      "Metrics Epoch 1325, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.5800000\n",
      " batch_invalid_valency_nodes:25.4782609\n",
      " batch_nodes_0degree:0.9800000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:3.1600000\n",
      " batch_node_degree:2.9269565\n",
      "Logits [20.000377655029297, 2.551417827606201, 66.6217269897461]\n",
      "Epoch duration: 2.428609609603882\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1325\n",
      "Epoch: 1326\n",
      "FGW torch.Size([29508, 5]) 7.058211485855281e-05\n",
      "Penalty params: tau=0.54297 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1326 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1326, train\n",
      " fgw:0.2077526\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2077526\n",
      "Measure Epoch 1326, train\n",
      " similarity:0.0252543\n",
      " penlog:-92.4626777\n",
      "Metrics Epoch 1326, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.8200000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.2200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.6800000\n",
      " batch_node_degree:2.8904348\n",
      "Logits [19.876964569091797, 2.4902710914611816, 66.23222351074219]\n",
      "Epoch duration: 2.563396692276001\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1326\n",
      "Epoch: 1327\n",
      "FGW torch.Size([29508, 5]) 6.881335866637528e-05\n",
      "Penalty params: tau=0.54272 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1327 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1327, train\n",
      " fgw:0.1985306\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1985306\n",
      "Measure Epoch 1327, train\n",
      " similarity:0.0220690\n",
      " penlog:-94.0709414\n",
      "Metrics Epoch 1327, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8600000\n",
      " batch_invalid_valency_nodes:27.7391304\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.2700000\n",
      " batch_node_degree:2.8286957\n",
      "Logits [19.889986038208008, 2.4699532985687256, 66.19850158691406]\n",
      "Epoch duration: 2.6247177124023438\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1327\n",
      "Epoch: 1328\n",
      "FGW torch.Size([29508, 5]) 7.080774230416864e-05\n",
      "Penalty params: tau=0.54247 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1328 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1328, train\n",
      " fgw:0.2041435\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2041435\n",
      "Measure Epoch 1328, train\n",
      " similarity:0.0294100\n",
      " penlog:-90.3864889\n",
      "Metrics Epoch 1328, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.2000000\n",
      " batch_invalid_valency_nodes:27.2173913\n",
      " batch_nodes_0degree:1.5000000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.0900000\n",
      " batch_node_degree:2.7834783\n",
      "Logits [19.854259490966797, 2.4372880458831787, 65.72887420654297]\n",
      "Epoch duration: 2.5281455516815186\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1328\n",
      "Epoch: 1329\n",
      "FGW torch.Size([29508, 5]) 6.92306348355487e-05\n",
      "Penalty params: tau=0.54222 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1329 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1329, train\n",
      " fgw:0.1918073\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1918073\n",
      "Measure Epoch 1329, train\n",
      " similarity:0.0230427\n",
      " penlog:-90.1892712\n",
      "Metrics Epoch 1329, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:24.7826087\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:2.1900000\n",
      " batch_node_degree:2.8208696\n",
      "Logits [19.681785583496094, 2.376983404159546, 64.78185272216797]\n",
      "Epoch duration: 2.336045980453491\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1329\n",
      "Epoch: 1330\n",
      "FGW torch.Size([29508, 5]) 6.88828804413788e-05\n",
      "Penalty params: tau=0.54197 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1330 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1330, train\n",
      " fgw:0.1932525\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1932525\n",
      "Measure Epoch 1330, train\n",
      " similarity:0.0233333\n",
      " penlog:-96.1468302\n",
      "Metrics Epoch 1330, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.5200000\n",
      " batch_node_degree:2.7773913\n",
      "Logits [19.60902976989746, 2.362447500228882, 64.20951843261719]\n",
      "Epoch duration: 2.4819679260253906\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1331\n",
      "FGW torch.Size([29508, 5]) 6.882151501486078e-05\n",
      "Penalty params: tau=0.54172 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1331 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1331, train\n",
      " fgw:0.1927442\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1927442\n",
      "Measure Epoch 1331, train\n",
      " similarity:0.0281300\n",
      " penlog:-92.3278891\n",
      "Metrics Epoch 1331, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.7391304\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.0700000\n",
      " batch_node_degree:2.8373913\n",
      "Logits [19.650802612304688, 2.3721299171447754, 64.1357192993164]\n",
      "Epoch duration: 2.3454577922821045\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1331\n",
      "Epoch: 1332\n",
      "FGW torch.Size([29508, 5]) 6.823831790825352e-05\n",
      "Penalty params: tau=0.54147 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1332 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1332, train\n",
      " fgw:0.2022008\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2022008\n",
      "Measure Epoch 1332, train\n",
      " similarity:0.0299981\n",
      " penlog:-88.3285517\n",
      "Metrics Epoch 1332, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.3800000\n",
      " batch_invalid_valency_nodes:25.7391304\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.9200000\n",
      " batch_node_degree:2.7860870\n",
      "Logits [19.716611862182617, 2.385211944580078, 64.30211639404297]\n",
      "Epoch duration: 2.461869716644287\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1332\n",
      "Epoch: 1333\n",
      "FGW torch.Size([29508, 5]) 6.980676698731259e-05\n",
      "Penalty params: tau=0.54122 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1333 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1333, train\n",
      " fgw:0.2068572\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2068572\n",
      "Measure Epoch 1333, train\n",
      " similarity:0.0064698\n",
      " penlog:-94.1281627\n",
      "Metrics Epoch 1333, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1600000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.2400000\n",
      " batch_node_degree:2.8365217\n",
      "Logits [19.71684455871582, 2.385988473892212, 64.27500915527344]\n",
      "Epoch duration: 2.377127170562744\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1333\n",
      "Epoch: 1334\n",
      "FGW torch.Size([29508, 5]) 6.989451503613964e-05\n",
      "Penalty params: tau=0.54097 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1334 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1334, train\n",
      " fgw:0.1994408\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1994408\n",
      "Measure Epoch 1334, train\n",
      " similarity:0.0052580\n",
      " penlog:-96.0489871\n",
      "Metrics Epoch 1334, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:27.3913043\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.7500000\n",
      " batch_node_degree:2.8086957\n",
      "Logits [19.73490333557129, 2.3885080814361572, 64.2452392578125]\n",
      "Epoch duration: 2.5888969898223877\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1334\n",
      "Epoch: 1335\n",
      "FGW torch.Size([29508, 5]) 7.138618821045384e-05\n",
      "Penalty params: tau=0.54072 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1335 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1335, train\n",
      " fgw:0.2109184\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2109184\n",
      "Measure Epoch 1335, train\n",
      " similarity:0.0108255\n",
      " penlog:-90.8351983\n",
      "Metrics Epoch 1335, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:25.5652174\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:0.9800000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.8700000\n",
      " batch_node_degree:2.7373913\n",
      "Logits [19.815900802612305, 2.3885695934295654, 64.35335540771484]\n",
      "Epoch duration: 2.462862968444824\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1335\n",
      "Epoch: 1336\n",
      "FGW torch.Size([29508, 5]) 6.871845835121349e-05\n",
      "Penalty params: tau=0.54047 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1336 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1336, train\n",
      " fgw:0.2136999\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2136999\n",
      "Measure Epoch 1336, train\n",
      " similarity:0.0043913\n",
      " penlog:-96.1476663\n",
      "Metrics Epoch 1336, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:26.4347826\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.5000000\n",
      " batch_node_degree:2.8321739\n",
      "Logits [20.016220092773438, 2.4186460971832275, 65.07341003417969]\n",
      "Epoch duration: 2.6833620071411133\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1336\n",
      "Epoch: 1337\n",
      "FGW torch.Size([29508, 5]) 6.566396041307598e-05\n",
      "Penalty params: tau=0.54022 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1337 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1337, train\n",
      " fgw:0.2004889\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2004889\n",
      "Measure Epoch 1337, train\n",
      " similarity:0.0272789\n",
      " penlog:-92.0284566\n",
      "Metrics Epoch 1337, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:4.1600000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.8800000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:42.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-0.5200000\n",
      " batch_node_degree:2.5565217\n",
      "Logits [20.308015823364258, 2.486121892929077, 66.16856384277344]\n",
      "Epoch duration: 2.4007163047790527\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1337\n",
      "Epoch: 1338\n",
      "FGW torch.Size([29508, 5]) 6.959395250305533e-05\n",
      "Penalty params: tau=0.53997 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1338 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1338, train\n",
      " fgw:0.1999513\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1999513\n",
      "Measure Epoch 1338, train\n",
      " similarity:0.0254764\n",
      " penlog:-94.2147663\n",
      "Metrics Epoch 1338, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8200000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.3400000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.6300000\n",
      " batch_node_degree:2.9782609\n",
      "Logits [20.60422706604004, 2.55446720123291, 67.24422454833984]\n",
      "Epoch duration: 2.388338565826416\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1338\n",
      "Epoch: 1339\n",
      "FGW torch.Size([29508, 5]) 6.369743641698733e-05\n",
      "Penalty params: tau=0.53973 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1339 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1339, train\n",
      " fgw:0.1924680\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1924680\n",
      "Measure Epoch 1339, train\n",
      " similarity:0.0384727\n",
      " penlog:-84.4012672\n",
      "Metrics Epoch 1339, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:4.0600000\n",
      " batch_invalid_valency_nodes:21.3043478\n",
      " batch_nodes_0degree:1.5600000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:44.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.4600000\n",
      " batch_node_degree:2.4582609\n",
      "Logits [20.744943618774414, 2.570598840713501, 67.50467681884766]\n",
      "Epoch duration: 2.332829475402832\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340\n",
      "FGW torch.Size([29508, 5]) 6.908809882588685e-05\n",
      "Penalty params: tau=0.53948 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1340 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1340, train\n",
      " fgw:0.1980973\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1980973\n",
      "Measure Epoch 1340, train\n",
      " similarity:0.0248889\n",
      " penlog:-96.1629976\n",
      "Metrics Epoch 1340, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:27.0434783\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.1600000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.8600000\n",
      " batch_node_degree:2.9286957\n",
      "Logits [20.76011848449707, 2.5621654987335205, 67.3612060546875]\n",
      "Epoch duration: 2.3232204914093018\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1340\n",
      "Epoch: 1341\n",
      "FGW torch.Size([29508, 5]) 6.699393270537257e-05\n",
      "Penalty params: tau=0.53923 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1341 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1341, train\n",
      " fgw:0.1938564\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1938564\n",
      "Measure Epoch 1341, train\n",
      " similarity:0.0278947\n",
      " penlog:-96.1513656\n",
      "Metrics Epoch 1341, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.8000000\n",
      " batch_node_degree:2.8147826\n",
      "Logits [20.75740623474121, 2.544839382171631, 67.1346435546875]\n",
      "Epoch duration: 2.432353973388672\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1341\n",
      "Epoch: 1342\n",
      "FGW torch.Size([29508, 5]) 6.677065539406613e-05\n",
      "Penalty params: tau=0.53898 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1342 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1342, train\n",
      " fgw:0.1973377\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1973377\n",
      "Measure Epoch 1342, train\n",
      " similarity:0.0083556\n",
      " penlog:-96.1739438\n",
      "Metrics Epoch 1342, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.3000000\n",
      " batch_invalid_valency_nodes:22.3478261\n",
      " batch_nodes_0degree:1.1600000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.1500000\n",
      " batch_node_degree:2.6686957\n",
      "Logits [20.61872100830078, 2.515089750289917, 66.33622741699219]\n",
      "Epoch duration: 2.580235719680786\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1342\n",
      "Epoch: 1343\n",
      "FGW torch.Size([29508, 5]) 6.740905519109219e-05\n",
      "Penalty params: tau=0.53873 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1343 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1343, train\n",
      " fgw:0.1838906\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1838906\n",
      "Measure Epoch 1343, train\n",
      " similarity:0.0060003\n",
      " penlog:-92.2441365\n",
      "Metrics Epoch 1343, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.5500000\n",
      " batch_node_degree:2.8026087\n",
      "Logits [20.4621524810791, 2.486651659011841, 65.50997924804688]\n",
      "Epoch duration: 2.608977794647217\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1343\n",
      "Epoch: 1344\n",
      "FGW torch.Size([29508, 5]) 6.625724927289411e-05\n",
      "Penalty params: tau=0.53848 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1344 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1344, train\n",
      " fgw:0.1903178\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1903178\n",
      "Measure Epoch 1344, train\n",
      " similarity:0.0054515\n",
      " penlog:-96.1577495\n",
      "Metrics Epoch 1344, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.6800000\n",
      " batch_invalid_valency_nodes:25.9130435\n",
      " batch_nodes_0degree:1.6200000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.3800000\n",
      " batch_node_degree:2.7060870\n",
      "Logits [20.372356414794922, 2.468759536743164, 64.98333740234375]\n",
      "Epoch duration: 2.4630320072174072\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1344\n",
      "Epoch: 1345\n",
      "FGW torch.Size([29508, 5]) 6.647015834460035e-05\n",
      "Penalty params: tau=0.53824 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1345 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1345, train\n",
      " fgw:0.1912541\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1912541\n",
      "Measure Epoch 1345, train\n",
      " similarity:0.0308322\n",
      " penlog:-88.2819760\n",
      "Metrics Epoch 1345, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.7600000\n",
      " batch_invalid_valency_nodes:24.8695652\n",
      " batch_nodes_0degree:1.6000000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:0.9000000\n",
      " batch_node_degree:2.7026087\n",
      "Logits [20.33754539489746, 2.4824130535125732, 64.7468032836914]\n",
      "Epoch duration: 2.4178831577301025\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1345\n",
      "Epoch: 1346\n",
      "FGW torch.Size([29508, 5]) 6.787130405427888e-05\n",
      "Penalty params: tau=0.53799 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1346 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1346, train\n",
      " fgw:0.2038244\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2038244\n",
      "Measure Epoch 1346, train\n",
      " similarity:0.0000000\n",
      " penlog:-100.0000000\n",
      "Metrics Epoch 1346, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:0.0000000\n",
      " batch_connected_components:2.6800000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.5000000\n",
      " batch_node_degree:2.7834783\n",
      "Logits [20.355621337890625, 2.5012362003326416, 64.82159423828125]\n",
      "Epoch duration: 2.5861096382141113\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1346\n",
      "Epoch: 1347\n",
      "FGW torch.Size([29508, 5]) 6.416108953999355e-05\n",
      "Penalty params: tau=0.53774 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1347 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1347, train\n",
      " fgw:0.1990715\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1990715\n",
      "Measure Epoch 1347, train\n",
      " similarity:0.0190052\n",
      " penlog:-81.9370036\n",
      "Metrics Epoch 1347, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:4.3000000\n",
      " batch_invalid_valency_nodes:23.1304348\n",
      " batch_nodes_0degree:1.7000000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:44.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.3000000\n",
      " batch_node_degree:2.5139130\n",
      "Logits [20.496355056762695, 2.5444998741149902, 65.6381607055664]\n",
      "Epoch duration: 2.654980421066284\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1347\n",
      "Epoch: 1348\n",
      "FGW torch.Size([29508, 5]) 6.776523514417931e-05\n",
      "Penalty params: tau=0.53749 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1348 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1348, train\n",
      " fgw:0.1933862\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1933862\n",
      "Measure Epoch 1348, train\n",
      " similarity:0.0070707\n",
      " penlog:-96.1577157\n",
      "Metrics Epoch 1348, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:27.4782609\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.2600000\n",
      " batch_node_degree:2.8991304\n",
      "Logits [20.445995330810547, 2.540311336517334, 65.81420135498047]\n",
      "Epoch duration: 2.5196516513824463\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1349\n",
      "FGW torch.Size([29508, 5]) 6.819284317316487e-05\n",
      "Penalty params: tau=0.53725 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1349 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1349, train\n",
      " fgw:0.2000554\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2000554\n",
      "Measure Epoch 1349, train\n",
      " similarity:0.0045833\n",
      " penlog:-98.1192048\n",
      "Metrics Epoch 1349, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:25.8260870\n",
      " batch_nodes_0degree:1.0200000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.1200000\n",
      " batch_node_degree:2.8660870\n",
      "Logits [20.11151885986328, 2.4825100898742676, 64.98538970947266]\n",
      "Epoch duration: 2.366809368133545\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1349\n",
      "Epoch: 1350\n",
      "FGW torch.Size([29508, 5]) 6.43138846498914e-05\n",
      "Penalty params: tau=0.53700 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1350 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1350, train\n",
      " fgw:0.1846647\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1846647\n",
      "Measure Epoch 1350, train\n",
      " similarity:0.0057125\n",
      " penlog:-94.1720143\n",
      "Metrics Epoch 1350, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1400000\n",
      " batch_invalid_valency_nodes:23.0434783\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.4400000\n",
      " batch_node_degree:2.7017391\n",
      "Logits [19.838552474975586, 2.4307303428649902, 64.54898071289062]\n",
      "Epoch duration: 2.3362772464752197\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1350\n",
      "Epoch: 1351\n",
      "FGW torch.Size([29508, 5]) 6.788066093577072e-05\n",
      "Penalty params: tau=0.53675 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1351 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1351, train\n",
      " fgw:0.1965153\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1965153\n",
      "Measure Epoch 1351, train\n",
      " similarity:0.0213115\n",
      " penlog:-94.1181502\n",
      "Metrics Epoch 1351, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.1600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.6600000\n",
      " batch_node_degree:2.9017391\n",
      "Logits [20.133705139160156, 2.480602741241455, 65.73519897460938]\n",
      "Epoch duration: 2.2181591987609863\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1351\n",
      "Epoch: 1352\n",
      "FGW torch.Size([29508, 5]) 6.8335109972395e-05\n",
      "Penalty params: tau=0.53650 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1352 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1352, train\n",
      " fgw:0.1918614\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1918614\n",
      "Measure Epoch 1352, train\n",
      " similarity:0.0064145\n",
      " penlog:-94.0620785\n",
      "Metrics Epoch 1352, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:26.5217391\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.0300000\n",
      " batch_node_degree:2.9756522\n",
      "Logits [20.13161277770996, 2.4816293716430664, 65.833740234375]\n",
      "Epoch duration: 2.402238130569458\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1352\n",
      "Epoch: 1353\n",
      "FGW torch.Size([29508, 5]) 6.536244472954422e-05\n",
      "Penalty params: tau=0.53626 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1353 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1353, train\n",
      " fgw:0.1971279\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1971279\n",
      "Measure Epoch 1353, train\n",
      " similarity:0.0319079\n",
      " penlog:-92.4525592\n",
      "Metrics Epoch 1353, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:21.2173913\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.6000000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.8300000\n",
      " batch_node_degree:2.6234783\n",
      "Logits [20.202377319335938, 2.499251365661621, 66.04421997070312]\n",
      "Epoch duration: 2.597740411758423\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1353\n",
      "Epoch: 1354\n",
      "FGW torch.Size([29508, 5]) 6.754320202162489e-05\n",
      "Penalty params: tau=0.53601 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1354 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1354, train\n",
      " fgw:0.1949675\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1949675\n",
      "Measure Epoch 1354, train\n",
      " similarity:0.0106262\n",
      " penlog:-94.1460854\n",
      "Metrics Epoch 1354, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1800000\n",
      " batch_invalid_valency_nodes:24.5217391\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.7700000\n",
      " batch_node_degree:2.7765217\n",
      "Logits [20.104158401489258, 2.4974558353424072, 65.88331604003906]\n",
      "Epoch duration: 2.3364429473876953\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1354\n",
      "Epoch: 1355\n",
      "FGW torch.Size([29508, 5]) 6.662642408628017e-05\n",
      "Penalty params: tau=0.53576 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1355 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1355, train\n",
      " fgw:0.1822369\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1822369\n",
      "Measure Epoch 1355, train\n",
      " similarity:0.0241860\n",
      " penlog:-96.1479394\n",
      "Metrics Epoch 1355, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:25.8260870\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.3500000\n",
      " batch_node_degree:2.7878261\n",
      "Logits [20.00802993774414, 2.492985725402832, 65.88363647460938]\n",
      "Epoch duration: 2.2800650596618652\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1355\n",
      "Epoch: 1356\n",
      "FGW torch.Size([29508, 5]) 6.51940717943944e-05\n",
      "Penalty params: tau=0.53552 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1356 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1356, train\n",
      " fgw:0.1952143\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1952143\n",
      "Measure Epoch 1356, train\n",
      " similarity:0.0303305\n",
      " penlog:-88.3035792\n",
      "Metrics Epoch 1356, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.4800000\n",
      " batch_invalid_valency_nodes:23.1304348\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.4100000\n",
      " batch_node_degree:2.5652174\n",
      "Logits [20.032339096069336, 2.4938042163848877, 66.21385192871094]\n",
      "Epoch duration: 2.5137267112731934\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1356\n",
      "Epoch: 1357\n",
      "FGW torch.Size([29508, 5]) 6.89450025674887e-05\n",
      "Penalty params: tau=0.53527 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1357 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1357, train\n",
      " fgw:0.1911353\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1911353\n",
      "Measure Epoch 1357, train\n",
      " similarity:0.0283871\n",
      " penlog:-96.1409288\n",
      "Metrics Epoch 1357, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.5200000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:1.0000000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:3.0200000\n",
      " batch_node_degree:2.8582609\n",
      "Logits [20.116146087646484, 2.497915744781494, 66.8727798461914]\n",
      "Epoch duration: 2.342367172241211\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1358\n",
      "FGW torch.Size([29508, 5]) 6.772946653654799e-05\n",
      "Penalty params: tau=0.53502 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1358 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1358, train\n",
      " fgw:0.1985867\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1985867\n",
      "Measure Epoch 1358, train\n",
      " similarity:0.0252222\n",
      " penlog:-92.0536325\n",
      "Metrics Epoch 1358, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.7600000\n",
      " batch_invalid_valency_nodes:21.7391304\n",
      " batch_nodes_0degree:1.4200000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:40.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.4500000\n",
      " batch_node_degree:2.5608696\n",
      "Logits [20.170984268188477, 2.4993362426757812, 67.20601654052734]\n",
      "Epoch duration: 2.2851147651672363\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1358\n",
      "Epoch: 1359\n",
      "FGW torch.Size([29508, 5]) 6.889008363941684e-05\n",
      "Penalty params: tau=0.53478 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1359 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1359, train\n",
      " fgw:0.1875555\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1875555\n",
      "Measure Epoch 1359, train\n",
      " similarity:0.0154343\n",
      " penlog:-94.1875775\n",
      "Metrics Epoch 1359, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.5400000\n",
      " batch_invalid_valency_nodes:25.8260870\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.7500000\n",
      " batch_node_degree:2.8852174\n",
      "Logits [20.139869689941406, 2.4729905128479004, 66.56295013427734]\n",
      "Epoch duration: 2.3137409687042236\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1359\n",
      "Epoch: 1360\n",
      "FGW torch.Size([29508, 5]) 6.789351755287498e-05\n",
      "Penalty params: tau=0.53453 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1360 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1360, train\n",
      " fgw:0.1994210\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1994210\n",
      "Measure Epoch 1360, train\n",
      " similarity:0.0233333\n",
      " penlog:-96.0676033\n",
      "Metrics Epoch 1360, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0000000\n",
      " batch_invalid_valency_nodes:23.1304348\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.7600000\n",
      " batch_node_degree:2.6947826\n",
      "Logits [20.14443016052246, 2.464648962020874, 65.69095611572266]\n",
      "Epoch duration: 2.301807165145874\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1360\n",
      "Epoch: 1361\n",
      "FGW torch.Size([29508, 5]) 6.689603469567373e-05\n",
      "Penalty params: tau=0.53428 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1361 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1361, train\n",
      " fgw:0.1952265\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1952265\n",
      "Measure Epoch 1361, train\n",
      " similarity:0.0211352\n",
      " penlog:-94.0481209\n",
      "Metrics Epoch 1361, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.9600000\n",
      " batch_invalid_valency_nodes:23.4782609\n",
      " batch_nodes_0degree:1.6000000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.0300000\n",
      " batch_node_degree:2.6052174\n",
      "Logits [19.992021560668945, 2.4482526779174805, 64.7922134399414]\n",
      "Epoch duration: 2.2382140159606934\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1361\n",
      "Epoch: 1362\n",
      "FGW torch.Size([29508, 5]) 7.034824375296012e-05\n",
      "Penalty params: tau=0.53404 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1362 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1362, train\n",
      " fgw:0.1933512\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1933512\n",
      "Measure Epoch 1362, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1362, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.5200000\n",
      " batch_invalid_valency_nodes:31.8260870\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:1.5200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:40.0000000\n",
      " avg_euler_error:4.6600000\n",
      " batch_node_degree:3.1686957\n",
      "Logits [19.818933486938477, 2.425877332687378, 64.01151275634766]\n",
      "Epoch duration: 2.3607399463653564\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1362\n",
      "Epoch: 1363\n",
      "FGW torch.Size([29508, 5]) 6.556217704201117e-05\n",
      "Penalty params: tau=0.53379 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1363 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1363, train\n",
      " fgw:0.2000349\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2000349\n",
      "Measure Epoch 1363, train\n",
      " similarity:0.0027069\n",
      " penlog:-96.1226379\n",
      "Metrics Epoch 1363, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.7800000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:1.6400000\n",
      " batch_nodes_7plus_degree:0.5800000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.4000000\n",
      " batch_node_degree:2.5565217\n",
      "Logits [19.56060791015625, 2.3970141410827637, 62.95207977294922]\n",
      "Epoch duration: 2.352485179901123\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1363\n",
      "Epoch: 1364\n",
      "FGW torch.Size([29508, 5]) 6.482444587163627e-05\n",
      "Penalty params: tau=0.53355 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1364 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1364, train\n",
      " fgw:0.1847946\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1847946\n",
      "Measure Epoch 1364, train\n",
      " similarity:0.0082138\n",
      " penlog:-94.1229486\n",
      "Metrics Epoch 1364, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:24.5217391\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.6400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.0600000\n",
      " batch_node_degree:2.7113043\n",
      "Logits [19.623472213745117, 2.406179189682007, 62.95065689086914]\n",
      "Epoch duration: 2.3094701766967773\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1364\n",
      "Epoch: 1365\n",
      "FGW torch.Size([29508, 5]) 6.816170935053378e-05\n",
      "Penalty params: tau=0.53330 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1365 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1365, train\n",
      " fgw:0.1899697\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1899697\n",
      "Measure Epoch 1365, train\n",
      " similarity:0.0086291\n",
      " penlog:-96.0480849\n",
      "Metrics Epoch 1365, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:29.2173913\n",
      " batch_nodes_0degree:1.0200000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:3.3000000\n",
      " batch_node_degree:3.0078261\n",
      "Logits [19.864179611206055, 2.4365015029907227, 63.632022857666016]\n",
      "Epoch duration: 2.24802303314209\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1365\n",
      "Epoch: 1366\n",
      "FGW torch.Size([29508, 5]) 6.579008186236024e-05\n",
      "Penalty params: tau=0.53306 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1366 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1366, train\n",
      " fgw:0.1920877\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1920877\n",
      "Measure Epoch 1366, train\n",
      " similarity:0.0349321\n",
      " penlog:-88.2344647\n",
      "Metrics Epoch 1366, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.4400000\n",
      " batch_invalid_valency_nodes:26.1739130\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.1700000\n",
      " batch_node_degree:2.6669565\n",
      "Logits [20.069602966308594, 2.4678101539611816, 64.17931365966797]\n",
      "Epoch duration: 2.4042091369628906\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1367\n",
      "FGW torch.Size([29508, 5]) 6.659397331532091e-05\n",
      "Penalty params: tau=0.53281 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1367 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1367, train\n",
      " fgw:0.1979143\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1979143\n",
      "Measure Epoch 1367, train\n",
      " similarity:0.0298825\n",
      " penlog:-90.2617689\n",
      "Metrics Epoch 1367, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:2.0100000\n",
      " batch_node_degree:2.7678261\n",
      "Logits [20.160295486450195, 2.4843339920043945, 64.64420318603516]\n",
      "Epoch duration: 2.26728892326355\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1367\n",
      "Epoch: 1368\n",
      "FGW torch.Size([29508, 5]) 6.513067637570202e-05\n",
      "Penalty params: tau=0.53257 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1368 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1368, train\n",
      " fgw:0.1852488\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1852488\n",
      "Measure Epoch 1368, train\n",
      " similarity:0.0249554\n",
      " penlog:-94.2917862\n",
      "Metrics Epoch 1368, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.6200000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.3600000\n",
      " batch_node_degree:2.7808696\n",
      "Logits [20.134164810180664, 2.480332374572754, 64.64271545410156]\n",
      "Epoch duration: 2.2941441535949707\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1368\n",
      "Epoch: 1369\n",
      "FGW torch.Size([29508, 5]) 6.864897295599803e-05\n",
      "Penalty params: tau=0.53232 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1369 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1369, train\n",
      " fgw:0.1954115\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1954115\n",
      "Measure Epoch 1369, train\n",
      " similarity:0.0272800\n",
      " penlog:-94.1587790\n",
      "Metrics Epoch 1369, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.5600000\n",
      " batch_invalid_valency_nodes:24.1739130\n",
      " batch_nodes_0degree:0.8600000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.5200000\n",
      " batch_node_degree:2.9365217\n",
      "Logits [20.149354934692383, 2.4766130447387695, 64.62506103515625]\n",
      "Epoch duration: 2.2157483100891113\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1369\n",
      "Epoch: 1370\n",
      "FGW torch.Size([29508, 5]) 6.6191736550536e-05\n",
      "Penalty params: tau=0.53207 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1370 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1370, train\n",
      " fgw:0.1929005\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1929005\n",
      "Measure Epoch 1370, train\n",
      " similarity:0.0298788\n",
      " penlog:-94.2672540\n",
      "Metrics Epoch 1370, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.1400000\n",
      " batch_node_degree:2.7269565\n",
      "Logits [20.309846878051758, 2.4949281215667725, 65.13732147216797]\n",
      "Epoch duration: 2.323962688446045\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1370\n",
      "Epoch: 1371\n",
      "FGW torch.Size([29508, 5]) 6.524255877593532e-05\n",
      "Penalty params: tau=0.53183 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1371 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1371, train\n",
      " fgw:0.1882190\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1882190\n",
      "Measure Epoch 1371, train\n",
      " similarity:0.0381596\n",
      " penlog:-88.2984546\n",
      "Metrics Epoch 1371, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:24.9565217\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.6300000\n",
      " batch_node_degree:2.7747826\n",
      "Logits [20.375890731811523, 2.486245632171631, 65.31657409667969]\n",
      "Epoch duration: 2.3533318042755127\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1371\n",
      "Epoch: 1372\n",
      "FGW torch.Size([29508, 5]) 6.77614807500504e-05\n",
      "Penalty params: tau=0.53158 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1372 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1372, train\n",
      " fgw:0.1906817\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1906817\n",
      "Measure Epoch 1372, train\n",
      " similarity:0.0303711\n",
      " penlog:-90.1836454\n",
      "Metrics Epoch 1372, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.9130435\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:26.3478261\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.7600000\n",
      " batch_node_degree:2.9139130\n",
      "Logits [20.34652328491211, 2.469942092895508, 65.20694732666016]\n",
      "Epoch duration: 2.2283713817596436\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1372\n",
      "Epoch: 1373\n",
      "FGW torch.Size([29508, 5]) 6.525519711431116e-05\n",
      "Penalty params: tau=0.53134 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1373 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1373, train\n",
      " fgw:0.1851156\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1851156\n",
      "Measure Epoch 1373, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1373, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.4200000\n",
      " batch_invalid_valency_nodes:25.9130435\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:1.0800000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:0.8300000\n",
      " batch_node_degree:2.7460870\n",
      "Logits [20.342527389526367, 2.461463451385498, 65.29358673095703]\n",
      "Epoch duration: 2.3133602142333984\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1373\n",
      "Epoch: 1374\n",
      "FGW torch.Size([29508, 5]) 6.573482824023813e-05\n",
      "Penalty params: tau=0.53110 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1374 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1374, train\n",
      " fgw:0.1889236\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1889236\n",
      "Measure Epoch 1374, train\n",
      " similarity:0.0038889\n",
      " penlog:-98.0704714\n",
      "Metrics Epoch 1374, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.5000000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:0.9800000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.2700000\n",
      " batch_node_degree:2.8278261\n",
      "Logits [20.403804779052734, 2.4740679264068604, 65.52902221679688]\n",
      "Epoch duration: 2.2953593730926514\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1374\n",
      "Epoch: 1375\n",
      "FGW torch.Size([29508, 5]) 6.581269553862512e-05\n",
      "Penalty params: tau=0.53085 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1375 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1375, train\n",
      " fgw:0.1886573\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1886573\n",
      "Measure Epoch 1375, train\n",
      " similarity:0.0308779\n",
      " penlog:-88.8439699\n",
      "Metrics Epoch 1375, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:23.4782609\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.0000000\n",
      " batch_node_degree:2.7486957\n",
      "Logits [20.429410934448242, 2.4875214099884033, 65.59815216064453]\n",
      "Epoch duration: 2.6475629806518555\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1376\n",
      "FGW torch.Size([29508, 5]) 6.236023182282224e-05\n",
      "Penalty params: tau=0.53061 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1376 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1376, train\n",
      " fgw:0.1835392\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1835392\n",
      "Measure Epoch 1376, train\n",
      " similarity:0.0303274\n",
      " penlog:-90.3683943\n",
      "Metrics Epoch 1376, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.5600000\n",
      " batch_invalid_valency_nodes:21.7391304\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.4600000\n",
      " invalid_euler_toofew:38.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.3300000\n",
      " batch_node_degree:2.5452174\n",
      "Logits [20.452518463134766, 2.503418445587158, 65.47463989257812]\n",
      "Epoch duration: 2.396286964416504\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1376\n",
      "Epoch: 1377\n",
      "FGW torch.Size([29508, 5]) 6.855894025648013e-05\n",
      "Penalty params: tau=0.53036 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1377 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1377, train\n",
      " fgw:0.1846341\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1846341\n",
      "Measure Epoch 1377, train\n",
      " similarity:0.0247660\n",
      " penlog:-94.5817393\n",
      "Metrics Epoch 1377, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7000000\n",
      " batch_invalid_valency_nodes:28.9565217\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.3600000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.8900000\n",
      " batch_node_degree:2.9843478\n",
      "Logits [20.300689697265625, 2.484508991241455, 64.948486328125]\n",
      "Epoch duration: 2.5569581985473633\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1377\n",
      "Epoch: 1378\n",
      "FGW torch.Size([29508, 5]) 6.366286106640473e-05\n",
      "Penalty params: tau=0.53012 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1378 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1378, train\n",
      " fgw:0.1800370\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1800370\n",
      "Measure Epoch 1378, train\n",
      " similarity:0.0278968\n",
      " penlog:-92.5482814\n",
      "Metrics Epoch 1378, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.7000000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.5700000\n",
      " batch_node_degree:2.6886957\n",
      "Logits [20.163406372070312, 2.4700722694396973, 64.36556243896484]\n",
      "Epoch duration: 2.471618413925171\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1378\n",
      "Epoch: 1379\n",
      "FGW torch.Size([29508, 5]) 6.285239942371845e-05\n",
      "Penalty params: tau=0.52987 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1379 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1379, train\n",
      " fgw:0.1890096\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1890096\n",
      "Measure Epoch 1379, train\n",
      " similarity:0.0263415\n",
      " penlog:-96.1788459\n",
      "Metrics Epoch 1379, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:23.1304348\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.2800000\n",
      " batch_node_degree:2.6773913\n",
      "Logits [19.993940353393555, 2.4525554180145264, 63.76095962524414]\n",
      "Epoch duration: 2.3828094005584717\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1379\n",
      "Epoch: 1380\n",
      "FGW torch.Size([29508, 5]) 6.817698158556595e-05\n",
      "Penalty params: tau=0.52963 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1380 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1380, train\n",
      " fgw:0.2009150\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2009150\n",
      "Measure Epoch 1380, train\n",
      " similarity:0.0259091\n",
      " penlog:-96.1545044\n",
      "Metrics Epoch 1380, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.5800000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:0.9200000\n",
      " batch_nodes_7plus_degree:1.3800000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.7500000\n",
      " batch_node_degree:3.0400000\n",
      "Logits [19.834800720214844, 2.4407269954681396, 63.15177536010742]\n",
      "Epoch duration: 2.1966123580932617\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1380\n",
      "Epoch: 1381\n",
      "FGW torch.Size([29508, 5]) 6.753762863809243e-05\n",
      "Penalty params: tau=0.52939 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1381 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1381, train\n",
      " fgw:0.1976482\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1976482\n",
      "Measure Epoch 1381, train\n",
      " similarity:0.0247619\n",
      " penlog:-96.1543004\n",
      "Metrics Epoch 1381, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9000000\n",
      " batch_invalid_valency_nodes:27.6521739\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.2600000\n",
      " batch_node_degree:2.8782609\n",
      "Logits [19.681114196777344, 2.4133810997009277, 62.56312561035156]\n",
      "Epoch duration: 2.200995922088623\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1381\n",
      "Epoch: 1382\n",
      "FGW torch.Size([29508, 5]) 6.345488509396091e-05\n",
      "Penalty params: tau=0.52914 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1382 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1382, train\n",
      " fgw:0.1901680\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1901680\n",
      "Measure Epoch 1382, train\n",
      " similarity:0.0242596\n",
      " penlog:-94.1118759\n",
      "Metrics Epoch 1382, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.8300000\n",
      " batch_node_degree:2.6417391\n",
      "Logits [19.824874877929688, 2.418851852416992, 63.05489730834961]\n",
      "Epoch duration: 2.338892936706543\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1382\n",
      "Epoch: 1383\n",
      "FGW torch.Size([29508, 5]) 6.681413651676849e-05\n",
      "Penalty params: tau=0.52890 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1383 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1383, train\n",
      " fgw:0.2010973\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2010973\n",
      "Measure Epoch 1383, train\n",
      " similarity:0.0253758\n",
      " penlog:-92.1697676\n",
      "Metrics Epoch 1383, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.1800000\n",
      " batch_invalid_valency_nodes:25.6521739\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.7400000\n",
      " batch_node_degree:2.7600000\n",
      "Logits [19.931983947753906, 2.4192659854888916, 63.646018981933594]\n",
      "Epoch duration: 2.3009912967681885\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1383\n",
      "Epoch: 1384\n",
      "FGW torch.Size([29508, 5]) 7.013975118752569e-05\n",
      "Penalty params: tau=0.52865 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1384 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1384, train\n",
      " fgw:0.2062086\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2062086\n",
      "Measure Epoch 1384, train\n",
      " similarity:0.0251064\n",
      " penlog:-96.1641605\n",
      "Metrics Epoch 1384, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:28.9565217\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.5000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.3000000\n",
      " batch_node_degree:3.0521739\n",
      "Logits [19.988386154174805, 2.424795150756836, 64.08502197265625]\n",
      "Epoch duration: 2.402615547180176\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1385\n",
      "FGW torch.Size([29508, 5]) 6.599099287996069e-05\n",
      "Penalty params: tau=0.52841 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1385 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1385, train\n",
      " fgw:0.2060518\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2060518\n",
      "Measure Epoch 1385, train\n",
      " similarity:0.0262755\n",
      " penlog:-92.5301731\n",
      "Metrics Epoch 1385, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.8000000\n",
      " batch_invalid_valency_nodes:23.0434783\n",
      " batch_nodes_0degree:1.9200000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:44.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.4000000\n",
      " batch_node_degree:2.5269565\n",
      "Logits [19.911800384521484, 2.4081273078918457, 63.99533462524414]\n",
      "Epoch duration: 2.4496312141418457\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1385\n",
      "Epoch: 1386\n",
      "FGW torch.Size([29508, 5]) 6.83634279994294e-05\n",
      "Penalty params: tau=0.52817 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1386 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1386, train\n",
      " fgw:0.2043573\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2043573\n",
      "Measure Epoch 1386, train\n",
      " similarity:0.0208603\n",
      " penlog:-94.0621424\n",
      "Metrics Epoch 1386, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7200000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.6500000\n",
      " batch_node_degree:2.8513043\n",
      "Logits [19.813077926635742, 2.388157606124878, 63.76649475097656]\n",
      "Epoch duration: 2.3222174644470215\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1386\n",
      "Epoch: 1387\n",
      "FGW torch.Size([29508, 5]) 7.033111614873633e-05\n",
      "Penalty params: tau=0.52793 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1387 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1387, train\n",
      " fgw:0.2058042\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2058042\n",
      "Measure Epoch 1387, train\n",
      " similarity:0.0260000\n",
      " penlog:-96.1810931\n",
      "Metrics Epoch 1387, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6000000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.0000000\n",
      " batch_nodes_7plus_degree:1.2600000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.7500000\n",
      " batch_node_degree:3.0173913\n",
      "Logits [19.969873428344727, 2.425096273422241, 64.40135192871094]\n",
      "Epoch duration: 2.389573812484741\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1387\n",
      "Epoch: 1388\n",
      "FGW torch.Size([29508, 5]) 6.449997454183176e-05\n",
      "Penalty params: tau=0.52768 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1388 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1388, train\n",
      " fgw:0.2025415\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2025415\n",
      "Measure Epoch 1388, train\n",
      " similarity:0.0323414\n",
      " penlog:-90.5102650\n",
      "Metrics Epoch 1388, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.4200000\n",
      " batch_invalid_valency_nodes:23.3913043\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:36.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.1100000\n",
      " batch_node_degree:2.6373913\n",
      "Logits [20.12898826599121, 2.468503475189209, 64.81781005859375]\n",
      "Epoch duration: 2.593597173690796\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1388\n",
      "Epoch: 1389\n",
      "FGW torch.Size([29508, 5]) 6.735415081493556e-05\n",
      "Penalty params: tau=0.52744 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1389 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1389, train\n",
      " fgw:0.1875349\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1875349\n",
      "Measure Epoch 1389, train\n",
      " similarity:0.0285990\n",
      " penlog:-94.1703400\n",
      "Metrics Epoch 1389, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:28.0869565\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.5700000\n",
      " batch_node_degree:2.9504348\n",
      "Logits [20.166820526123047, 2.480259895324707, 65.06128692626953]\n",
      "Epoch duration: 2.1929798126220703\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1389\n",
      "Epoch: 1390\n",
      "FGW torch.Size([29508, 5]) 6.829671474406496e-05\n",
      "Penalty params: tau=0.52720 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1390 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1390, train\n",
      " fgw:0.1986825\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1986825\n",
      "Measure Epoch 1390, train\n",
      " similarity:0.0320911\n",
      " penlog:-92.5117902\n",
      "Metrics Epoch 1390, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.7800000\n",
      " batch_invalid_valency_nodes:25.3043478\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.4300000\n",
      " batch_node_degree:2.8391304\n",
      "Logits [20.163448333740234, 2.4845685958862305, 65.02169036865234]\n",
      "Epoch duration: 2.3819851875305176\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1390\n",
      "Epoch: 1391\n",
      "FGW torch.Size([29508, 5]) 6.629549898207188e-05\n",
      "Penalty params: tau=0.52695 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1391 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1391, train\n",
      " fgw:0.2085970\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2085970\n",
      "Measure Epoch 1391, train\n",
      " similarity:0.0331973\n",
      " penlog:-88.3173069\n",
      "Metrics Epoch 1391, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6086957\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.4600000\n",
      " batch_invalid_valency_nodes:22.2608696\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.2300000\n",
      " batch_node_degree:2.6121739\n",
      "Logits [20.079429626464844, 2.4820973873138428, 64.65003204345703]\n",
      "Epoch duration: 2.5064139366149902\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1391\n",
      "Epoch: 1392\n",
      "FGW torch.Size([29508, 5]) 7.11139728082344e-05\n",
      "Penalty params: tau=0.52671 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1392 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1392, train\n",
      " fgw:0.2087225\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2087225\n",
      "Measure Epoch 1392, train\n",
      " similarity:0.0292068\n",
      " penlog:-92.1511619\n",
      "Metrics Epoch 1392, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.6400000\n",
      " batch_invalid_valency_nodes:30.4347826\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.5800000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:38.0000000\n",
      " avg_euler_error:4.1900000\n",
      " batch_node_degree:3.0869565\n",
      "Logits [19.79003143310547, 2.4263675212860107, 63.645328521728516]\n",
      "Epoch duration: 2.611506223678589\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1392\n",
      "Epoch: 1393\n",
      "FGW torch.Size([29508, 5]) 7.178512896643952e-05\n",
      "Penalty params: tau=0.52647 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1393 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1393, train\n",
      " fgw:0.2057805\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2057805\n",
      "Measure Epoch 1393, train\n",
      " similarity:0.0309165\n",
      " penlog:-92.1949309\n",
      "Metrics Epoch 1393, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9000000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.5300000\n",
      " batch_node_degree:2.9086957\n",
      "Logits [19.716501235961914, 2.405496597290039, 63.598594665527344]\n",
      "Epoch duration: 2.701465368270874\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1394\n",
      "FGW torch.Size([29508, 5]) 6.764207500964403e-05\n",
      "Penalty params: tau=0.52623 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1394 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1394, train\n",
      " fgw:0.2172212\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2172212\n",
      "Measure Epoch 1394, train\n",
      " similarity:0.0328794\n",
      " penlog:-90.1719175\n",
      "Metrics Epoch 1394, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:4.2400000\n",
      " batch_invalid_valency_nodes:24.7826087\n",
      " batch_nodes_0degree:1.9600000\n",
      " batch_nodes_7plus_degree:0.8200000\n",
      " invalid_euler_toofew:42.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.4500000\n",
      " batch_node_degree:2.5400000\n",
      "Logits [19.871070861816406, 2.414875030517578, 64.32373046875]\n",
      "Epoch duration: 2.4712140560150146\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1394\n",
      "Epoch: 1395\n",
      "FGW torch.Size([29508, 5]) 7.254489173647016e-05\n",
      "Penalty params: tau=0.52598 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1395 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1395, train\n",
      " fgw:0.2130783\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2130783\n",
      "Measure Epoch 1395, train\n",
      " similarity:0.0248452\n",
      " penlog:-94.0257633\n",
      "Metrics Epoch 1395, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8000000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.3000000\n",
      " batch_node_degree:2.9808696\n",
      "Logits [19.91297721862793, 2.4312570095062256, 64.72798919677734]\n",
      "Epoch duration: 2.542124032974243\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1395\n",
      "Epoch: 1396\n",
      "FGW torch.Size([29508, 5]) 7.052889850456268e-05\n",
      "Penalty params: tau=0.52574 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1396 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1396, train\n",
      " fgw:0.2070381\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2070381\n",
      "Measure Epoch 1396, train\n",
      " similarity:0.0248547\n",
      " penlog:-92.1287424\n",
      "Metrics Epoch 1396, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.2400000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:1.1400000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.7600000\n",
      " batch_node_degree:2.7800000\n",
      "Logits [19.990772247314453, 2.456834077835083, 65.06559753417969]\n",
      "Epoch duration: 2.3967394828796387\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1396\n",
      "Epoch: 1397\n",
      "FGW torch.Size([29508, 5]) 6.702198879793286e-05\n",
      "Penalty params: tau=0.52550 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1397 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1397, train\n",
      " fgw:0.2093498\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2093498\n",
      "Measure Epoch 1397, train\n",
      " similarity:0.0272415\n",
      " penlog:-94.2626801\n",
      "Metrics Epoch 1397, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.5400000\n",
      " batch_invalid_valency_nodes:22.6956522\n",
      " batch_nodes_0degree:1.6800000\n",
      " batch_nodes_7plus_degree:0.5000000\n",
      " invalid_euler_toofew:38.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.5300000\n",
      " batch_node_degree:2.4956522\n",
      "Logits [19.95726203918457, 2.4569458961486816, 64.87409210205078]\n",
      "Epoch duration: 2.4540514945983887\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1397\n",
      "Epoch: 1398\n",
      "FGW torch.Size([29508, 5]) 7.343087054323405e-05\n",
      "Penalty params: tau=0.52526 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1398 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1398, train\n",
      " fgw:0.2116130\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2116130\n",
      "Measure Epoch 1398, train\n",
      " similarity:0.0214706\n",
      " penlog:-96.1025662\n",
      "Metrics Epoch 1398, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.0400000\n",
      " batch_invalid_valency_nodes:30.0869565\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:1.5400000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:3.6700000\n",
      " batch_node_degree:3.0260870\n",
      "Logits [19.734708786010742, 2.4183108806610107, 64.1907730102539]\n",
      "Epoch duration: 2.4388844966888428\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1398\n",
      "Epoch: 1399\n",
      "FGW torch.Size([29508, 5]) 6.693440809613094e-05\n",
      "Penalty params: tau=0.52502 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1399 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1399, train\n",
      " fgw:0.1946030\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1946030\n",
      "Measure Epoch 1399, train\n",
      " similarity:0.0320268\n",
      " penlog:-88.3725996\n",
      "Metrics Epoch 1399, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.2800000\n",
      " batch_invalid_valency_nodes:23.9130435\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.8700000\n",
      " batch_node_degree:2.6860870\n",
      "Logits [19.724214553833008, 2.428624153137207, 64.3481674194336]\n",
      "Epoch duration: 2.251394510269165\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1399\n",
      "Epoch: 1400\n",
      "FGW torch.Size([29508, 5]) 6.651644798694178e-05\n",
      "Penalty params: tau=0.52477 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1400 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1400, train\n",
      " fgw:0.1940106\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1940106\n",
      "Measure Epoch 1400, train\n",
      " similarity:0.0357097\n",
      " penlog:-86.4178523\n",
      "Metrics Epoch 1400, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.3400000\n",
      " batch_invalid_valency_nodes:23.3913043\n",
      " batch_nodes_0degree:1.5600000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.7600000\n",
      " batch_node_degree:2.6504348\n",
      "Logits [19.768165588378906, 2.45633602142334, 64.82598876953125]\n",
      "Epoch duration: 2.158850908279419\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1400\n",
      "Epoch: 1401\n",
      "FGW torch.Size([29508, 5]) 7.083266245899722e-05\n",
      "Penalty params: tau=0.52453 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1401 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1401, train\n",
      " fgw:0.2023222\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2023222\n",
      "Measure Epoch 1401, train\n",
      " similarity:0.0269505\n",
      " penlog:-92.5650405\n",
      "Metrics Epoch 1401, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.5000000\n",
      " batch_invalid_valency_nodes:29.5652174\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.1800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.4200000\n",
      " batch_node_degree:3.0191304\n",
      "Logits [19.8497314453125, 2.482551336288452, 65.42119598388672]\n",
      "Epoch duration: 2.500373363494873\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1401\n",
      "Epoch: 1402\n",
      "FGW torch.Size([29508, 5]) 6.50632064207457e-05\n",
      "Penalty params: tau=0.52429 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1402 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1402, train\n",
      " fgw:0.1984613\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1984613\n",
      "Measure Epoch 1402, train\n",
      " similarity:0.0315826\n",
      " penlog:-92.2110566\n",
      "Metrics Epoch 1402, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.4800000\n",
      " batch_invalid_valency_nodes:24.0000000\n",
      " batch_nodes_0degree:1.6800000\n",
      " batch_nodes_7plus_degree:0.7400000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:0.2400000\n",
      " batch_node_degree:2.6086957\n",
      "Logits [19.898332595825195, 2.491152048110962, 65.69684600830078]\n",
      "Epoch duration: 2.526775360107422\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1403\n",
      "FGW torch.Size([29508, 5]) 6.694335024803877e-05\n",
      "Penalty params: tau=0.52405 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1403 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1403, train\n",
      " fgw:0.1938694\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1938694\n",
      "Measure Epoch 1403, train\n",
      " similarity:0.0239216\n",
      " penlog:-96.0733091\n",
      "Metrics Epoch 1403, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:25.6521739\n",
      " batch_nodes_0degree:1.4200000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:2.0200000\n",
      " batch_node_degree:2.7600000\n",
      "Logits [19.884777069091797, 2.4849462509155273, 65.6191177368164]\n",
      "Epoch duration: 2.4381980895996094\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1403\n",
      "Epoch: 1404\n",
      "FGW torch.Size([29508, 5]) 6.786463200114667e-05\n",
      "Penalty params: tau=0.52381 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1404 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1404, train\n",
      " fgw:0.1916926\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1916926\n",
      "Measure Epoch 1404, train\n",
      " similarity:0.0297308\n",
      " penlog:-94.5408389\n",
      "Metrics Epoch 1404, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.2800000\n",
      " batch_invalid_valency_nodes:26.1739130\n",
      " batch_nodes_0degree:1.6000000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.5800000\n",
      " batch_node_degree:2.7843478\n",
      "Logits [19.99357032775879, 2.526784658432007, 66.27820587158203]\n",
      "Epoch duration: 2.5363757610321045\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1404\n",
      "Epoch: 1405\n",
      "FGW torch.Size([29508, 5]) 6.751749606337398e-05\n",
      "Penalty params: tau=0.52357 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1405 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1405, train\n",
      " fgw:0.1988103\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1988103\n",
      "Measure Epoch 1405, train\n",
      " similarity:0.0256508\n",
      " penlog:-94.2939811\n",
      "Metrics Epoch 1405, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:1.4200000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.1800000\n",
      " batch_node_degree:2.8217391\n",
      "Logits [19.998802185058594, 2.531660318374634, 66.34203338623047]\n",
      "Epoch duration: 2.3091561794281006\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1405\n",
      "Epoch: 1406\n",
      "FGW torch.Size([29508, 5]) 6.831947393948212e-05\n",
      "Penalty params: tau=0.52333 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1406 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1406, train\n",
      " fgw:0.1956652\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1956652\n",
      "Measure Epoch 1406, train\n",
      " similarity:0.0226667\n",
      " penlog:-96.0802350\n",
      "Metrics Epoch 1406, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:24.0000000\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.5600000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.1800000\n",
      " batch_node_degree:2.6982609\n",
      "Logits [19.82037353515625, 2.4949347972869873, 65.77189636230469]\n",
      "Epoch duration: 2.6817259788513184\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1406\n",
      "Epoch: 1407\n",
      "FGW torch.Size([29508, 5]) 6.988156383158639e-05\n",
      "Penalty params: tau=0.52308 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1407 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1407, train\n",
      " fgw:0.2003972\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2003972\n",
      "Measure Epoch 1407, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1407, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.0200000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:2.4800000\n",
      " batch_node_degree:2.8460870\n",
      "Logits [19.54445457458496, 2.454854965209961, 64.83660888671875]\n",
      "Epoch duration: 2.3868408203125\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1407\n",
      "Epoch: 1408\n",
      "FGW torch.Size([29508, 5]) 6.90806336933747e-05\n",
      "Penalty params: tau=0.52284 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1408 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1408, train\n",
      " fgw:0.1984291\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1984291\n",
      "Measure Epoch 1408, train\n",
      " similarity:0.0239698\n",
      " penlog:-92.1546947\n",
      "Metrics Epoch 1408, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.4200000\n",
      " batch_invalid_valency_nodes:27.6521739\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:1.1600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.0600000\n",
      " batch_node_degree:2.7947826\n",
      "Logits [19.16253662109375, 2.390103816986084, 63.55888366699219]\n",
      "Epoch duration: 2.505640983581543\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1408\n",
      "Epoch: 1409\n",
      "FGW torch.Size([29508, 5]) 6.712717731716111e-05\n",
      "Penalty params: tau=0.52260 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1409 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1409, train\n",
      " fgw:0.1968911\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1968911\n",
      "Measure Epoch 1409, train\n",
      " similarity:0.0229318\n",
      " penlog:-94.1885208\n",
      "Metrics Epoch 1409, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.7200000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.7000000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.8000000\n",
      " batch_node_degree:2.6426087\n",
      "Logits [18.981340408325195, 2.3641197681427, 63.0839958190918]\n",
      "Epoch duration: 2.182847261428833\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1409\n",
      "Epoch: 1410\n",
      "FGW torch.Size([29508, 5]) 6.681325612589717e-05\n",
      "Penalty params: tau=0.52236 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1410 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1410, train\n",
      " fgw:0.1896199\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1896199\n",
      "Measure Epoch 1410, train\n",
      " similarity:0.0248333\n",
      " penlog:-94.0743296\n",
      "Metrics Epoch 1410, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.4000000\n",
      " batch_invalid_valency_nodes:25.7391304\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:1.1800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:3.2400000\n",
      " batch_node_degree:2.9269565\n",
      "Logits [18.78658103942871, 2.33900785446167, 62.77376937866211]\n",
      "Epoch duration: 2.4366261959075928\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1410\n",
      "Epoch: 1411\n",
      "FGW torch.Size([29508, 5]) 6.837301043560728e-05\n",
      "Penalty params: tau=0.52212 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1411 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1411, train\n",
      " fgw:0.1905983\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1905983\n",
      "Measure Epoch 1411, train\n",
      " similarity:0.0289037\n",
      " penlog:-94.1724149\n",
      "Metrics Epoch 1411, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:26.4347826\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.5100000\n",
      " batch_node_degree:2.8373913\n",
      "Logits [18.612232208251953, 2.324291944503784, 62.258384704589844]\n",
      "Epoch duration: 2.197700023651123\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1412\n",
      "FGW torch.Size([29508, 5]) 6.68050633976236e-05\n",
      "Penalty params: tau=0.52188 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1412 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1412, train\n",
      " fgw:0.2063277\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2063277\n",
      "Measure Epoch 1412, train\n",
      " similarity:0.0336229\n",
      " penlog:-90.2276248\n",
      "Metrics Epoch 1412, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.8400000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.0000000\n",
      " batch_node_degree:2.7086957\n",
      "Logits [18.83673667907715, 2.356849431991577, 63.29206848144531]\n",
      "Epoch duration: 2.4779422283172607\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1412\n",
      "Epoch: 1413\n",
      "FGW torch.Size([29508, 5]) 6.97928189765662e-05\n",
      "Penalty params: tau=0.52164 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1413 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1413, train\n",
      " fgw:0.1960549\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1960549\n",
      "Measure Epoch 1413, train\n",
      " similarity:0.0263830\n",
      " penlog:-96.0424950\n",
      "Metrics Epoch 1413, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8200000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.3000000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:2.5300000\n",
      " batch_node_degree:2.8582609\n",
      "Logits [19.050100326538086, 2.3700923919677734, 64.09203338623047]\n",
      "Epoch duration: 2.2100117206573486\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1413\n",
      "Epoch: 1414\n",
      "FGW torch.Size([29508, 5]) 6.868483615107834e-05\n",
      "Penalty params: tau=0.52140 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1414 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1414, train\n",
      " fgw:0.1941205\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1941205\n",
      "Measure Epoch 1414, train\n",
      " similarity:0.0076756\n",
      " penlog:-94.1157674\n",
      "Metrics Epoch 1414, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8800000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.0400000\n",
      " batch_node_degree:2.8173913\n",
      "Logits [19.241104125976562, 2.3862550258636475, 64.70710754394531]\n",
      "Epoch duration: 2.4275097846984863\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1414\n",
      "Epoch: 1415\n",
      "FGW torch.Size([29508, 5]) 6.5526386606507e-05\n",
      "Penalty params: tau=0.52116 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1415 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1415, train\n",
      " fgw:0.1915674\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1915674\n",
      "Measure Epoch 1415, train\n",
      " similarity:0.0273295\n",
      " penlog:-92.1308191\n",
      "Metrics Epoch 1415, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.7391304\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.6400000\n",
      " batch_invalid_valency_nodes:24.4347826\n",
      " batch_nodes_0degree:1.5800000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:32.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.5900000\n",
      " batch_node_degree:2.6582609\n",
      "Logits [19.384918212890625, 2.3961219787597656, 65.12670135498047]\n",
      "Epoch duration: 2.6254782676696777\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1415\n",
      "Epoch: 1416\n",
      "FGW torch.Size([29508, 5]) 6.978694727877155e-05\n",
      "Penalty params: tau=0.52092 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1416 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1416, train\n",
      " fgw:0.2013605\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2013605\n",
      "Measure Epoch 1416, train\n",
      " similarity:0.0270325\n",
      " penlog:-94.4887275\n",
      "Metrics Epoch 1416, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.3000000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:0.8600000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.8100000\n",
      " batch_node_degree:3.0078261\n",
      "Logits [19.470855712890625, 2.4030933380126953, 65.3072280883789]\n",
      "Epoch duration: 2.403855800628662\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1416\n",
      "Epoch: 1417\n",
      "FGW torch.Size([29508, 5]) 6.706090789521113e-05\n",
      "Penalty params: tau=0.52068 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1417 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1417, train\n",
      " fgw:0.1898663\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1898663\n",
      "Measure Epoch 1417, train\n",
      " similarity:0.0255814\n",
      " penlog:-96.1483573\n",
      "Metrics Epoch 1417, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1400000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.3600000\n",
      " batch_node_degree:2.8278261\n",
      "Logits [19.498703002929688, 2.4010212421417236, 65.55582427978516]\n",
      "Epoch duration: 2.362133264541626\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1417\n",
      "Epoch: 1418\n",
      "FGW torch.Size([29508, 5]) 6.5404296037741e-05\n",
      "Penalty params: tau=0.52044 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1418 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1418, train\n",
      " fgw:0.1917684\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1917684\n",
      "Measure Epoch 1418, train\n",
      " similarity:0.0268929\n",
      " penlog:-94.1556237\n",
      "Metrics Epoch 1418, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:18.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.5900000\n",
      " batch_node_degree:2.7365217\n",
      "Logits [19.535594940185547, 2.4150302410125732, 65.63726043701172]\n",
      "Epoch duration: 2.4173338413238525\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1418\n",
      "Epoch: 1419\n",
      "FGW torch.Size([29508, 5]) 6.864457100164145e-05\n",
      "Penalty params: tau=0.52020 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1419 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1419, train\n",
      " fgw:0.1962077\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1962077\n",
      "Measure Epoch 1419, train\n",
      " similarity:0.0069894\n",
      " penlog:-94.0322506\n",
      "Metrics Epoch 1419, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.2200000\n",
      " batch_invalid_valency_nodes:27.3913043\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.2600000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.5900000\n",
      " batch_node_degree:2.9913043\n",
      "Logits [19.624507904052734, 2.4461684226989746, 65.75164031982422]\n",
      "Epoch duration: 2.257277011871338\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1419\n",
      "Epoch: 1420\n",
      "FGW torch.Size([29508, 5]) 6.383863365044817e-05\n",
      "Penalty params: tau=0.51996 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1420 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1420, train\n",
      " fgw:0.1962153\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1962153\n",
      "Measure Epoch 1420, train\n",
      " similarity:0.0107852\n",
      " penlog:-96.0292585\n",
      "Metrics Epoch 1420, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.3000000\n",
      " batch_invalid_valency_nodes:22.0869565\n",
      " batch_nodes_0degree:1.4200000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.7300000\n",
      " batch_node_degree:2.6391304\n",
      "Logits [19.512449264526367, 2.4511561393737793, 64.99712371826172]\n",
      "Epoch duration: 2.71260929107666\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1421\n",
      "FGW torch.Size([29508, 5]) 6.669450522167608e-05\n",
      "Penalty params: tau=0.51972 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1421 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1421, train\n",
      " fgw:0.1891977\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1891977\n",
      "Measure Epoch 1421, train\n",
      " similarity:0.0094737\n",
      " penlog:-98.0219921\n",
      "Metrics Epoch 1421, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.6521739\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.8800000\n",
      " batch_invalid_valency_nodes:22.8695652\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.9100000\n",
      " batch_node_degree:2.7634783\n",
      "Logits [19.49565315246582, 2.4508323669433594, 64.53609466552734]\n",
      "Epoch duration: 2.253617763519287\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1421\n",
      "Epoch: 1422\n",
      "FGW torch.Size([29508, 5]) 6.808746547903866e-05\n",
      "Penalty params: tau=0.51948 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1422 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1422, train\n",
      " fgw:0.2066560\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2066560\n",
      "Measure Epoch 1422, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1422, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.8000000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.7500000\n",
      " batch_node_degree:2.7521739\n",
      "Logits [19.390735626220703, 2.43170166015625, 63.972412109375]\n",
      "Epoch duration: 2.678054094314575\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1422\n",
      "Epoch: 1423\n",
      "FGW torch.Size([29508, 5]) 6.412738730432466e-05\n",
      "Penalty params: tau=0.51924 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1423 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1423, train\n",
      " fgw:0.1976175\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1976175\n",
      "Measure Epoch 1423, train\n",
      " similarity:0.0270458\n",
      " penlog:-92.1419968\n",
      "Metrics Epoch 1423, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.5800000\n",
      " batch_invalid_valency_nodes:23.5652174\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.2200000\n",
      " batch_node_degree:2.6269565\n",
      "Logits [19.44766616821289, 2.4397614002227783, 64.17076873779297]\n",
      "Epoch duration: 2.298457622528076\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1423\n",
      "Epoch: 1424\n",
      "FGW torch.Size([29508, 5]) 6.74189577694051e-05\n",
      "Penalty params: tau=0.51900 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1424 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1424, train\n",
      " fgw:0.1926843\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1926843\n",
      "Measure Epoch 1424, train\n",
      " similarity:0.0313660\n",
      " penlog:-92.2544870\n",
      "Metrics Epoch 1424, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:24.8695652\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.2600000\n",
      " batch_node_degree:2.8243478\n",
      "Logits [19.32109832763672, 2.428962469100952, 63.81949234008789]\n",
      "Epoch duration: 2.4033143520355225\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1424\n",
      "Epoch: 1425\n",
      "FGW torch.Size([29508, 5]) 6.903171015437692e-05\n",
      "Penalty params: tau=0.51877 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1425 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1425, train\n",
      " fgw:0.1992698\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1992698\n",
      "Measure Epoch 1425, train\n",
      " similarity:0.0344917\n",
      " penlog:-90.3345163\n",
      "Metrics Epoch 1425, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:1.1800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:28.0000000\n",
      " avg_euler_error:3.4300000\n",
      " batch_node_degree:2.9582609\n",
      "Logits [19.211711883544922, 2.4273836612701416, 63.52162551879883]\n",
      "Epoch duration: 2.408388376235962\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1425\n",
      "Epoch: 1426\n",
      "FGW torch.Size([29508, 5]) 6.648977432632819e-05\n",
      "Penalty params: tau=0.51853 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1426 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1426, train\n",
      " fgw:0.1927027\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1927027\n",
      "Measure Epoch 1426, train\n",
      " similarity:0.0412278\n",
      " penlog:-90.1414176\n",
      "Metrics Epoch 1426, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:25.9130435\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.5800000\n",
      " batch_node_degree:2.7626087\n",
      "Logits [19.38711166381836, 2.4479265213012695, 64.21826934814453]\n",
      "Epoch duration: 2.38405704498291\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1426\n",
      "Epoch: 1427\n",
      "FGW torch.Size([29508, 5]) 6.691185262752697e-05\n",
      "Penalty params: tau=0.51829 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1427 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1427, train\n",
      " fgw:0.1875173\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1875173\n",
      "Measure Epoch 1427, train\n",
      " similarity:0.0258426\n",
      " penlog:-94.4019673\n",
      "Metrics Epoch 1427, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:26.0869565\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.6700000\n",
      " batch_node_degree:2.7869565\n",
      "Logits [19.79844856262207, 2.499253749847412, 65.58760833740234]\n",
      "Epoch duration: 2.3091704845428467\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1427\n",
      "Epoch: 1428\n",
      "FGW torch.Size([29508, 5]) 6.969755486352369e-05\n",
      "Penalty params: tau=0.51805 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1428 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1428, train\n",
      " fgw:0.2037134\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2037134\n",
      "Measure Epoch 1428, train\n",
      " similarity:0.0274513\n",
      " penlog:-94.1604622\n",
      "Metrics Epoch 1428, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.5000000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:0.9600000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.5000000\n",
      " batch_node_degree:2.9626087\n",
      "Logits [20.047534942626953, 2.5092391967773438, 66.42247009277344]\n",
      "Epoch duration: 2.2324607372283936\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1428\n",
      "Epoch: 1429\n",
      "FGW torch.Size([29508, 5]) 6.328852759907022e-05\n",
      "Penalty params: tau=0.51781 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1429 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1429, train\n",
      " fgw:0.1896539\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1896539\n",
      "Measure Epoch 1429, train\n",
      " similarity:0.0287242\n",
      " penlog:-92.1380883\n",
      "Metrics Epoch 1429, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.7000000\n",
      " batch_invalid_valency_nodes:23.3913043\n",
      " batch_nodes_0degree:1.8600000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:44.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.5700000\n",
      " batch_node_degree:2.5156522\n",
      "Logits [20.333810806274414, 2.5544779300689697, 67.62456512451172]\n",
      "Epoch duration: 2.7916100025177\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1430\n",
      "FGW torch.Size([29508, 5]) 7.019978511380032e-05\n",
      "Penalty params: tau=0.51757 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1430 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1430, train\n",
      " fgw:0.1911617\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1911617\n",
      "Measure Epoch 1430, train\n",
      " similarity:0.0211321\n",
      " penlog:-96.1072508\n",
      "Metrics Epoch 1430, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.1000000\n",
      " batch_invalid_valency_nodes:30.8695652\n",
      " batch_nodes_0degree:0.8400000\n",
      " batch_nodes_7plus_degree:1.5200000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:46.0000000\n",
      " avg_euler_error:5.2300000\n",
      " batch_node_degree:3.2095652\n",
      "Logits [20.437868118286133, 2.5586695671081543, 68.00102996826172]\n",
      "Epoch duration: 2.36997389793396\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1430\n",
      "Epoch: 1431\n",
      "FGW torch.Size([29508, 5]) 6.082161416998133e-05\n",
      "Penalty params: tau=0.51733 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1431 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1431, train\n",
      " fgw:0.1973440\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1973440\n",
      "Measure Epoch 1431, train\n",
      " similarity:0.0447989\n",
      " penlog:-76.4476642\n",
      "Metrics Epoch 1431, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:24.0000000\n",
      " batch_connected_components:4.3400000\n",
      " batch_invalid_valency_nodes:21.5652174\n",
      " batch_nodes_0degree:1.9400000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:50.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-1.3500000\n",
      " batch_node_degree:2.3626087\n",
      "Logits [20.431930541992188, 2.5590054988861084, 67.90204620361328]\n",
      "Epoch duration: 2.401444673538208\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1431\n",
      "Epoch: 1432\n",
      "FGW torch.Size([29508, 5]) 6.840104470029473e-05\n",
      "Penalty params: tau=0.51710 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1432 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1432, train\n",
      " fgw:0.1916613\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1916613\n",
      "Measure Epoch 1432, train\n",
      " similarity:0.0292282\n",
      " penlog:-92.1893517\n",
      "Metrics Epoch 1432, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.4800000\n",
      " batch_invalid_valency_nodes:28.5217391\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.1800000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.6000000\n",
      " batch_node_degree:2.9739130\n",
      "Logits [20.0022029876709, 2.490325927734375, 66.25658416748047]\n",
      "Epoch duration: 2.3528990745544434\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1432\n",
      "Epoch: 1433\n",
      "FGW torch.Size([29508, 5]) 6.787940947106108e-05\n",
      "Penalty params: tau=0.51686 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1433 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1433, train\n",
      " fgw:0.1957828\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1957828\n",
      "Measure Epoch 1433, train\n",
      " similarity:0.0297290\n",
      " penlog:-90.1420692\n",
      "Metrics Epoch 1433, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:26.6086957\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.0600000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.2900000\n",
      " batch_node_degree:2.8747826\n",
      "Logits [19.24364471435547, 2.3760268688201904, 63.88237762451172]\n",
      "Epoch duration: 2.3362088203430176\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1433\n",
      "Epoch: 1434\n",
      "FGW torch.Size([29508, 5]) 6.328496237983927e-05\n",
      "Penalty params: tau=0.51662 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1434 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1434, train\n",
      " fgw:0.1904729\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1904729\n",
      "Measure Epoch 1434, train\n",
      " similarity:0.0370798\n",
      " penlog:-84.6187356\n",
      "Metrics Epoch 1434, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:4.1000000\n",
      " batch_invalid_valency_nodes:22.5217391\n",
      " batch_nodes_0degree:2.0400000\n",
      " batch_nodes_7plus_degree:0.5800000\n",
      " invalid_euler_toofew:46.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.8700000\n",
      " batch_node_degree:2.4495652\n",
      "Logits [19.302907943725586, 2.377318859100342, 63.87844467163086]\n",
      "Epoch duration: 2.296542167663574\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1434\n",
      "Epoch: 1435\n",
      "FGW torch.Size([29508, 5]) 6.879161082906649e-05\n",
      "Penalty params: tau=0.51638 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1435 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1435, train\n",
      " fgw:0.1898341\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1898341\n",
      "Measure Epoch 1435, train\n",
      " similarity:0.0244444\n",
      " penlog:-96.2039464\n",
      "Metrics Epoch 1435, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6200000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:1.3400000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.6200000\n",
      " batch_node_degree:2.9478261\n",
      "Logits [19.458423614501953, 2.3889477252960205, 64.4629135131836]\n",
      "Epoch duration: 2.472104787826538\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1435\n",
      "Epoch: 1436\n",
      "FGW torch.Size([29508, 5]) 6.746262806700543e-05\n",
      "Penalty params: tau=0.51614 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1436 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1436, train\n",
      " fgw:0.1950360\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1950360\n",
      "Measure Epoch 1436, train\n",
      " similarity:0.0285233\n",
      " penlog:-92.1578131\n",
      "Metrics Epoch 1436, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.8800000\n",
      " batch_invalid_valency_nodes:27.3913043\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.6600000\n",
      " batch_node_degree:2.9000000\n",
      "Logits [19.712860107421875, 2.4430553913116455, 65.3951644897461]\n",
      "Epoch duration: 2.2878177165985107\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1436\n",
      "Epoch: 1437\n",
      "FGW torch.Size([29508, 5]) 6.361043051583692e-05\n",
      "Penalty params: tau=0.51591 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1437 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1437, train\n",
      " fgw:0.2024151\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2024151\n",
      "Measure Epoch 1437, train\n",
      " similarity:0.0312472\n",
      " penlog:-86.1582725\n",
      "Metrics Epoch 1437, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:4.0000000\n",
      " batch_invalid_valency_nodes:23.6521739\n",
      " batch_nodes_0degree:1.8200000\n",
      " batch_nodes_7plus_degree:0.4800000\n",
      " invalid_euler_toofew:50.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.7300000\n",
      " batch_node_degree:2.4878261\n",
      "Logits [19.86672019958496, 2.4797024726867676, 66.14893341064453]\n",
      "Epoch duration: 2.413257598876953\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1437\n",
      "Epoch: 1438\n",
      "FGW torch.Size([29508, 5]) 7.03654732205905e-05\n",
      "Penalty params: tau=0.51567 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1438 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1438, train\n",
      " fgw:0.1942013\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1942013\n",
      "Measure Epoch 1438, train\n",
      " similarity:0.0213514\n",
      " penlog:-96.0527140\n",
      "Metrics Epoch 1438, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.2000000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:0.9800000\n",
      " batch_nodes_7plus_degree:1.4000000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:4.5000000\n",
      " batch_node_degree:3.0495652\n",
      "Logits [19.773120880126953, 2.449836254119873, 65.86505126953125]\n",
      "Epoch duration: 2.2659671306610107\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1439\n",
      "FGW torch.Size([29508, 5]) 6.545131327584386e-05\n",
      "Penalty params: tau=0.51543 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1439 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1439, train\n",
      " fgw:0.2060226\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2060226\n",
      "Measure Epoch 1439, train\n",
      " similarity:0.0331761\n",
      " penlog:-84.3153011\n",
      "Metrics Epoch 1439, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:3.6000000\n",
      " batch_invalid_valency_nodes:25.0434783\n",
      " batch_nodes_0degree:1.7600000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:38.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:-0.1900000\n",
      " batch_node_degree:2.5843478\n",
      "Logits [19.46687126159668, 2.3925344944000244, 65.13768768310547]\n",
      "Epoch duration: 2.413285732269287\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1439\n",
      "Epoch: 1440\n",
      "FGW torch.Size([29508, 5]) 6.732577458024025e-05\n",
      "Penalty params: tau=0.51519 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1440 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1440, train\n",
      " fgw:0.1951130\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1951130\n",
      "Measure Epoch 1440, train\n",
      " similarity:0.0247283\n",
      " penlog:-94.1984721\n",
      "Metrics Epoch 1440, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:24.5217391\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.9600000\n",
      " batch_node_degree:2.8095652\n",
      "Logits [19.416229248046875, 2.386942148208618, 64.89611053466797]\n",
      "Epoch duration: 2.498220682144165\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1440\n",
      "Epoch: 1441\n",
      "FGW torch.Size([29508, 5]) 6.997444870648906e-05\n",
      "Penalty params: tau=0.51496 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1441 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1441, train\n",
      " fgw:0.1857687\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1857687\n",
      "Measure Epoch 1441, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1441, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.5600000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:0.8200000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:5.2300000\n",
      " batch_node_degree:3.1147826\n",
      "Logits [19.538013458251953, 2.423456907272339, 65.04313659667969]\n",
      "Epoch duration: 2.125359296798706\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1441\n",
      "Epoch: 1442\n",
      "FGW torch.Size([29508, 5]) 6.319516251096502e-05\n",
      "Penalty params: tau=0.51472 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1442 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1442, train\n",
      " fgw:0.1941020\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1941020\n",
      "Measure Epoch 1442, train\n",
      " similarity:0.0343584\n",
      " penlog:-82.2447762\n",
      "Metrics Epoch 1442, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:4.2800000\n",
      " batch_invalid_valency_nodes:24.2608696\n",
      " batch_nodes_0degree:2.1200000\n",
      " batch_nodes_7plus_degree:0.6000000\n",
      " invalid_euler_toofew:50.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-1.2300000\n",
      " batch_node_degree:2.4452174\n",
      "Logits [19.57722282409668, 2.4423084259033203, 64.78780364990234]\n",
      "Epoch duration: 2.422940731048584\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1442\n",
      "Epoch: 1443\n",
      "FGW torch.Size([29508, 5]) 6.715417839586735e-05\n",
      "Penalty params: tau=0.51448 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1443 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1443, train\n",
      " fgw:0.1858956\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1858956\n",
      "Measure Epoch 1443, train\n",
      " similarity:0.0240384\n",
      " penlog:-94.0619224\n",
      "Metrics Epoch 1443, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:29.7391304\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:3.3800000\n",
      " batch_node_degree:3.0130435\n",
      "Logits [19.67618751525879, 2.4656729698181152, 64.93466186523438]\n",
      "Epoch duration: 2.2739181518554688\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1443\n",
      "Epoch: 1444\n",
      "FGW torch.Size([29508, 5]) 6.729325104970485e-05\n",
      "Penalty params: tau=0.51425 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1444 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1444, train\n",
      " fgw:0.1877168\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1877168\n",
      "Measure Epoch 1444, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1444, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.4200000\n",
      " batch_invalid_valency_nodes:27.5652174\n",
      " batch_nodes_0degree:0.9400000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:34.0000000\n",
      " avg_euler_error:3.9300000\n",
      " batch_node_degree:3.0313043\n",
      "Logits [19.75747299194336, 2.491520404815674, 65.15261840820312]\n",
      "Epoch duration: 2.317176342010498\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1444\n",
      "Epoch: 1445\n",
      "FGW torch.Size([29508, 5]) 6.144042708911002e-05\n",
      "Penalty params: tau=0.51401 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1445 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1445, train\n",
      " fgw:0.1941489\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1941489\n",
      "Measure Epoch 1445, train\n",
      " similarity:0.0299638\n",
      " penlog:-88.2312287\n",
      "Metrics Epoch 1445, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:4.0600000\n",
      " batch_invalid_valency_nodes:22.4347826\n",
      " batch_nodes_0degree:1.8000000\n",
      " batch_nodes_7plus_degree:0.5400000\n",
      " invalid_euler_toofew:46.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-0.8600000\n",
      " batch_node_degree:2.4956522\n",
      "Logits [19.855302810668945, 2.5201945304870605, 65.4353256225586]\n",
      "Epoch duration: 2.29957914352417\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1445\n",
      "Epoch: 1446\n",
      "FGW torch.Size([29508, 5]) 6.94826157996431e-05\n",
      "Penalty params: tau=0.51377 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1446 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1446, train\n",
      " fgw:0.1984269\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1984269\n",
      "Measure Epoch 1446, train\n",
      " similarity:0.0234783\n",
      " penlog:-96.1916139\n",
      "Metrics Epoch 1446, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8000000\n",
      " batch_invalid_valency_nodes:28.7826087\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.3000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:3.6800000\n",
      " batch_node_degree:3.0095652\n",
      "Logits [19.787384033203125, 2.502156972885132, 65.25243377685547]\n",
      "Epoch duration: 2.1980392932891846\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1446\n",
      "Epoch: 1447\n",
      "FGW torch.Size([29508, 5]) 6.458110874518752e-05\n",
      "Penalty params: tau=0.51354 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1447 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1447, train\n",
      " fgw:0.1824065\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1824065\n",
      "Measure Epoch 1447, train\n",
      " similarity:0.0250000\n",
      " penlog:-96.1555769\n",
      "Metrics Epoch 1447, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.0000000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.8100000\n",
      " batch_node_degree:2.8817391\n",
      "Logits [19.873748779296875, 2.512014865875244, 65.38469696044922]\n",
      "Epoch duration: 2.3035824298858643\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1448\n",
      "FGW torch.Size([29508, 5]) 6.128739914856851e-05\n",
      "Penalty params: tau=0.51330 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1448 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1448, train\n",
      " fgw:0.1912546\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1912546\n",
      "Measure Epoch 1448, train\n",
      " similarity:0.0355090\n",
      " penlog:-86.3157842\n",
      "Metrics Epoch 1448, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.9800000\n",
      " batch_invalid_valency_nodes:22.0000000\n",
      " batch_nodes_0degree:1.7000000\n",
      " batch_nodes_7plus_degree:0.5400000\n",
      " invalid_euler_toofew:40.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-0.7000000\n",
      " batch_node_degree:2.4721739\n",
      "Logits [19.849651336669922, 2.511388063430786, 65.23198699951172]\n",
      "Epoch duration: 2.425389289855957\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1448\n",
      "Epoch: 1449\n",
      "FGW torch.Size([29508, 5]) 6.743177073076367e-05\n",
      "Penalty params: tau=0.51306 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1449 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1449, train\n",
      " fgw:0.1961656\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1961656\n",
      "Measure Epoch 1449, train\n",
      " similarity:0.0028571\n",
      " penlog:-98.0594470\n",
      "Metrics Epoch 1449, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.9000000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.8100000\n",
      " batch_node_degree:2.9339130\n",
      "Logits [19.666057586669922, 2.4820845127105713, 64.84971618652344]\n",
      "Epoch duration: 2.804835081100464\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1449\n",
      "Epoch: 1450\n",
      "FGW torch.Size([29508, 5]) 6.558782479260117e-05\n",
      "Penalty params: tau=0.51283 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1450 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1450, train\n",
      " fgw:0.1882160\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1882160\n",
      "Measure Epoch 1450, train\n",
      " similarity:0.0294998\n",
      " penlog:-94.2157545\n",
      "Metrics Epoch 1450, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.8200000\n",
      " batch_invalid_valency_nodes:27.9130435\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:2.8500000\n",
      " batch_node_degree:2.9200000\n",
      "Logits [19.68303108215332, 2.485137939453125, 65.00370025634766]\n",
      "Epoch duration: 2.5891716480255127\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1450\n",
      "Epoch: 1451\n",
      "FGW torch.Size([29508, 5]) 6.124017818365246e-05\n",
      "Penalty params: tau=0.51259 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1451 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1451, train\n",
      " fgw:0.1943954\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1943954\n",
      "Measure Epoch 1451, train\n",
      " similarity:0.0378100\n",
      " penlog:-82.4591653\n",
      "Metrics Epoch 1451, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:4.2400000\n",
      " batch_invalid_valency_nodes:21.2173913\n",
      " batch_nodes_0degree:1.7200000\n",
      " batch_nodes_7plus_degree:0.6000000\n",
      " invalid_euler_toofew:46.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:-0.9600000\n",
      " batch_node_degree:2.4504348\n",
      "Logits [19.807289123535156, 2.4968934059143066, 65.59496307373047]\n",
      "Epoch duration: 2.4631874561309814\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1451\n",
      "Epoch: 1452\n",
      "FGW torch.Size([29508, 5]) 6.982512422837317e-05\n",
      "Penalty params: tau=0.51235 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1452 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1452, train\n",
      " fgw:0.1964130\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1964130\n",
      "Measure Epoch 1452, train\n",
      " similarity:0.0278049\n",
      " penlog:-96.1172119\n",
      "Metrics Epoch 1452, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:26.6956522\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.8700000\n",
      " batch_node_degree:2.9800000\n",
      "Logits [19.831403732299805, 2.4872264862060547, 65.9089584350586]\n",
      "Epoch duration: 2.267235040664673\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1452\n",
      "Epoch: 1453\n",
      "FGW torch.Size([29508, 5]) 6.651290459558368e-05\n",
      "Penalty params: tau=0.51212 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1453 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1453, train\n",
      " fgw:0.2003507\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2003507\n",
      "Measure Epoch 1453, train\n",
      " similarity:0.0248768\n",
      " penlog:-94.2323395\n",
      "Metrics Epoch 1453, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.1000000\n",
      " batch_invalid_valency_nodes:26.7826087\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:2.2300000\n",
      " batch_node_degree:2.8617391\n",
      "Logits [19.9279842376709, 2.4901583194732666, 66.12723541259766]\n",
      "Epoch duration: 2.4337074756622314\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1453\n",
      "Epoch: 1454\n",
      "FGW torch.Size([29508, 5]) 6.359813414746895e-05\n",
      "Penalty params: tau=0.51188 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1454 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1454, train\n",
      " fgw:0.1911453\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1911453\n",
      "Measure Epoch 1454, train\n",
      " similarity:0.0355678\n",
      " penlog:-86.2552707\n",
      "Metrics Epoch 1454, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.6956522\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.9600000\n",
      " batch_invalid_valency_nodes:22.6086957\n",
      " batch_nodes_0degree:1.8400000\n",
      " batch_nodes_7plus_degree:0.5200000\n",
      " invalid_euler_toofew:52.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.9900000\n",
      " batch_node_degree:2.4721739\n",
      "Logits [19.940563201904297, 2.4875717163085938, 66.25221252441406]\n",
      "Epoch duration: 2.276043176651001\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1454\n",
      "Epoch: 1455\n",
      "FGW torch.Size([29508, 5]) 6.978971214266494e-05\n",
      "Penalty params: tau=0.51165 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1455 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1455, train\n",
      " fgw:0.1965610\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1965610\n",
      "Measure Epoch 1455, train\n",
      " similarity:0.0266650\n",
      " penlog:-94.1800996\n",
      "Metrics Epoch 1455, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.4400000\n",
      " batch_invalid_valency_nodes:26.9565217\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.2800000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.1400000\n",
      " batch_node_degree:2.9852174\n",
      "Logits [19.92548942565918, 2.4818904399871826, 66.06153106689453]\n",
      "Epoch duration: 2.383352279663086\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1455\n",
      "Epoch: 1456\n",
      "FGW torch.Size([29508, 5]) 6.535137799801305e-05\n",
      "Penalty params: tau=0.51141 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1456 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1456, train\n",
      " fgw:0.1960017\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1960017\n",
      "Measure Epoch 1456, train\n",
      " similarity:0.0391970\n",
      " penlog:-86.5095210\n",
      "Metrics Epoch 1456, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.6000000\n",
      " batch_invalid_valency_nodes:23.1304348\n",
      " batch_nodes_0degree:1.7200000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:6.0000000\n",
      " avg_euler_error:0.4100000\n",
      " batch_node_degree:2.6200000\n",
      "Logits [19.894832611083984, 2.4918053150177, 65.86521911621094]\n",
      "Epoch duration: 2.341526985168457\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1457\n",
      "FGW torch.Size([29508, 5]) 6.602760549867526e-05\n",
      "Penalty params: tau=0.51118 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1457 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1457, train\n",
      " fgw:0.1905820\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1905820\n",
      "Measure Epoch 1457, train\n",
      " similarity:0.0295557\n",
      " penlog:-92.1441383\n",
      "Metrics Epoch 1457, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.3200000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.5400000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.2900000\n",
      " batch_node_degree:2.7486957\n",
      "Logits [19.777395248413086, 2.483217716217041, 65.5081787109375]\n",
      "Epoch duration: 2.526724338531494\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1457\n",
      "Epoch: 1458\n",
      "FGW torch.Size([29508, 5]) 6.890091026434675e-05\n",
      "Penalty params: tau=0.51094 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1458 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1458, train\n",
      " fgw:0.1999348\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1999348\n",
      "Measure Epoch 1458, train\n",
      " similarity:0.0266026\n",
      " penlog:-94.1563623\n",
      "Metrics Epoch 1458, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:28.0000000\n",
      " batch_nodes_0degree:1.0800000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:30.0000000\n",
      " avg_euler_error:4.0000000\n",
      " batch_node_degree:2.9991304\n",
      "Logits [19.62441062927246, 2.468719005584717, 65.12008666992188]\n",
      "Epoch duration: 2.5269250869750977\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1458\n",
      "Epoch: 1459\n",
      "FGW torch.Size([29508, 5]) 6.411666254280135e-05\n",
      "Penalty params: tau=0.51071 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1459 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1459, train\n",
      " fgw:0.2009658\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2009658\n",
      "Measure Epoch 1459, train\n",
      " similarity:0.0303204\n",
      " penlog:-90.1725559\n",
      "Metrics Epoch 1459, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:4.2000000\n",
      " batch_invalid_valency_nodes:20.8695652\n",
      " batch_nodes_0degree:1.8200000\n",
      " batch_nodes_7plus_degree:0.6600000\n",
      " invalid_euler_toofew:48.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-0.7900000\n",
      " batch_node_degree:2.4617391\n",
      "Logits [19.36313819885254, 2.4418423175811768, 64.47088623046875]\n",
      "Epoch duration: 2.344604969024658\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1459\n",
      "Epoch: 1460\n",
      "FGW torch.Size([29508, 5]) 6.766338628949597e-05\n",
      "Penalty params: tau=0.51047 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1460 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1460, train\n",
      " fgw:0.2027560\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2027560\n",
      "Measure Epoch 1460, train\n",
      " similarity:0.0230303\n",
      " penlog:-96.0141770\n",
      "Metrics Epoch 1460, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8400000\n",
      " batch_invalid_valency_nodes:27.2173913\n",
      " batch_nodes_0degree:1.4000000\n",
      " batch_nodes_7plus_degree:1.1000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:1.9400000\n",
      " batch_node_degree:2.8173913\n",
      "Logits [19.35959243774414, 2.427011013031006, 64.66389465332031]\n",
      "Epoch duration: 2.6470181941986084\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1460\n",
      "Epoch: 1461\n",
      "FGW torch.Size([29508, 5]) 7.094136526575312e-05\n",
      "Penalty params: tau=0.51024 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1461 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1461, train\n",
      " fgw:0.2013604\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2013604\n",
      "Measure Epoch 1461, train\n",
      " similarity:0.0225641\n",
      " penlog:-96.0053714\n",
      "Metrics Epoch 1461, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.2800000\n",
      " batch_invalid_valency_nodes:31.4782609\n",
      " batch_nodes_0degree:0.8400000\n",
      " batch_nodes_7plus_degree:1.4600000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:40.0000000\n",
      " avg_euler_error:4.9900000\n",
      " batch_node_degree:3.2052174\n",
      "Logits [19.215789794921875, 2.367368221282959, 64.48902893066406]\n",
      "Epoch duration: 2.514549493789673\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1461\n",
      "Epoch: 1462\n",
      "FGW torch.Size([29508, 5]) 6.324610876617953e-05\n",
      "Penalty params: tau=0.51000 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1462 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1462, train\n",
      " fgw:0.2113563\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2113563\n",
      "Measure Epoch 1462, train\n",
      " similarity:0.0378531\n",
      " penlog:-82.1500639\n",
      "Metrics Epoch 1462, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.4347826\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:4.4400000\n",
      " batch_invalid_valency_nodes:20.8695652\n",
      " batch_nodes_0degree:1.7600000\n",
      " batch_nodes_7plus_degree:0.3200000\n",
      " invalid_euler_toofew:58.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-1.8000000\n",
      " batch_node_degree:2.3400000\n",
      "Logits [19.404417037963867, 2.3596298694610596, 64.9747314453125]\n",
      "Epoch duration: 2.7120425701141357\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1462\n",
      "Epoch: 1463\n",
      "FGW torch.Size([29508, 5]) 6.791880150558427e-05\n",
      "Penalty params: tau=0.50977 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1463 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1463, train\n",
      " fgw:0.1997924\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1997924\n",
      "Measure Epoch 1463, train\n",
      " similarity:0.0226866\n",
      " penlog:-95.9967373\n",
      "Metrics Epoch 1463, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6600000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.8000000\n",
      " batch_node_degree:2.8730435\n",
      "Logits [19.624290466308594, 2.377814769744873, 65.50617980957031]\n",
      "Epoch duration: 2.055640459060669\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1463\n",
      "Epoch: 1464\n",
      "FGW torch.Size([29508, 5]) 7.387016376014799e-05\n",
      "Penalty params: tau=0.50953 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1464 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1464, train\n",
      " fgw:0.2054110\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2054110\n",
      "Measure Epoch 1464, train\n",
      " similarity:0.0268902\n",
      " penlog:-94.1445042\n",
      "Metrics Epoch 1464, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.3000000\n",
      " batch_invalid_valency_nodes:31.8260870\n",
      " batch_nodes_0degree:0.8800000\n",
      " batch_nodes_7plus_degree:1.9800000\n",
      " invalid_euler_toofew:0.0000000\n",
      " invalid_euler_toomany:42.0000000\n",
      " avg_euler_error:5.4300000\n",
      " batch_node_degree:3.2600000\n",
      "Logits [19.730907440185547, 2.3911099433898926, 65.73438262939453]\n",
      "Epoch duration: 2.413632869720459\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1464\n",
      "Epoch: 1465\n",
      "FGW torch.Size([29508, 5]) 6.378020043484867e-05\n",
      "Penalty params: tau=0.50930 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1465 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1465, train\n",
      " fgw:0.2072259\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2072259\n",
      "Measure Epoch 1465, train\n",
      " similarity:0.0394474\n",
      " penlog:-83.9525886\n",
      "Metrics Epoch 1465, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:5.1200000\n",
      " batch_invalid_valency_nodes:21.5652174\n",
      " batch_nodes_0degree:2.4600000\n",
      " batch_nodes_7plus_degree:0.5000000\n",
      " invalid_euler_toofew:74.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-3.0500000\n",
      " batch_node_degree:2.2191304\n",
      "Logits [19.662874221801758, 2.4043610095977783, 65.4163818359375]\n",
      "Epoch duration: 2.3290205001831055\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1466\n",
      "FGW torch.Size([29508, 5]) 7.31003237888217e-05\n",
      "Penalty params: tau=0.50906 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1466 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1466, train\n",
      " fgw:0.2081956\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2081956\n",
      "Measure Epoch 1466, train\n",
      " similarity:0.0262910\n",
      " penlog:-94.1378808\n",
      "Metrics Epoch 1466, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.5800000\n",
      " batch_invalid_valency_nodes:28.2608696\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.2800000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:26.0000000\n",
      " avg_euler_error:3.6900000\n",
      " batch_node_degree:2.9530435\n",
      "Logits [19.401390075683594, 2.388159990310669, 64.56330871582031]\n",
      "Epoch duration: 2.4285330772399902\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1466\n",
      "Epoch: 1467\n",
      "FGW torch.Size([29508, 5]) 7.327891216846183e-05\n",
      "Penalty params: tau=0.50883 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1467 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1467, train\n",
      " fgw:0.1978346\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1978346\n",
      "Measure Epoch 1467, train\n",
      " similarity:0.0245040\n",
      " penlog:-94.5041029\n",
      "Metrics Epoch 1467, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.4000000\n",
      " batch_invalid_valency_nodes:33.2173913\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:1.7000000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:44.0000000\n",
      " avg_euler_error:5.3300000\n",
      " batch_node_degree:3.2060870\n",
      "Logits [19.18031883239746, 2.385780096054077, 63.86453628540039]\n",
      "Epoch duration: 2.380537748336792\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1467\n",
      "Epoch: 1468\n",
      "FGW torch.Size([29508, 5]) 6.266084528760985e-05\n",
      "Penalty params: tau=0.50859 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1468 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1468, train\n",
      " fgw:0.2086288\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2086288\n",
      "Measure Epoch 1468, train\n",
      " similarity:0.0239385\n",
      " penlog:-94.1861818\n",
      "Metrics Epoch 1468, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:5.0000000\n",
      " batch_invalid_valency_nodes:22.6956522\n",
      " batch_nodes_0degree:2.3800000\n",
      " batch_nodes_7plus_degree:0.3600000\n",
      " invalid_euler_toofew:60.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-2.5700000\n",
      " batch_node_degree:2.2878261\n",
      "Logits [19.02117156982422, 2.393284559249878, 63.04502868652344]\n",
      "Epoch duration: 2.6153323650360107\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1468\n",
      "Epoch: 1469\n",
      "FGW torch.Size([29508, 5]) 6.880480941617861e-05\n",
      "Penalty params: tau=0.50836 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1469 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1469, train\n",
      " fgw:0.2138416\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2138416\n",
      "Measure Epoch 1469, train\n",
      " similarity:0.0329790\n",
      " penlog:-88.1918509\n",
      "Metrics Epoch 1469, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.2000000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:1.8000000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.4700000\n",
      " batch_node_degree:2.7434783\n",
      "Logits [18.83226203918457, 2.367230176925659, 62.20880889892578]\n",
      "Epoch duration: 2.811070442199707\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1469\n",
      "Epoch: 1470\n",
      "FGW torch.Size([29508, 5]) 7.553916657343507e-05\n",
      "Penalty params: tau=0.50813 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1470 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1470, train\n",
      " fgw:0.2017160\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2017160\n",
      "Measure Epoch 1470, train\n",
      " similarity:0.0036015\n",
      " penlog:-96.1394235\n",
      "Metrics Epoch 1470, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.2800000\n",
      " batch_invalid_valency_nodes:33.1304348\n",
      " batch_nodes_0degree:0.9200000\n",
      " batch_nodes_7plus_degree:1.6200000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:66.0000000\n",
      " avg_euler_error:7.1000000\n",
      " batch_node_degree:3.3373913\n",
      "Logits [18.687124252319336, 2.3388192653656006, 61.77262878417969]\n",
      "Epoch duration: 2.4231648445129395\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1470\n",
      "Epoch: 1471\n",
      "FGW torch.Size([29508, 5]) 6.23224041191861e-05\n",
      "Penalty params: tau=0.50789 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1471 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1471, train\n",
      " fgw:0.1911520\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1911520\n",
      "Measure Epoch 1471, train\n",
      " similarity:0.0402850\n",
      " penlog:-84.3495466\n",
      "Metrics Epoch 1471, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.5652174\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:4.2800000\n",
      " batch_invalid_valency_nodes:23.8260870\n",
      " batch_nodes_0degree:2.1000000\n",
      " batch_nodes_7plus_degree:0.5000000\n",
      " invalid_euler_toofew:50.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-1.7300000\n",
      " batch_node_degree:2.3939130\n",
      "Logits [18.840988159179688, 2.3639707565307617, 62.30384826660156]\n",
      "Epoch duration: 2.4881298542022705\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1471\n",
      "Epoch: 1472\n",
      "FGW torch.Size([29508, 5]) 6.567395030288026e-05\n",
      "Penalty params: tau=0.50766 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1472 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1472, train\n",
      " fgw:0.2030847\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2030847\n",
      "Measure Epoch 1472, train\n",
      " similarity:0.0308546\n",
      " penlog:-86.0234500\n",
      "Metrics Epoch 1472, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:4.2600000\n",
      " batch_invalid_valency_nodes:22.7826087\n",
      " batch_nodes_0degree:1.7000000\n",
      " batch_nodes_7plus_degree:0.6000000\n",
      " invalid_euler_toofew:36.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.6700000\n",
      " batch_node_degree:2.5365217\n",
      "Logits [18.726581573486328, 2.334054470062256, 62.18974304199219]\n",
      "Epoch duration: 2.482713222503662\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1472\n",
      "Epoch: 1473\n",
      "FGW torch.Size([29508, 5]) 7.60257025831379e-05\n",
      "Penalty params: tau=0.50742 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1473 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1473, train\n",
      " fgw:0.1997832\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1997832\n",
      "Measure Epoch 1473, train\n",
      " similarity:0.0233333\n",
      " penlog:-96.1700314\n",
      "Metrics Epoch 1473, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:1.8400000\n",
      " batch_invalid_valency_nodes:34.5217391\n",
      " batch_nodes_0degree:0.8400000\n",
      " batch_nodes_7plus_degree:2.1600000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:58.0000000\n",
      " avg_euler_error:7.7600000\n",
      " batch_node_degree:3.4417391\n",
      "Logits [18.64805793762207, 2.3094048500061035, 62.24079513549805]\n",
      "Epoch duration: 2.3033530712127686\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1473\n",
      "Epoch: 1474\n",
      "FGW torch.Size([29508, 5]) 6.404447776731104e-05\n",
      "Penalty params: tau=0.50719 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1474 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1474, train\n",
      " fgw:0.1937751\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1937751\n",
      "Measure Epoch 1474, train\n",
      " similarity:0.0302476\n",
      " penlog:-88.2250039\n",
      "Metrics Epoch 1474, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.5400000\n",
      " batch_invalid_valency_nodes:25.1304348\n",
      " batch_nodes_0degree:1.8400000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:34.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.3100000\n",
      " batch_node_degree:2.6113043\n",
      "Logits [18.844472885131836, 2.3305060863494873, 62.91938400268555]\n",
      "Epoch duration: 2.382122278213501\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1475\n",
      "FGW torch.Size([29508, 5]) 6.481523450929672e-05\n",
      "Penalty params: tau=0.50696 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1475 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1475, train\n",
      " fgw:0.2034853\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2034853\n",
      "Measure Epoch 1475, train\n",
      " similarity:0.0375326\n",
      " penlog:-82.5166730\n",
      "Metrics Epoch 1475, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:18.0000000\n",
      " batch_connected_components:3.9600000\n",
      " batch_invalid_valency_nodes:21.3913043\n",
      " batch_nodes_0degree:1.9600000\n",
      " batch_nodes_7plus_degree:0.4800000\n",
      " invalid_euler_toofew:48.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-1.0200000\n",
      " batch_node_degree:2.4634783\n",
      "Logits [19.016233444213867, 2.3572826385498047, 63.56964874267578]\n",
      "Epoch duration: 2.3728344440460205\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1475\n",
      "Epoch: 1476\n",
      "FGW torch.Size([29508, 5]) 7.263579755090177e-05\n",
      "Penalty params: tau=0.50672 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1476 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1476, train\n",
      " fgw:0.1992827\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1992827\n",
      "Measure Epoch 1476, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1476, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.0600000\n",
      " batch_invalid_valency_nodes:31.9130435\n",
      " batch_nodes_0degree:0.9000000\n",
      " batch_nodes_7plus_degree:1.7000000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:50.0000000\n",
      " avg_euler_error:5.9300000\n",
      " batch_node_degree:3.2573913\n",
      "Logits [18.997472763061523, 2.36012601852417, 63.4254035949707]\n",
      "Epoch duration: 2.292494535446167\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1476\n",
      "Epoch: 1477\n",
      "FGW torch.Size([29508, 5]) 6.67220083414577e-05\n",
      "Penalty params: tau=0.50649 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1477 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1477, train\n",
      " fgw:0.1912766\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1912766\n",
      "Measure Epoch 1477, train\n",
      " similarity:0.0295025\n",
      " penlog:-92.0457286\n",
      "Metrics Epoch 1477, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9600000\n",
      " batch_invalid_valency_nodes:26.8695652\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.0900000\n",
      " batch_node_degree:2.8295652\n",
      "Logits [19.08429718017578, 2.3801708221435547, 63.80914306640625]\n",
      "Epoch duration: 2.3998289108276367\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1477\n",
      "Epoch: 1478\n",
      "FGW torch.Size([29508, 5]) 6.262977694859728e-05\n",
      "Penalty params: tau=0.50626 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1478 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1478, train\n",
      " fgw:0.1953952\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1953952\n",
      "Measure Epoch 1478, train\n",
      " similarity:0.0229444\n",
      " penlog:-94.0933299\n",
      "Metrics Epoch 1478, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.4200000\n",
      " batch_invalid_valency_nodes:21.1304348\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:40.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:-0.5200000\n",
      " batch_node_degree:2.5173913\n",
      "Logits [19.129056930541992, 2.3850982189178467, 63.64229965209961]\n",
      "Epoch duration: 2.2453670501708984\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1478\n",
      "Epoch: 1479\n",
      "FGW torch.Size([29508, 5]) 7.017989992164075e-05\n",
      "Penalty params: tau=0.50602 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1479 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1479, train\n",
      " fgw:0.1952276\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1952276\n",
      "Measure Epoch 1479, train\n",
      " similarity:0.0250000\n",
      " penlog:-96.1261969\n",
      "Metrics Epoch 1479, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.5200000\n",
      " batch_invalid_valency_nodes:30.8695652\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.6400000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.3500000\n",
      " batch_node_degree:3.1278261\n",
      "Logits [18.94696617126465, 2.3578712940216064, 62.7243766784668]\n",
      "Epoch duration: 2.261624813079834\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1479\n",
      "Epoch: 1480\n",
      "FGW torch.Size([29508, 5]) 6.793870852561668e-05\n",
      "Penalty params: tau=0.50579 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1480 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1480, train\n",
      " fgw:0.1945665\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1945665\n",
      "Measure Epoch 1480, train\n",
      " similarity:0.0240000\n",
      " penlog:-96.1303534\n",
      "Metrics Epoch 1480, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:3.1000000\n",
      " batch_invalid_valency_nodes:27.8260870\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:1.4400000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.8000000\n",
      " batch_node_degree:2.9426087\n",
      "Logits [18.730060577392578, 2.324615478515625, 61.744625091552734]\n",
      "Epoch duration: 2.4096858501434326\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1480\n",
      "Epoch: 1481\n",
      "FGW torch.Size([29508, 5]) 6.292566104093567e-05\n",
      "Penalty params: tau=0.50556 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1481 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1481, train\n",
      " fgw:0.1899666\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1899666\n",
      "Measure Epoch 1481, train\n",
      " similarity:0.0350004\n",
      " penlog:-86.1589264\n",
      "Metrics Epoch 1481, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.8200000\n",
      " batch_invalid_valency_nodes:23.1304348\n",
      " batch_nodes_0degree:1.8400000\n",
      " batch_nodes_7plus_degree:0.5400000\n",
      " invalid_euler_toofew:46.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-0.8000000\n",
      " batch_node_degree:2.4852174\n",
      "Logits [18.979534149169922, 2.3716046810150146, 62.57667541503906]\n",
      "Epoch duration: 2.4822750091552734\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1481\n",
      "Epoch: 1482\n",
      "FGW torch.Size([29508, 5]) 6.77602001815103e-05\n",
      "Penalty params: tau=0.50532 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1482 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1482, train\n",
      " fgw:0.1969984\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1969984\n",
      "Measure Epoch 1482, train\n",
      " similarity:0.0305744\n",
      " penlog:-92.0487978\n",
      "Metrics Epoch 1482, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0800000\n",
      " batch_invalid_valency_nodes:22.6956522\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.1300000\n",
      " batch_node_degree:2.7730435\n",
      "Logits [19.135635375976562, 2.388580083847046, 62.996299743652344]\n",
      "Epoch duration: 2.635037899017334\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1482\n",
      "Epoch: 1483\n",
      "FGW torch.Size([29508, 5]) 6.996458250796422e-05\n",
      "Penalty params: tau=0.50509 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1483 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1483, train\n",
      " fgw:0.1935207\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1935207\n",
      "Measure Epoch 1483, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1483, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.2400000\n",
      " batch_invalid_valency_nodes:29.3913043\n",
      " batch_nodes_0degree:0.9600000\n",
      " batch_nodes_7plus_degree:1.3400000\n",
      " invalid_euler_toofew:0.0000000\n",
      " invalid_euler_toomany:38.0000000\n",
      " avg_euler_error:4.4900000\n",
      " batch_node_degree:3.1417391\n",
      "Logits [19.198644638061523, 2.4053821563720703, 63.18805694580078]\n",
      "Epoch duration: 2.700275182723999\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1484\n",
      "FGW torch.Size([29508, 5]) 6.437198317144066e-05\n",
      "Penalty params: tau=0.50486 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1484 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1484, train\n",
      " fgw:0.1982079\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1982079\n",
      "Measure Epoch 1484, train\n",
      " similarity:0.0261687\n",
      " penlog:-94.1114585\n",
      "Metrics Epoch 1484, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.7000000\n",
      " batch_invalid_valency_nodes:22.2608696\n",
      " batch_nodes_0degree:1.4400000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:40.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-0.5300000\n",
      " batch_node_degree:2.5582609\n",
      "Logits [19.200511932373047, 2.3941900730133057, 62.972557067871094]\n",
      "Epoch duration: 2.3839943408966064\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1484\n",
      "Epoch: 1485\n",
      "FGW torch.Size([29508, 5]) 6.61260201013647e-05\n",
      "Penalty params: tau=0.50463 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1485 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1485, train\n",
      " fgw:0.1877459\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1877459\n",
      "Measure Epoch 1485, train\n",
      " similarity:0.0256393\n",
      " penlog:-94.1752603\n",
      "Metrics Epoch 1485, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:24.0869565\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.4400000\n",
      " batch_node_degree:2.7478261\n",
      "Logits [19.0972843170166, 2.3499724864959717, 62.5964469909668]\n",
      "Epoch duration: 2.528669595718384\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1485\n",
      "Epoch: 1486\n",
      "FGW torch.Size([29508, 5]) 7.068876584526151e-05\n",
      "Penalty params: tau=0.50439 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1486 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1486, train\n",
      " fgw:0.2016857\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2016857\n",
      "Measure Epoch 1486, train\n",
      " similarity:0.0271797\n",
      " penlog:-92.0456056\n",
      "Metrics Epoch 1486, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.5600000\n",
      " batch_invalid_valency_nodes:27.3913043\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.2400000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:3.9900000\n",
      " batch_node_degree:3.0095652\n",
      "Logits [19.023666381835938, 2.333625555038452, 62.25214767456055]\n",
      "Epoch duration: 2.474093437194824\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1486\n",
      "Epoch: 1487\n",
      "FGW torch.Size([29508, 5]) 6.628534174524248e-05\n",
      "Penalty params: tau=0.50416 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1487 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1487, train\n",
      " fgw:0.2004103\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2004103\n",
      "Measure Epoch 1487, train\n",
      " similarity:0.0371957\n",
      " penlog:-86.1398403\n",
      "Metrics Epoch 1487, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.5217391\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:4.1800000\n",
      " batch_invalid_valency_nodes:23.9130435\n",
      " batch_nodes_0degree:1.8600000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:42.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:-0.5400000\n",
      " batch_node_degree:2.5478261\n",
      "Logits [19.126834869384766, 2.3657171726226807, 62.55663299560547]\n",
      "Epoch duration: 2.2469534873962402\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1487\n",
      "Epoch: 1488\n",
      "FGW torch.Size([29508, 5]) 6.673583993688226e-05\n",
      "Penalty params: tau=0.50393 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1488 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1488, train\n",
      " fgw:0.1971317\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1971317\n",
      "Measure Epoch 1488, train\n",
      " similarity:0.0317102\n",
      " penlog:-90.2329598\n",
      "Metrics Epoch 1488, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:22.7826087\n",
      " batch_nodes_0degree:1.1800000\n",
      " batch_nodes_7plus_degree:0.8400000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.1700000\n",
      " batch_node_degree:2.7191304\n",
      "Logits [19.308597564697266, 2.408986806869507, 63.1155891418457]\n",
      "Epoch duration: 2.490067720413208\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1488\n",
      "Epoch: 1489\n",
      "FGW torch.Size([29508, 5]) 6.722447142237797e-05\n",
      "Penalty params: tau=0.50370 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1489 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1489, train\n",
      " fgw:0.1926213\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1926213\n",
      "Measure Epoch 1489, train\n",
      " similarity:0.0275518\n",
      " penlog:-94.2783190\n",
      "Metrics Epoch 1489, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.7600000\n",
      " batch_invalid_valency_nodes:25.0434783\n",
      " batch_nodes_0degree:0.9800000\n",
      " batch_nodes_7plus_degree:1.0400000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:24.0000000\n",
      " avg_euler_error:3.1400000\n",
      " batch_node_degree:2.9052174\n",
      "Logits [19.47150230407715, 2.4369208812713623, 63.538238525390625]\n",
      "Epoch duration: 2.71748948097229\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1489\n",
      "Epoch: 1490\n",
      "FGW torch.Size([29508, 5]) 6.406739703379571e-05\n",
      "Penalty params: tau=0.50347 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1490 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1490, train\n",
      " fgw:0.1923244\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1923244\n",
      "Measure Epoch 1490, train\n",
      " similarity:0.0269246\n",
      " penlog:-88.1511125\n",
      "Metrics Epoch 1490, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.4800000\n",
      " batch_invalid_valency_nodes:22.1739130\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.5600000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.7600000\n",
      " batch_node_degree:2.6469565\n",
      "Logits [19.572898864746094, 2.452282428741455, 63.739192962646484]\n",
      "Epoch duration: 2.6530206203460693\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1490\n",
      "Epoch: 1491\n",
      "FGW torch.Size([29508, 5]) 6.706097337882966e-05\n",
      "Penalty params: tau=0.50323 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1491 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1491, train\n",
      " fgw:0.2080034\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2080034\n",
      "Measure Epoch 1491, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1491, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.8695652\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:3.1200000\n",
      " batch_invalid_valency_nodes:27.5652174\n",
      " batch_nodes_0degree:1.3800000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.2700000\n",
      " batch_node_degree:2.9000000\n",
      "Logits [19.615617752075195, 2.4412641525268555, 63.72777557373047]\n",
      "Epoch duration: 2.44901180267334\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1491\n",
      "Epoch: 1492\n",
      "FGW torch.Size([29508, 5]) 6.822309660492465e-05\n",
      "Penalty params: tau=0.50300 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1492 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1492, train\n",
      " fgw:0.1991795\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1991795\n",
      "Measure Epoch 1492, train\n",
      " similarity:0.0212500\n",
      " penlog:-96.0459252\n",
      "Metrics Epoch 1492, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.8400000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:8.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:3.2400000\n",
      " batch_node_degree:2.9365217\n",
      "Logits [19.608787536621094, 2.417227268218994, 63.476898193359375]\n",
      "Epoch duration: 2.2153165340423584\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1493\n",
      "FGW torch.Size([29508, 5]) 6.51414884487167e-05\n",
      "Penalty params: tau=0.50277 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1493 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1493, train\n",
      " fgw:0.2008974\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2008974\n",
      "Measure Epoch 1493, train\n",
      " similarity:0.0210526\n",
      " penlog:-94.0885367\n",
      "Metrics Epoch 1493, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.4800000\n",
      " batch_invalid_valency_nodes:23.9130435\n",
      " batch_nodes_0degree:1.6600000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.6000000\n",
      " batch_node_degree:2.6295652\n",
      "Logits [19.61166763305664, 2.3913183212280273, 63.02050018310547]\n",
      "Epoch duration: 2.727903366088867\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1493\n",
      "Epoch: 1494\n",
      "FGW torch.Size([29508, 5]) 6.657707854174078e-05\n",
      "Penalty params: tau=0.50254 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1494 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1494, train\n",
      " fgw:0.1939916\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1939916\n",
      "Measure Epoch 1494, train\n",
      " similarity:0.0266557\n",
      " penlog:-94.1605986\n",
      "Metrics Epoch 1494, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.5600000\n",
      " batch_invalid_valency_nodes:24.6956522\n",
      " batch_nodes_0degree:1.3600000\n",
      " batch_nodes_7plus_degree:0.8600000\n",
      " invalid_euler_toofew:24.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:1.0400000\n",
      " batch_node_degree:2.7460870\n",
      "Logits [19.654172897338867, 2.3744702339172363, 62.99456787109375]\n",
      "Epoch duration: 2.544186592102051\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1494\n",
      "Epoch: 1495\n",
      "FGW torch.Size([29508, 5]) 6.801266135880724e-05\n",
      "Penalty params: tau=0.50231 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1495 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1495, train\n",
      " fgw:0.1962921\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1962921\n",
      "Measure Epoch 1495, train\n",
      " similarity:0.0284211\n",
      " penlog:-92.2477443\n",
      "Metrics Epoch 1495, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.4400000\n",
      " batch_invalid_valency_nodes:28.3478261\n",
      " batch_nodes_0degree:1.1200000\n",
      " batch_nodes_7plus_degree:1.4400000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:38.0000000\n",
      " avg_euler_error:3.9500000\n",
      " batch_node_degree:3.0765217\n",
      "Logits [19.778615951538086, 2.383251428604126, 63.37355041503906]\n",
      "Epoch duration: 2.4353625774383545\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1495\n",
      "Epoch: 1496\n",
      "FGW torch.Size([29508, 5]) 6.468085484812036e-05\n",
      "Penalty params: tau=0.50208 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1496 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1496, train\n",
      " fgw:0.1919329\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1919329\n",
      "Measure Epoch 1496, train\n",
      " similarity:0.0278573\n",
      " penlog:-88.2207681\n",
      "Metrics Epoch 1496, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.6800000\n",
      " batch_invalid_valency_nodes:24.6086957\n",
      " batch_nodes_0degree:1.4600000\n",
      " batch_nodes_7plus_degree:0.8000000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.6400000\n",
      " batch_node_degree:2.6486957\n",
      "Logits [19.88498878479004, 2.4227705001831055, 63.7043571472168]\n",
      "Epoch duration: 2.415069818496704\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1496\n",
      "Epoch: 1497\n",
      "FGW torch.Size([29508, 5]) 6.50466390652582e-05\n",
      "Penalty params: tau=0.50185 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1497 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1497, train\n",
      " fgw:0.1938161\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1938161\n",
      "Measure Epoch 1497, train\n",
      " similarity:0.0271170\n",
      " penlog:-92.0638512\n",
      "Metrics Epoch 1497, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:23.4782609\n",
      " batch_nodes_0degree:1.2000000\n",
      " batch_nodes_7plus_degree:0.6200000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.7000000\n",
      " batch_node_degree:2.7200000\n",
      "Logits [19.92082405090332, 2.4462645053863525, 63.94669723510742]\n",
      "Epoch duration: 2.4460465908050537\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1497\n",
      "Epoch: 1498\n",
      "FGW torch.Size([29508, 5]) 6.812005449319258e-05\n",
      "Penalty params: tau=0.50161 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1498 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1498, train\n",
      " fgw:0.1917123\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1917123\n",
      "Measure Epoch 1498, train\n",
      " similarity:0.0200000\n",
      " penlog:-98.0416051\n",
      "Metrics Epoch 1498, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.9565217\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.2200000\n",
      " batch_invalid_valency_nodes:30.0869565\n",
      " batch_nodes_0degree:1.0200000\n",
      " batch_nodes_7plus_degree:1.5600000\n",
      " invalid_euler_toofew:2.0000000\n",
      " invalid_euler_toomany:36.0000000\n",
      " avg_euler_error:4.2300000\n",
      " batch_node_degree:3.1434783\n",
      "Logits [19.989957809448242, 2.480750322341919, 64.33502960205078]\n",
      "Epoch duration: 2.312627077102661\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1498\n",
      "Epoch: 1499\n",
      "FGW torch.Size([29508, 5]) 6.61822923575528e-05\n",
      "Penalty params: tau=0.50138 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1499 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1499, train\n",
      " fgw:0.2002760\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2002760\n",
      "Measure Epoch 1499, train\n",
      " similarity:0.0270436\n",
      " penlog:-94.1996423\n",
      "Metrics Epoch 1499, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.9400000\n",
      " batch_invalid_valency_nodes:24.4347826\n",
      " batch_nodes_0degree:1.4800000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:22.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.0000000\n",
      " batch_node_degree:2.7095652\n",
      "Logits [20.016742706298828, 2.5056214332580566, 64.39762878417969]\n",
      "Epoch duration: 2.5757088661193848\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1499\n",
      "Epoch: 1500\n",
      "FGW torch.Size([29508, 5]) 6.697104981867597e-05\n",
      "Penalty params: tau=0.50115 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1500 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1500, train\n",
      " fgw:0.2049820\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2049820\n",
      "Measure Epoch 1500, train\n",
      " similarity:0.0337640\n",
      " penlog:-88.5615264\n",
      "Metrics Epoch 1500, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.3800000\n",
      " batch_invalid_valency_nodes:23.9130435\n",
      " batch_nodes_0degree:1.5200000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.9800000\n",
      " batch_node_degree:2.6634783\n",
      "Logits [20.150066375732422, 2.557568073272705, 65.24191284179688]\n",
      "Epoch duration: 2.6140382289886475\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1500\n",
      "Epoch: 1501\n",
      "FGW torch.Size([29508, 5]) 6.938915612408891e-05\n",
      "Penalty params: tau=0.50092 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1501 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1501, train\n",
      " fgw:0.2031063\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2031063\n",
      "Measure Epoch 1501, train\n",
      " similarity:0.0288529\n",
      " penlog:-92.3227074\n",
      "Metrics Epoch 1501, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.6200000\n",
      " batch_invalid_valency_nodes:27.2173913\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.1200000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:32.0000000\n",
      " avg_euler_error:3.4600000\n",
      " batch_node_degree:2.9460870\n",
      "Logits [20.14612579345703, 2.559720516204834, 65.46485137939453]\n",
      "Epoch duration: 2.349207639694214\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1502\n",
      "FGW torch.Size([29508, 5]) 6.584806396858767e-05\n",
      "Penalty params: tau=0.50069 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1502 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1502, train\n",
      " fgw:0.1955480\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1955480\n",
      "Measure Epoch 1502, train\n",
      " similarity:0.0379110\n",
      " penlog:-86.1232546\n",
      "Metrics Epoch 1502, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.8800000\n",
      " batch_invalid_valency_nodes:25.2173913\n",
      " batch_nodes_0degree:1.6000000\n",
      " batch_nodes_7plus_degree:0.9000000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:2.0000000\n",
      " avg_euler_error:0.2800000\n",
      " batch_node_degree:2.6643478\n",
      "Logits [20.009492874145508, 2.5429699420928955, 65.05558776855469]\n",
      "Epoch duration: 2.3699824810028076\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1502\n",
      "Epoch: 1503\n",
      "FGW torch.Size([29508, 5]) 6.683285027975217e-05\n",
      "Penalty params: tau=0.50046 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1503 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1503, train\n",
      " fgw:0.1953279\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1953279\n",
      "Measure Epoch 1503, train\n",
      " similarity:0.0290965\n",
      " penlog:-92.2190614\n",
      "Metrics Epoch 1503, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.8800000\n",
      " batch_invalid_valency_nodes:25.6521739\n",
      " batch_nodes_0degree:1.0600000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:16.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.6400000\n",
      " batch_node_degree:2.8826087\n",
      "Logits [19.59373664855957, 2.4802463054656982, 63.72377014160156]\n",
      "Epoch duration: 2.26649808883667\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1503\n",
      "Epoch: 1504\n",
      "FGW torch.Size([29508, 5]) 6.727698200847954e-05\n",
      "Penalty params: tau=0.50023 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1504 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1504, train\n",
      " fgw:0.1922209\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1922209\n",
      "Measure Epoch 1504, train\n",
      " similarity:0.0269433\n",
      " penlog:-92.5290921\n",
      "Metrics Epoch 1504, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:2.9800000\n",
      " batch_invalid_valency_nodes:25.6521739\n",
      " batch_nodes_0degree:1.3200000\n",
      " batch_nodes_7plus_degree:0.9200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:2.6100000\n",
      " batch_node_degree:2.8217391\n",
      "Logits [19.25206184387207, 2.411276340484619, 62.48430252075195]\n",
      "Epoch duration: 2.1351120471954346\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1504\n",
      "Epoch: 1505\n",
      "FGW torch.Size([29508, 5]) 6.494207627838477e-05\n",
      "Penalty params: tau=0.50000 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1505 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1505, train\n",
      " fgw:0.1854150\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1854150\n",
      "Measure Epoch 1505, train\n",
      " similarity:0.0274908\n",
      " penlog:-90.1802871\n",
      "Metrics Epoch 1505, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.7800000\n",
      " batch_invalid_valency_nodes:24.4347826\n",
      " batch_nodes_0degree:1.5600000\n",
      " batch_nodes_7plus_degree:0.7800000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:4.0000000\n",
      " avg_euler_error:0.6500000\n",
      " batch_node_degree:2.6678261\n",
      "Logits [19.474451065063477, 2.4361703395843506, 63.35659408569336]\n",
      "Epoch duration: 2.327239513397217\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1505\n",
      "Epoch: 1506\n",
      "FGW torch.Size([29508, 5]) 6.76247727824375e-05\n",
      "Penalty params: tau=0.49977 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1506 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1506, train\n",
      " fgw:0.2011875\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2011875\n",
      "Measure Epoch 1506, train\n",
      " similarity:0.0284993\n",
      " penlog:-92.2040362\n",
      "Metrics Epoch 1506, train\n",
      " batch_molecular_validity:4.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:8.0000000\n",
      " batch_connected_components:3.1600000\n",
      " batch_invalid_valency_nodes:25.5652174\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:1.0200000\n",
      " invalid_euler_toofew:28.0000000\n",
      " invalid_euler_toomany:18.0000000\n",
      " avg_euler_error:1.4900000\n",
      " batch_node_degree:2.8234783\n",
      "Logits [19.578807830810547, 2.441092014312744, 63.787601470947266]\n",
      "Epoch duration: 2.602619171142578\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1506\n",
      "Epoch: 1507\n",
      "FGW torch.Size([29508, 5]) 6.795151421101764e-05\n",
      "Penalty params: tau=0.49954 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1507 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1507, train\n",
      " fgw:0.1945411\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1945411\n",
      "Measure Epoch 1507, train\n",
      " similarity:0.0030508\n",
      " penlog:-98.0353212\n",
      "Metrics Epoch 1507, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:2.0000000\n",
      " batch_connected_components:2.7200000\n",
      " batch_invalid_valency_nodes:27.3043478\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.8800000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:2.9300000\n",
      " batch_node_degree:2.9191304\n",
      "Logits [19.63673210144043, 2.426389455795288, 64.19905090332031]\n",
      "Epoch duration: 2.422372579574585\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1507\n",
      "Epoch: 1508\n",
      "FGW torch.Size([29508, 5]) 6.672973540844396e-05\n",
      "Penalty params: tau=0.49931 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1508 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1508, train\n",
      " fgw:0.1892939\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1892939\n",
      "Measure Epoch 1508, train\n",
      " similarity:0.0360931\n",
      " penlog:-88.4342051\n",
      "Metrics Epoch 1508, train\n",
      " batch_molecular_validity:6.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:2.9200000\n",
      " batch_invalid_valency_nodes:25.3913043\n",
      " batch_nodes_0degree:1.2600000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:12.0000000\n",
      " avg_euler_error:1.8500000\n",
      " batch_node_degree:2.7747826\n",
      "Logits [19.595706939697266, 2.413236618041992, 64.31444549560547]\n",
      "Epoch duration: 2.314160108566284\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1508\n",
      "Epoch: 1509\n",
      "FGW torch.Size([29508, 5]) 6.679845682810992e-05\n",
      "Penalty params: tau=0.49908 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1509 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1509, train\n",
      " fgw:0.1868598\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1868598\n",
      "Measure Epoch 1509, train\n",
      " similarity:0.0227661\n",
      " penlog:-94.0817729\n",
      "Metrics Epoch 1509, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.1304348\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:3.5000000\n",
      " batch_invalid_valency_nodes:25.0434783\n",
      " batch_nodes_0degree:1.2800000\n",
      " batch_nodes_7plus_degree:0.9400000\n",
      " invalid_euler_toofew:26.0000000\n",
      " invalid_euler_toomany:14.0000000\n",
      " avg_euler_error:1.5100000\n",
      " batch_node_degree:2.7834783\n",
      "Logits [19.64542579650879, 2.4193973541259766, 64.7335205078125]\n",
      "Epoch duration: 2.5206005573272705\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1509\n",
      "Epoch: 1510\n",
      "FGW torch.Size([29508, 5]) 6.684721302008256e-05\n",
      "Penalty params: tau=0.49885 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1510 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1510, train\n",
      " fgw:0.1904486\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1904486\n",
      "Measure Epoch 1510, train\n",
      " similarity:0.0103669\n",
      " penlog:-90.5474511\n",
      "Metrics Epoch 1510, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.8800000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:1.2400000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.7400000\n",
      " batch_node_degree:2.9121739\n",
      "Logits [19.71341896057129, 2.4490606784820557, 65.03137969970703]\n",
      "Epoch duration: 2.5209364891052246\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1511\n",
      "FGW torch.Size([29508, 5]) 6.656096229562536e-05\n",
      "Penalty params: tau=0.49862 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1511 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1511, train\n",
      " fgw:0.1972249\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1972249\n",
      "Measure Epoch 1511, train\n",
      " similarity:0.0207692\n",
      " penlog:-96.0507562\n",
      "Metrics Epoch 1511, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.0434783\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.6000000\n",
      " batch_invalid_valency_nodes:26.0000000\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:0.9600000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.3000000\n",
      " batch_node_degree:2.8226087\n",
      "Logits [19.626070022583008, 2.4608750343322754, 64.98458099365234]\n",
      "Epoch duration: 2.5520453453063965\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1511\n",
      "Epoch: 1512\n",
      "FGW torch.Size([29508, 5]) 6.57949858577922e-05\n",
      "Penalty params: tau=0.49839 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1512 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1512, train\n",
      " fgw:0.1952490\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1952490\n",
      "Measure Epoch 1512, train\n",
      " similarity:0.0241791\n",
      " penlog:-96.0384610\n",
      "Metrics Epoch 1512, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.7400000\n",
      " batch_invalid_valency_nodes:21.7391304\n",
      " batch_nodes_0degree:1.2200000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:6.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:1.6300000\n",
      " batch_node_degree:2.7495652\n",
      "Logits [19.895984649658203, 2.5197253227233887, 65.80957794189453]\n",
      "Epoch duration: 2.4534528255462646\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1512\n",
      "Epoch: 1513\n",
      "FGW torch.Size([29508, 5]) 6.567951641045511e-05\n",
      "Penalty params: tau=0.49816 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1513 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1513, train\n",
      " fgw:0.1869271\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1869271\n",
      "Measure Epoch 1513, train\n",
      " similarity:0.0242638\n",
      " penlog:-94.0762506\n",
      "Metrics Epoch 1513, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:6.0000000\n",
      " batch_connected_components:2.6800000\n",
      " batch_invalid_valency_nodes:26.1739130\n",
      " batch_nodes_0degree:1.1000000\n",
      " batch_nodes_7plus_degree:1.3000000\n",
      " invalid_euler_toofew:4.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:2.8000000\n",
      " batch_node_degree:2.9747826\n",
      "Logits [20.210132598876953, 2.5741183757781982, 66.80962371826172]\n",
      "Epoch duration: 2.620311737060547\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1513\n",
      "Epoch: 1514\n",
      "FGW torch.Size([29508, 5]) 6.241907976800576e-05\n",
      "Penalty params: tau=0.49793 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1514 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1514, train\n",
      " fgw:0.1814769\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1814769\n",
      "Measure Epoch 1514, train\n",
      " similarity:0.0291314\n",
      " penlog:-90.2269253\n",
      "Metrics Epoch 1514, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:3.2600000\n",
      " batch_invalid_valency_nodes:22.3478261\n",
      " batch_nodes_0degree:1.6200000\n",
      " batch_nodes_7plus_degree:0.6800000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:8.0000000\n",
      " avg_euler_error:0.6100000\n",
      " batch_node_degree:2.6182609\n",
      "Logits [20.352741241455078, 2.596097230911255, 67.0698471069336]\n",
      "Epoch duration: 2.5570390224456787\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1514\n",
      "Epoch: 1515\n",
      "FGW torch.Size([29508, 5]) 6.59154902677983e-05\n",
      "Penalty params: tau=0.49770 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1515 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1515, train\n",
      " fgw:0.1955452\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1955452\n",
      "Measure Epoch 1515, train\n",
      " similarity:0.0350910\n",
      " penlog:-86.2936758\n",
      "Metrics Epoch 1515, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:14.0000000\n",
      " batch_connected_components:3.0600000\n",
      " batch_invalid_valency_nodes:23.3043478\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:14.0000000\n",
      " invalid_euler_toomany:16.0000000\n",
      " avg_euler_error:1.6900000\n",
      " batch_node_degree:2.7113043\n",
      "Logits [20.057952880859375, 2.539869546890259, 65.93824005126953]\n",
      "Epoch duration: 2.3451693058013916\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1515\n",
      "Epoch: 1516\n",
      "FGW torch.Size([29508, 5]) 6.781961565138772e-05\n",
      "Penalty params: tau=0.49747 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1516 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1516, train\n",
      " fgw:0.1895035\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1895035\n",
      "Measure Epoch 1516, train\n",
      " similarity:0.0348855\n",
      " penlog:-84.6543529\n",
      "Metrics Epoch 1516, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.2173913\n",
      " batch_molecular_disconnected_validity:16.0000000\n",
      " batch_connected_components:2.9000000\n",
      " batch_invalid_valency_nodes:26.1739130\n",
      " batch_nodes_0degree:1.1400000\n",
      " batch_nodes_7plus_degree:1.2000000\n",
      " invalid_euler_toofew:20.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.2200000\n",
      " batch_node_degree:2.8713043\n",
      "Logits [19.584640502929688, 2.4459311962127686, 64.18526458740234]\n",
      "Epoch duration: 2.424072742462158\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1516\n",
      "Epoch: 1517\n",
      "FGW torch.Size([29508, 5]) 6.545029464177787e-05\n",
      "Penalty params: tau=0.49724 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1517 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1517, train\n",
      " fgw:0.1938777\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1938777\n",
      "Measure Epoch 1517, train\n",
      " similarity:0.0302248\n",
      " penlog:-88.2647584\n",
      "Metrics Epoch 1517, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3043478\n",
      " batch_molecular_disconnected_validity:12.0000000\n",
      " batch_connected_components:3.4000000\n",
      " batch_invalid_valency_nodes:24.3478261\n",
      " batch_nodes_0degree:1.3400000\n",
      " batch_nodes_7plus_degree:0.7600000\n",
      " invalid_euler_toofew:30.0000000\n",
      " invalid_euler_toomany:10.0000000\n",
      " avg_euler_error:0.8700000\n",
      " batch_node_degree:2.6782609\n",
      "Logits [19.272062301635742, 2.381369113922119, 63.11331558227539]\n",
      "Epoch duration: 2.6439783573150635\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1517\n",
      "Epoch: 1518\n",
      "FGW torch.Size([29508, 5]) 6.723825208609924e-05\n",
      "Penalty params: tau=0.49702 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1518 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1518, train\n",
      " fgw:0.1994733\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1994733\n",
      "Measure Epoch 1518, train\n",
      " similarity:0.0331463\n",
      " penlog:-90.3284245\n",
      "Metrics Epoch 1518, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.4782609\n",
      " batch_molecular_disconnected_validity:10.0000000\n",
      " batch_connected_components:2.8600000\n",
      " batch_invalid_valency_nodes:24.5217391\n",
      " batch_nodes_0degree:1.0400000\n",
      " batch_nodes_7plus_degree:0.7200000\n",
      " invalid_euler_toofew:10.0000000\n",
      " invalid_euler_toomany:20.0000000\n",
      " avg_euler_error:2.4200000\n",
      " batch_node_degree:2.7886957\n",
      "Logits [19.491939544677734, 2.4078543186187744, 63.91706466674805]\n",
      "Epoch duration: 2.4499423503875732\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1518\n",
      "Epoch: 1519\n",
      "FGW torch.Size([29508, 5]) 6.625780224567279e-05\n",
      "Penalty params: tau=0.49679 conn_l=0.00100 val_l=0.00100 euler_l=1.00000 epoch=1519 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 1519, train\n",
      " fgw:0.1955942\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.1955942\n",
      "Measure Epoch 1519, train\n",
      " similarity:0.0215000\n",
      " penlog:-96.0581233\n",
      "Metrics Epoch 1519, train\n",
      " batch_molecular_validity:2.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:99.3913043\n",
      " batch_molecular_disconnected_validity:4.0000000\n",
      " batch_connected_components:2.2800000\n",
      " batch_invalid_valency_nodes:27.1304348\n",
      " batch_nodes_0degree:0.9000000\n",
      " batch_nodes_7plus_degree:0.8000000\n",
      " invalid_euler_toofew:12.0000000\n",
      " invalid_euler_toomany:22.0000000\n",
      " avg_euler_error:3.0800000\n",
      " batch_node_degree:2.9278261\n",
      "Logits [19.72074317932129, 2.441481828689575, 64.70164489746094]\n",
      "Epoch duration: 2.635432720184326\n",
      "mol_opt/output_dev2/ffn-base-nopen-gumbel1/model_ffn-base-nopen-gumbel1_1519\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:262] . unexpected pos 194218432 vs 194218320",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b0c0228fb046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mcleanup_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(molopt, molopt_decoder, optimizer, penalty, scheduler, epoch, args, outfile)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m'scheduler'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     }\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:262] . unexpected pos 194218432 vs 194218320"
     ]
    }
   ],
   "source": [
    "molopt, molopt_decoder = main(args, train_data_loader = train_data_loader, val_data_loader = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "molopt, molopt_decoder = main(args, train_data_loader = train_data_loader, val_data_loader = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.7234, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in train_data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break\n",
    "    \n",
    "x_embedding = molopt.forward(X)\n",
    "yhat_logits = molopt_decoder.forward(x_embedding, X, Y)\n",
    "yhat_labels = molopt_decoder.discretize_argmax(*yhat_logits)\n",
    "# yhat_labels = molopt_decoder.discretize(*yhat_logits)\n",
    "pred_pack = (yhat_labels, yhat_logits, Y.scope), Y \n",
    "\n",
    "target = Y.get_graph_outputs()\n",
    "symbols_labels, charges_labels, bonds_labels = yhat_labels\n",
    "symbols_logits, charges_logits, bonds_logits = yhat_logits\n",
    "\n",
    "from mol_opt.ot_utils import FGW \n",
    "fgw_loss = FGW(alpha = 0.5)\n",
    "fgw_loss(*pred_pack, tau = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.Adam([torch.autograd.Variable(torch.Tensor([0.]))]).param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5833011217497763"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "99 ** (1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuda': True,\n",
       " 'output_dir': 'mol_opt/output_dev1/pointwise-test5',\n",
       " 'tb_logs_dir': 'mol_opt/logs_dev1/pointwise-test5',\n",
       " 'init_model': 'pointwise-test5',\n",
       " 'init_decoder_model': 'pointwise-test5_decode',\n",
       " 'task': 'qed',\n",
       " 'model_type': 'pointwise',\n",
       " 'one_batch_train': True,\n",
       " 'batch_size': 50,\n",
       " 'pred_hidden': 150,\n",
       " 'pc_hidden': 100,\n",
       " 'ffn_activation': 'LeakyReLU',\n",
       " 'n_epochs': 1000,\n",
       " 'dim_tangent_space': 40,\n",
       " 'n_layers': 5,\n",
       " 'n_hidden': 250,\n",
       " 'n_ffn_hidden': 100,\n",
       " 'linear_out': False,\n",
       " 'dropout_gcn': 0.0,\n",
       " 'dropout_ffn': 0.0,\n",
       " 'agg_func': 'sum',\n",
       " 'batch_norm': False,\n",
       " 'N_transformer': 6,\n",
       " 'n_ffn_transformer': 100,\n",
       " 'n_heads_transformer': 10,\n",
       " 'dropout_transformer': 0.1,\n",
       " 'ot_solver': 'emd',\n",
       " 'sinkhorn_entropy': 0.1,\n",
       " 'sinkhorn_max_it': 10000,\n",
       " 'connectivity': False,\n",
       " 'valency': True,\n",
       " 'euler_characteristic_penalty': True,\n",
       " 'annealing_rate': 0.002,\n",
       " 'connectivity_lambda': 0,\n",
       " 'valency_lambda': 0,\n",
       " 'euler_lambda': 1,\n",
       " 'connectivity_hard': False,\n",
       " 'valency_hard': False,\n",
       " 'scale_lambdas': False,\n",
       " 'conn_penalty_function': 'logdet',\n",
       " 'penalty_gumbel': False,\n",
       " 'device': 'cuda:0',\n",
       " 'n_labels': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(\"/home/octav/gitrepos/tum-thesis/mol_opt/dev7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    \"pointwise10-dev8/train_avg_euler_error/mean\",\n",
    "    \"pointwise10-dev8/train_avg_euler_error/bot_band\",\n",
    "    \"pointwise10-dev8/train_avg_euler_error/top_band\"\n",
    "]\n",
    "# writer.add_custom_scalars_marginchart(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_scalar(\"plm2/plm2\", 0, 1)\n",
    "# writer.add_scalar(\"plm2/plm2\", 1, 2)\n",
    "# writer.add_scalar(\"plm2/plm2\", 0, 3)\n",
    "# writer.add_scalar(\"plm2/plm2\", 1, 4)\n",
    "tags = [\"plm\", \"plm\", \"plm\"]\n",
    "# layout = {\"plm\" : {\"plm\" : [\"Margin\", tags]}}\n",
    "layout = {\"plm1\" : {\"plm\" : [\"Margin\", tags], \"plm2\": [\"Multiline\", tags]},\n",
    "          \"plm2\": {\"plm\" : [\"Margin\", tags], \"plm2\": [\"Multiline\", tags]}}\n",
    "writer.add_custom_scalars(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_summary() missing 1 required positional argument: 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5a2081fe54a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: add_summary() missing 1 required positional argument: 'summary'"
     ]
    }
   ],
   "source": [
    "writer._get_file_writer().add_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/octav/gitrepos/tum-thesis/mol_opt/dev6'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer.logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboardX\n",
    "tensorboardX.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX.summary import custom_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer._get_file_writer().add_summary(custom_scalars(layout), global_step = 3)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars('plm', {'plm0' : 0.0, 'plmt' : 0.1, 'plmb' : -0.1}, 3)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "symbols_nll, charges_nll, bonds_nll = F.gumbel_softmax(tau = tau, dim=1, logits = symbols_logits), F.gumbel_softmax(tau=tau,dim=1,logits=charges_logits), F.gumbel_softmax(tau=tau,dim=1, logits = bonds_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(symbols_nll.mean(axis = 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "molopt.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load('mol_opt/output_pointwise10-onebatch/model_pointwise10-onebatch_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"model\"]['opt0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt2 = MolOpt(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt2.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt2.load_state_dict(model_dict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt2.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt3,args3 = load_model('mol_opt/output_pointwise10-onebatch/model_pointwise10-onebatch_8', MolOpt, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(molopt3.opt0.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgw_loss(*pred_pack, tau = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
