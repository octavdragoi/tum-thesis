{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, get_latest_model\n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "from mol_opt.log_mol_opt import format_data_name, load_data, save_data\n",
    "from mol_opt.task_metrics import measure_task\n",
    "from otgnn.utils import save_model, load_model, StatsTracker, log_tensorboard\n",
    "from molgen.metrics.mol_metrics import MolMetrics\n",
    "from tensorboardX import SummaryWriter\n",
    "from mol_opt.log_mol_opt import do_epoch\n",
    "from otgnn.graph import SYMBOLS, FORMAL_CHARGES, BOND_TYPES\n",
    "from pathlib import Path\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(N_transformer=6, agg_func='sum', batch_norm=False, batch_size=50, conn_lambda_end=30, conn_lambda_epochs_end=14000, conn_lambda_epochs_start=12000, conn_lambda_start=1, conn_penalty_function='capped_logdet', connectivity=False, connectivity_hard=False, cuda=True, device='cuda:0', dim_tangent_space=40, dropout_ffn=0.0, dropout_gcn=0.0, dropout_transformer=0.1, euler_characteristic_penalty=False, euler_lambda_end=20, euler_lambda_epochs_end=14000, euler_lambda_epochs_start=12000, euler_lambda_start=1, ffn_activation='LeakyReLU', init_decoder_model='pointwise-test3_decode', init_model='pointwise-test3', linear_out=False, max_num_atoms=70, model_type='pointwise', n_epochs=20, n_ffn_hidden=100, n_ffn_transformer=100, n_heads_transformer=10, n_hidden=200, n_labels=1, n_layers=5, one_batch_train=False, ot_solver='emd', output_dir='mol_opt/output_dev2/pointwise-test3', pc_hidden=150, penalty_gumbel=False, pred_hidden=150, scale_lambdas=True, sinkhorn_entropy=0.1, sinkhorn_max_it=10000, task='qed', tau_end=0.001, tau_epochs_end=16000, tau_epochs_start=1, tau_start=1, tb_logs_dir='mol_opt/logs_dev2/pointwise-test3', valency=False, valency_hard=False, valency_lambda_end=50, valency_lambda_epochs_end=14000, valency_lambda_epochs_start=12000, valency_lambda_start=10) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = \"pointwise\"\n",
    "sys.argv = [\"\", \"-cuda\", \"-model_type\", model_type]\n",
    "args = get_args()\n",
    "outdir_suffix = \"dev2\"\n",
    "args.n_epochs = 20 \n",
    "args.init_model = \"{}-test3\".format(model_type)\n",
    "# args.init_model = \"{}-test1\".format(model_type)\n",
    "args.init_decoder_model = \"{}_decode\".format(args.init_model)\n",
    "args.output_dir = \"mol_opt/output_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "args.tb_logs_dir = \"mol_opt/logs_{}/{}\".format(outdir_suffix, args.init_model)\n",
    "args.batch_size = 50 \n",
    "\n",
    "args.penalty_gumbel = False \n",
    "\n",
    "args.scale_lambdas = True\n",
    "args.connectivity = False \n",
    "args.valency = False \n",
    "args.euler_characteristic_penalty = False\n",
    "args.conn_lambda_start = 1\n",
    "args.conn_lambda_end = 30\n",
    "args.conn_lambda_epochs_start = 12000\n",
    "args.conn_lambda_epochs_end = 14000\n",
    "args.valency_lambda_start = 10\n",
    "args.valency_lambda_end = 50\n",
    "args.valency_lambda_epochs_start = 12000\n",
    "args.valency_lambda_epochs_end = 14000\n",
    "args.euler_lambda_start = 1\n",
    "args.euler_lambda_end = 20 \n",
    "args.euler_lambda_epochs_start = 12000\n",
    "args.euler_lambda_epochs_end = 14000\n",
    "args.tau_start = 1\n",
    "args.tau_end = 0.001\n",
    "args.tau_epochs_start = 1\n",
    "args.tau_epochs_end = 16000\n",
    "\n",
    "\n",
    "args.conn_penalty_function = \"capped_logdet\" \n",
    "\n",
    "print(args, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train_pairs\", args.batch_size, same_number_atoms = True)\n",
    "train_data_loader = get_loader(\"molgen/data/chembl50\", \"raw\", args.batch_size, same_number_atoms = False)\n",
    "# val_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"valid\", 36, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found previous model mol_opt/output_dev2/pointwise-test3/model_pointwise-test3_9, epoch 9. Overwriting args.\n",
      "Epoch: 10\n",
      "FGW torch.Size([29508, 5]) 8.44663882162422e-05\n",
      "FGW torch.Size([29508, 5]) 8.476530638290569e-05\n",
      "FGW torch.Size([29508, 5]) 8.318025356857106e-05\n",
      "FGW torch.Size([29508, 5]) 8.440942474408075e-05\n",
      "FGW torch.Size([29508, 5]) 8.497113594785333e-05\n",
      "FGW torch.Size([29508, 5]) 8.4500148659572e-05\n",
      "FGW torch.Size([29508, 5]) 8.171048102667555e-05\n",
      "FGW torch.Size([29508, 5]) 8.48886338644661e-05\n",
      "FGW torch.Size([29508, 5]) 8.171058289008215e-05\n",
      "FGW torch.Size([29508, 5]) 8.348158007720485e-05\n",
      "FGW torch.Size([29508, 5]) 8.104809967335314e-05\n",
      "FGW torch.Size([29508, 5]) 8.42040462885052e-05\n",
      "FGW torch.Size([29508, 5]) 8.258300658781081e-05\n",
      "FGW torch.Size([29508, 5]) 8.167204941855744e-05\n",
      "FGW torch.Size([29508, 5]) 8.674088167026639e-05\n",
      "FGW torch.Size([29508, 5]) 7.465166709152982e-05\n",
      "FGW torch.Size([29508, 5]) 8.951355266617611e-05\n",
      "FGW torch.Size([29508, 5]) 7.280457793967798e-05\n",
      "FGW torch.Size([29508, 5]) 8.326781244250014e-05\n",
      "FGW torch.Size([29508, 5]) 9.300903911935166e-05\n",
      "FGW torch.Size([29508, 5]) 6.906251655891538e-05\n",
      "FGW torch.Size([29508, 5]) 8.018124208319932e-05\n",
      "FGW torch.Size([29508, 5]) 0.00010581541573628783\n",
      "FGW torch.Size([29508, 5]) 6.904915062477812e-05\n",
      "FGW torch.Size([29508, 5]) 7.211160118458793e-05\n",
      "FGW torch.Size([29508, 5]) 0.00011406528938096017\n",
      "FGW torch.Size([29508, 5]) 7.277470285771415e-05\n",
      "FGW torch.Size([29508, 5]) 6.941983883734792e-05\n",
      "Penalty params: tau=0.99569 conn_l=1.00000 val_l=10.00000 euler_l=1.00000 epoch=10 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 10, train\n",
      " fgw:0.2360697\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2360697\n",
      "Epoch duration: 41.45974016189575\n",
      "mol_opt/output_dev2/pointwise-test3/model_pointwise-test3_10\n",
      "Epoch: 11\n",
      "FGW torch.Size([29508, 5]) 9.236102778231725e-05\n",
      "FGW torch.Size([29508, 5]) 9.775890794117004e-05\n",
      "FGW torch.Size([29508, 5]) 7.47261947253719e-05\n",
      "FGW torch.Size([29508, 5]) 7.697689579799771e-05\n",
      "FGW torch.Size([29508, 5]) 9.498444705968723e-05\n",
      "FGW torch.Size([29508, 5]) 9.643317753216252e-05\n",
      "FGW torch.Size([29508, 5]) 7.561493839602917e-05\n",
      "FGW torch.Size([29508, 5]) 7.27006045053713e-05\n",
      "FGW torch.Size([29508, 5]) 8.792323933448642e-05\n",
      "FGW torch.Size([29508, 5]) 9.829048940446228e-05\n",
      "FGW torch.Size([29508, 5]) 8.0769372289069e-05\n",
      "FGW torch.Size([29508, 5]) 7.504983659600839e-05\n",
      "FGW torch.Size([29508, 5]) 8.25597089715302e-05\n",
      "FGW torch.Size([29508, 5]) 9.440055146114901e-05\n",
      "FGW torch.Size([29508, 5]) 7.908116822363809e-05\n",
      "FGW torch.Size([29508, 5]) 7.51946572563611e-05\n",
      "FGW torch.Size([29508, 5]) 8.162968879332766e-05\n",
      "FGW torch.Size([29508, 5]) 9.150183905148879e-05\n",
      "FGW torch.Size([29508, 5]) 8.415912452619523e-05\n",
      "FGW torch.Size([29508, 5]) 7.728811033302918e-05\n",
      "FGW torch.Size([29508, 5]) 8.058578532654792e-05\n",
      "FGW torch.Size([29508, 5]) 8.670079841976985e-05\n",
      "FGW torch.Size([29508, 5]) 7.972966704983264e-05\n",
      "FGW torch.Size([29508, 5]) 7.80800764914602e-05\n",
      "FGW torch.Size([29508, 5]) 8.211014210246503e-05\n",
      "FGW torch.Size([29508, 5]) 8.549605263397098e-05\n",
      "FGW torch.Size([29508, 5]) 7.954535976750776e-05\n",
      "FGW torch.Size([29508, 5]) 7.647329766768962e-05\n",
      "Penalty params: tau=0.99526 conn_l=1.00000 val_l=10.00000 euler_l=1.00000 epoch=11 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 11, train\n",
      " fgw:0.2338669\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2338669\n",
      "Epoch duration: 41.9144561290741\n",
      "mol_opt/output_dev2/pointwise-test3/model_pointwise-test3_11\n",
      "Epoch: 12\n",
      "FGW torch.Size([29508, 5]) 8.061893458943814e-05\n",
      "FGW torch.Size([29508, 5]) 8.277118467958644e-05\n",
      "FGW torch.Size([29508, 5]) 7.847953384043649e-05\n",
      "FGW torch.Size([29508, 5]) 7.782662578392774e-05\n",
      "FGW torch.Size([29508, 5]) 8.134637755574659e-05\n",
      "FGW torch.Size([29508, 5]) 8.068301394814625e-05\n",
      "FGW torch.Size([29508, 5]) 7.783230830682442e-05\n",
      "FGW torch.Size([29508, 5]) 7.951815496198833e-05\n",
      "FGW torch.Size([29508, 5]) 8.005815470824018e-05\n",
      "FGW torch.Size([29508, 5]) 7.701954746153206e-05\n",
      "FGW torch.Size([29508, 5]) 7.816273864591494e-05\n",
      "FGW torch.Size([29508, 5]) 8.193197572836652e-05\n",
      "FGW torch.Size([29508, 5]) 7.736295083304867e-05\n",
      "FGW torch.Size([29508, 5]) 7.787990034557879e-05\n",
      "FGW torch.Size([29508, 5]) 8.035327482502908e-05\n",
      "FGW torch.Size([29508, 5]) 7.658330287085846e-05\n",
      "FGW torch.Size([29508, 5]) 7.67632300266996e-05\n",
      "FGW torch.Size([29508, 5]) 8.25743263703771e-05\n",
      "FGW torch.Size([29508, 5]) 7.755288243060932e-05\n",
      "FGW torch.Size([29508, 5]) 7.43732089176774e-05\n",
      "FGW torch.Size([29508, 5]) 7.885500963311642e-05\n",
      "FGW torch.Size([29508, 5]) 7.98614346422255e-05\n",
      "FGW torch.Size([29508, 5]) 7.525556429754943e-05\n",
      "FGW torch.Size([29508, 5]) 7.798883598297834e-05\n",
      "FGW torch.Size([29508, 5]) 7.975524931680411e-05\n",
      "FGW torch.Size([29508, 5]) 7.583240221720189e-05\n",
      "FGW torch.Size([29508, 5]) 7.816679863026366e-05\n",
      "FGW torch.Size([29508, 5]) 7.783171167830005e-05\n",
      "Penalty params: tau=0.99483 conn_l=1.00000 val_l=10.00000 euler_l=1.00000 epoch=12 mode=[0 0 0] conn=False euler=False val=False\n",
      "Losses Epoch 12, train\n",
      " fgw:0.2177049\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.2177049\n",
      "Epoch duration: 41.54781699180603\n",
      "mol_opt/output_dev2/pointwise-test3/model_pointwise-test3_12\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'mol_opt/output_dev2/pointwise-test3/data_pointwise-test3_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0c0228fb046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mcleanup_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/log_mol_opt.py\u001b[0m in \u001b[0;36mcleanup_dir\u001b[0;34m(outdir, lastepoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mep_diff\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmodulo\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodulo\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'mol_opt/output_dev2/pointwise-test3/data_pointwise-test3_1'"
     ]
    }
   ],
   "source": [
    "molopt, molopt_decoder = main(args, train_data_loader = train_data_loader, val_data_loader = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol_opt/output_dev2/pointwise-test3/data_pointwise-test3_1\n",
      "mol_opt/output_dev2/pointwise-test3/data_pointwise-test3_1/train_0.out\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(args.output_dir, format_data_name(args.init_model, 1))\n",
    "data_path = os.path.join(dir_path,  \"{}_{}.out\".format(\"train\", 0))\n",
    "print(dir_path)\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaded_dict = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fgw': 3.595323181152344,\n",
       "  'conn_penalty': 0.0,\n",
       "  'val_penalty': 0.0,\n",
       "  'euler_penalty': 0.0,\n",
       "  'total': 3.595323181152344},\n",
       " {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict['losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((tensor([13, 16, 13,  ..., 16, 13, 16]),\n",
       "   tensor([3, 3, 3,  ..., 3, 3, 3]),\n",
       "   tensor([4, 3, 3,  ..., 3, 3, 4])),\n",
       "  (tensor([[ 0.0350, -0.0453,  0.0178,  ...,  0.0346,  0.0418,  0.0557],\n",
       "           [ 0.0379, -0.0453,  0.0105,  ...,  0.0288,  0.0465,  0.0678],\n",
       "           [ 0.0359, -0.0464,  0.0111,  ...,  0.0294,  0.0486,  0.0723],\n",
       "           ...,\n",
       "           [ 0.0301, -0.0401, -0.0013,  ...,  0.0228,  0.0227,  0.0632],\n",
       "           [ 0.0202, -0.0440,  0.0079,  ...,  0.0279,  0.0306,  0.0590],\n",
       "           [ 0.0313, -0.0441,  0.0051,  ...,  0.0284,  0.0359,  0.0638]],\n",
       "          requires_grad=True),\n",
       "   tensor([[-0.0535, -0.0756, -0.0574,  0.0841,  0.0702],\n",
       "           [-0.0626, -0.0684, -0.0577,  0.0855,  0.0658],\n",
       "           [-0.0646, -0.0687, -0.0570,  0.0848,  0.0647],\n",
       "           ...,\n",
       "           [-0.0413, -0.0713, -0.0632,  0.0848,  0.0673],\n",
       "           [-0.0441, -0.0737, -0.0660,  0.0869,  0.0692],\n",
       "           [-0.0530, -0.0668, -0.0542,  0.0797,  0.0673]], requires_grad=True),\n",
       "   tensor([[-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0000e+03],\n",
       "           [-6.3665e-02,  1.4003e-02, -2.1929e-02,  1.0894e-01,  2.5072e-02],\n",
       "           [-6.5902e-02,  1.5487e-02, -1.7059e-02,  1.1256e-01,  2.8185e-02],\n",
       "           ...,\n",
       "           [-6.4162e-02,  1.3389e-02, -2.3896e-02,  1.0987e-01,  2.1035e-02],\n",
       "           [-6.1098e-02,  1.0536e-02, -1.1558e-02,  1.0443e-01,  2.9472e-02],\n",
       "           [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0000e+03]],\n",
       "          requires_grad=True)),\n",
       "  [(0, 25),\n",
       "   (25, 16),\n",
       "   (41, 29),\n",
       "   (70, 35),\n",
       "   (105, 21),\n",
       "   (126, 47),\n",
       "   (173, 18),\n",
       "   (191, 23),\n",
       "   (214, 23),\n",
       "   (237, 18),\n",
       "   (255, 16),\n",
       "   (271, 23),\n",
       "   (294, 18),\n",
       "   (312, 21),\n",
       "   (333, 7),\n",
       "   (340, 12),\n",
       "   (352, 12),\n",
       "   (364, 21),\n",
       "   (385, 17),\n",
       "   (402, 23),\n",
       "   (425, 25),\n",
       "   (450, 27),\n",
       "   (477, 30),\n",
       "   (507, 25),\n",
       "   (532, 23),\n",
       "   (555, 21),\n",
       "   (576, 14),\n",
       "   (590, 19),\n",
       "   (609, 32),\n",
       "   (641, 28),\n",
       "   (669, 24),\n",
       "   (693, 26),\n",
       "   (719, 17),\n",
       "   (736, 26),\n",
       "   (762, 20),\n",
       "   (782, 22),\n",
       "   (804, 43),\n",
       "   (847, 28),\n",
       "   (875, 13),\n",
       "   (888, 24),\n",
       "   (912, 25),\n",
       "   (937, 18),\n",
       "   (955, 34),\n",
       "   (989, 25),\n",
       "   (1014, 29),\n",
       "   (1043, 13),\n",
       "   (1056, 41),\n",
       "   (1097, 20),\n",
       "   (1117, 16),\n",
       "   (1133, 17)]),\n",
       " <otgnn.graph.mol_graph.MolGraph at 0x7f8af96e66d8>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict[\"pred_pack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_pack': (((tensor([13, 16, 13,  ..., 16, 13, 16]),\n",
       "    tensor([3, 3, 3,  ..., 3, 3, 3]),\n",
       "    tensor([4, 3, 3,  ..., 3, 3, 4])),\n",
       "   (tensor([[ 0.0350, -0.0453,  0.0178,  ...,  0.0346,  0.0418,  0.0557],\n",
       "            [ 0.0379, -0.0453,  0.0105,  ...,  0.0288,  0.0465,  0.0678],\n",
       "            [ 0.0359, -0.0464,  0.0111,  ...,  0.0294,  0.0486,  0.0723],\n",
       "            ...,\n",
       "            [ 0.0301, -0.0401, -0.0013,  ...,  0.0228,  0.0227,  0.0632],\n",
       "            [ 0.0202, -0.0440,  0.0079,  ...,  0.0279,  0.0306,  0.0590],\n",
       "            [ 0.0313, -0.0441,  0.0051,  ...,  0.0284,  0.0359,  0.0638]],\n",
       "           requires_grad=True),\n",
       "    tensor([[-0.0535, -0.0756, -0.0574,  0.0841,  0.0702],\n",
       "            [-0.0626, -0.0684, -0.0577,  0.0855,  0.0658],\n",
       "            [-0.0646, -0.0687, -0.0570,  0.0848,  0.0647],\n",
       "            ...,\n",
       "            [-0.0413, -0.0713, -0.0632,  0.0848,  0.0673],\n",
       "            [-0.0441, -0.0737, -0.0660,  0.0869,  0.0692],\n",
       "            [-0.0530, -0.0668, -0.0542,  0.0797,  0.0673]], requires_grad=True),\n",
       "    tensor([[-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0000e+03],\n",
       "            [-6.3665e-02,  1.4003e-02, -2.1929e-02,  1.0894e-01,  2.5072e-02],\n",
       "            [-6.5902e-02,  1.5487e-02, -1.7059e-02,  1.1256e-01,  2.8185e-02],\n",
       "            ...,\n",
       "            [-6.4162e-02,  1.3389e-02, -2.3896e-02,  1.0987e-01,  2.1035e-02],\n",
       "            [-6.1098e-02,  1.0536e-02, -1.1558e-02,  1.0443e-01,  2.9472e-02],\n",
       "            [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0000e+03]],\n",
       "           requires_grad=True)),\n",
       "   [(0, 25),\n",
       "    (25, 16),\n",
       "    (41, 29),\n",
       "    (70, 35),\n",
       "    (105, 21),\n",
       "    (126, 47),\n",
       "    (173, 18),\n",
       "    (191, 23),\n",
       "    (214, 23),\n",
       "    (237, 18),\n",
       "    (255, 16),\n",
       "    (271, 23),\n",
       "    (294, 18),\n",
       "    (312, 21),\n",
       "    (333, 7),\n",
       "    (340, 12),\n",
       "    (352, 12),\n",
       "    (364, 21),\n",
       "    (385, 17),\n",
       "    (402, 23),\n",
       "    (425, 25),\n",
       "    (450, 27),\n",
       "    (477, 30),\n",
       "    (507, 25),\n",
       "    (532, 23),\n",
       "    (555, 21),\n",
       "    (576, 14),\n",
       "    (590, 19),\n",
       "    (609, 32),\n",
       "    (641, 28),\n",
       "    (669, 24),\n",
       "    (693, 26),\n",
       "    (719, 17),\n",
       "    (736, 26),\n",
       "    (762, 20),\n",
       "    (782, 22),\n",
       "    (804, 43),\n",
       "    (847, 28),\n",
       "    (875, 13),\n",
       "    (888, 24),\n",
       "    (912, 25),\n",
       "    (937, 18),\n",
       "    (955, 34),\n",
       "    (989, 25),\n",
       "    (1014, 29),\n",
       "    (1043, 13),\n",
       "    (1056, 41),\n",
       "    (1097, 20),\n",
       "    (1117, 16),\n",
       "    (1133, 17)]),\n",
       "  <otgnn.graph.mol_graph.MolGraph at 0x7f8af96e66d8>),\n",
       " 'losses': ({'fgw': 3.595323181152344,\n",
       "   'conn_penalty': 0.0,\n",
       "   'val_penalty': 0.0,\n",
       "   'euler_penalty': 0.0,\n",
       "   'total': 3.595323181152344},\n",
       "  {}),\n",
       " 'pen_stats': {'tau': 0.9995683315056232,\n",
       "  'conn_lambda': 1,\n",
       "  'valency_lambda': 10,\n",
       "  'euler_lambda': 1,\n",
       "  'current_epoch': 1,\n",
       "  'lambda_mode': array([0, 0, 0])},\n",
       " 'lr': 0.004}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = [x for x in os.listdir(args.output_dir) if \"data\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_writer = SummaryWriter(logdir = args.tb_logs_dir)\n",
    "metrics = MolMetrics(SYMBOLS, FORMAL_CHARGES, BOND_TYPES, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " fgw:0.0066266\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.0066266\n",
      "\n",
      " similarity:0.0122219\n",
      " penlog:-10.4965227\n",
      "\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:97.7294686\n",
      " batch_molecular_disconnected_validity:88.8888889\n",
      " batch_connected_components:21.1133333\n",
      " batch_invalid_valency_nodes:87.1787440\n",
      " batch_nodes_0degree:19.8422222\n",
      " batch_nodes_7plus_degree:0.0622222\n",
      " invalid_euler_toofew:99.1111111\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-20.8644444\n",
      " batch_node_degree:0.3026087\n"
     ]
    }
   ],
   "source": [
    "losses_stats_tracker.print_stats()\n",
    "measure_stats_tracker.print_stats()\n",
    "metrics_stats_tracker.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(args.tb_logs_dir).mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_0.out\n",
      "fgw 3.595323181152344\n",
      "conn_penalty 0.0\n",
      "val_penalty 0.0\n",
      "euler_penalty 0.0\n",
      "total 3.595323181152344\n",
      "Losses Epoch 1, train\n",
      " fgw:3.5953232\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:3.5953232\n",
      "Measure Epoch 1, train\n",
      " similarity:0.0000000\n",
      " penlog:-100.0000000\n",
      "Metrics Epoch 1, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:0.0000000\n",
      " batch_molecular_disconnected_validity:0.0000000\n",
      " batch_connected_components:1.0000000\n",
      " batch_invalid_valency_nodes:99.5652174\n",
      " batch_nodes_0degree:0.0000000\n",
      " batch_nodes_7plus_degree:22.8600000\n",
      " invalid_euler_toofew:0.0000000\n",
      " invalid_euler_toomany:100.0000000\n",
      " avg_euler_error:260.5800000\n",
      " batch_node_degree:24.6591304\n",
      "train_penalty/learning_rate\n",
      "train_losses/fgw\n",
      "train_losses/conn_penalty\n",
      "train_losses/val_penalty\n",
      "train_losses/euler_penalty\n",
      "train_losses/total\n",
      "train_measure/similarity\n",
      "train_measure/penlog\n",
      "train_metrics/batch_molecular_validity\n",
      "train_metrics/batch_correctness\n",
      "train_metrics/batch_symbol_accuracy\n",
      "train_metrics/batch_molecular_disconnected_validity\n",
      "train_metrics/batch_connected_components\n",
      "train_metrics/batch_invalid_valency_nodes\n",
      "train_metrics/batch_nodes_0degree\n",
      "train_metrics/batch_nodes_7plus_degree\n",
      "train_metrics/invalid_euler_toofew\n",
      "train_metrics/invalid_euler_toomany\n",
      "train_penalty/tau\n",
      "train_penalty/conn_lambda\n",
      "train_penalty/valency_lambda\n",
      "train_penalty/euler_lambda\n",
      "train_penalty/current_epoch\n",
      "train_penalty/lambda_mode\n",
      "Epoch 2\n",
      "train_0.out\n",
      "fgw 0.7209090423583985\n",
      "conn_penalty 0.0\n",
      "val_penalty 0.0\n",
      "euler_penalty 0.0\n",
      "total 0.7209090423583985\n",
      "Losses Epoch 2, train\n",
      " fgw:0.7209090\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.7209090\n",
      "Measure Epoch 2, train\n",
      " similarity:0.0011438\n",
      " penlog:5.4686389\n",
      "Metrics Epoch 2, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:74.7826087\n",
      " batch_molecular_disconnected_validity:100.0000000\n",
      " batch_connected_components:23.0000000\n",
      " batch_invalid_valency_nodes:100.0000000\n",
      " batch_nodes_0degree:23.0000000\n",
      " batch_nodes_7plus_degree:0.0000000\n",
      " invalid_euler_toofew:100.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-23.0000000\n",
      " batch_node_degree:0.0000000\n",
      "train_penalty/learning_rate\n",
      "train_losses/fgw\n",
      "train_losses/conn_penalty\n",
      "train_losses/val_penalty\n",
      "train_losses/euler_penalty\n",
      "train_losses/total\n",
      "train_measure/similarity\n",
      "train_measure/penlog\n",
      "train_metrics/batch_molecular_validity\n",
      "train_metrics/batch_correctness\n",
      "train_metrics/batch_symbol_accuracy\n",
      "train_metrics/batch_molecular_disconnected_validity\n",
      "train_metrics/batch_connected_components\n",
      "train_metrics/batch_invalid_valency_nodes\n",
      "train_metrics/batch_nodes_0degree\n",
      "train_metrics/batch_nodes_7plus_degree\n",
      "train_metrics/invalid_euler_toofew\n",
      "train_metrics/invalid_euler_toomany\n",
      "train_penalty/tau\n",
      "train_penalty/conn_lambda\n",
      "train_penalty/valency_lambda\n",
      "train_penalty/euler_lambda\n",
      "train_penalty/current_epoch\n",
      "train_penalty/lambda_mode\n",
      "Epoch 3\n",
      "train_0.out\n",
      "fgw 0.5261087036132812\n",
      "conn_penalty 0.0\n",
      "val_penalty 0.0\n",
      "euler_penalty 0.0\n",
      "total 0.5261087036132812\n",
      "Losses Epoch 3, train\n",
      " fgw:0.5261087\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.5261087\n",
      "Measure Epoch 3, train\n",
      " similarity:0.0025262\n",
      " penlog:1.3249085\n",
      "Metrics Epoch 3, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:92.2608696\n",
      " batch_molecular_disconnected_validity:100.0000000\n",
      " batch_connected_components:23.0000000\n",
      " batch_invalid_valency_nodes:100.0000000\n",
      " batch_nodes_0degree:23.0000000\n",
      " batch_nodes_7plus_degree:0.0000000\n",
      " invalid_euler_toofew:100.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-23.0000000\n",
      " batch_node_degree:0.0000000\n",
      "train_penalty/learning_rate\n",
      "train_losses/fgw\n",
      "train_losses/conn_penalty\n",
      "train_losses/val_penalty\n",
      "train_losses/euler_penalty\n",
      "train_losses/total\n",
      "train_measure/similarity\n",
      "train_measure/penlog\n",
      "train_metrics/batch_molecular_validity\n",
      "train_metrics/batch_correctness\n",
      "train_metrics/batch_symbol_accuracy\n",
      "train_metrics/batch_molecular_disconnected_validity\n",
      "train_metrics/batch_connected_components\n",
      "train_metrics/batch_invalid_valency_nodes\n",
      "train_metrics/batch_nodes_0degree\n",
      "train_metrics/batch_nodes_7plus_degree\n",
      "train_metrics/invalid_euler_toofew\n",
      "train_metrics/invalid_euler_toomany\n",
      "train_penalty/tau\n",
      "train_penalty/conn_lambda\n",
      "train_penalty/valency_lambda\n",
      "train_penalty/euler_lambda\n",
      "train_penalty/current_epoch\n",
      "train_penalty/lambda_mode\n",
      "Epoch 4\n",
      "train_0.out\n",
      "fgw 0.36876190185546875\n",
      "conn_penalty 0.0\n",
      "val_penalty 0.0\n",
      "euler_penalty 0.0\n",
      "total 0.36876190185546875\n",
      "Losses Epoch 4, train\n",
      " fgw:0.3687619\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.3687619\n",
      "Measure Epoch 4, train\n",
      " similarity:0.0035681\n",
      " penlog:-5.0931109\n",
      "Metrics Epoch 4, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:97.3043478\n",
      " batch_molecular_disconnected_validity:94.0000000\n",
      " batch_connected_components:21.8000000\n",
      " batch_invalid_valency_nodes:91.3043478\n",
      " batch_nodes_0degree:20.8800000\n",
      " batch_nodes_7plus_degree:0.0000000\n",
      " invalid_euler_toofew:100.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-21.6600000\n",
      " batch_node_degree:0.2295652\n",
      "train_penalty/learning_rate\n",
      "train_losses/fgw\n",
      "train_losses/conn_penalty\n",
      "train_losses/val_penalty\n",
      "train_losses/euler_penalty\n",
      "train_losses/total\n",
      "train_measure/similarity\n",
      "train_measure/penlog\n",
      "train_metrics/batch_molecular_validity\n",
      "train_metrics/batch_correctness\n",
      "train_metrics/batch_symbol_accuracy\n",
      "train_metrics/batch_molecular_disconnected_validity\n",
      "train_metrics/batch_connected_components\n",
      "train_metrics/batch_invalid_valency_nodes\n",
      "train_metrics/batch_nodes_0degree\n",
      "train_metrics/batch_nodes_7plus_degree\n",
      "train_metrics/invalid_euler_toofew\n",
      "train_metrics/invalid_euler_toomany\n",
      "train_penalty/tau\n",
      "train_penalty/conn_lambda\n",
      "train_penalty/valency_lambda\n",
      "train_penalty/euler_lambda\n",
      "train_penalty/current_epoch\n",
      "train_penalty/lambda_mode\n",
      "Epoch 5\n",
      "train_0.out\n",
      "fgw 0.31662315368652344\n",
      "conn_penalty 0.0\n",
      "val_penalty 0.0\n",
      "euler_penalty 0.0\n",
      "total 0.31662315368652344\n",
      "Losses Epoch 5, train\n",
      " fgw:0.3166232\n",
      " conn_penalty:0.0000000\n",
      " val_penalty:0.0000000\n",
      " euler_penalty:0.0000000\n",
      " total:0.3166232\n",
      "Measure Epoch 5, train\n",
      " similarity:0.0115630\n",
      " penlog:-29.2996767\n",
      "Metrics Epoch 5, train\n",
      " batch_molecular_validity:0.0000000\n",
      " batch_correctness:0.0000000\n",
      " batch_symbol_accuracy:98.7826087\n",
      " batch_molecular_disconnected_validity:70.0000000\n",
      " batch_connected_components:17.9200000\n",
      " batch_invalid_valency_nodes:66.9565217\n",
      " batch_nodes_0degree:14.7800000\n",
      " batch_nodes_7plus_degree:0.2400000\n",
      " invalid_euler_toofew:98.0000000\n",
      " invalid_euler_toomany:0.0000000\n",
      " avg_euler_error:-16.9600000\n",
      " batch_node_degree:0.9252174\n",
      "train_penalty/learning_rate\n",
      "train_losses/fgw\n",
      "train_losses/conn_penalty\n",
      "train_losses/val_penalty\n",
      "train_losses/euler_penalty\n",
      "train_losses/total\n",
      "train_measure/similarity\n",
      "train_measure/penlog\n",
      "train_metrics/batch_molecular_validity\n",
      "train_metrics/batch_correctness\n",
      "train_metrics/batch_symbol_accuracy\n",
      "train_metrics/batch_molecular_disconnected_validity\n",
      "train_metrics/batch_connected_components\n",
      "train_metrics/batch_invalid_valency_nodes\n",
      "train_metrics/batch_nodes_0degree\n",
      "train_metrics/batch_nodes_7plus_degree\n",
      "train_metrics/invalid_euler_toofew\n",
      "train_metrics/invalid_euler_toomany\n",
      "train_penalty/tau\n",
      "train_penalty/conn_lambda\n",
      "train_penalty/valency_lambda\n",
      "train_penalty/euler_lambda\n",
      "train_penalty/current_epoch\n",
      "train_penalty/lambda_mode\n",
      "Epoch 6\n"
     ]
    }
   ],
   "source": [
    "do_epoch(1, args.output_dir, tb_writer, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(args.tb_logs_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/octav/gitrepos/tum-thesis'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mol_opt/logs_dev2/pointwise-test3'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.tb_logs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_tensorboard(tb_writer, losses_stats_tracker.get_stats(), data_type + \"_losses\", epochidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses_stats_tracker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-55d96f2b140c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses_stats_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'losses_stats_tracker' is not defined"
     ]
    }
   ],
   "source": [
    "losses_stats_tracker.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgw_loss(*pred_pack, tau = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
