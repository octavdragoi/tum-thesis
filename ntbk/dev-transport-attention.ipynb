{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"molgen\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"iclr19-graph2graph/props\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN, fused_gw_torch\n",
    "# from molgen.dataloading.MolGraphBatchPreprocessor import MolGraph\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "from otgnn.graph import SYMBOLS, FORMAL_CHARGES, BOND_TYPES\n",
    "\n",
    "\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, load_checkpoint, initialize_models\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.decoder_mol_opt import MolOptDecoder\n",
    "from mol_opt.ot_utils import encode_target\n",
    "from mol_opt.ot_utils import FGW \n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "\n",
    "from molgen.dataloading.feat2smiles import feat2smiles\n",
    "from molgen.dataloading.mol_drawer import MolDrawer\n",
    "from molgen.metrics.Penalty import Penalty\n",
    "from molgen.metrics.mol_metrics import MolMetrics\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import time\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from molgen.metrics.Penalty import Penalty as PenaltyNew\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/octav/data-volume/tum-thesis/output_dev3_saves/deepsets-chembl1/\n",
      "mol_opt/logs_dev3_saves/deepsets-chembl1/\n"
     ]
    }
   ],
   "source": [
    "model_type = \"deepsets\"\n",
    "sys.argv = [\"\", \"-model_type\", model_type, \"-one_batch_train\"]\n",
    "args = get_args()\n",
    "outdir_suffix = \"dev3_saves\"\n",
    "args.init_model = \"{}-chembl1\".format(model_type)\n",
    "args.output_dir = \"/run/media/octav/data-volume/tum-thesis/output_{}/{}/\".format(outdir_suffix, args.init_model)\n",
    "args.tb_logs_dir = \"mol_opt/logs_{}/{}/\".format(outdir_suffix, args.init_model)\n",
    "\n",
    "print (args.output_dir)\n",
    "print (args.tb_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/octav/data-volume/tum-thesis/output_dev3_saves/deepsets-chembl1/model_deepsets-chembl1_11\n",
      "MolOpt(\n",
      "  (GCN): GCN(\n",
      "    (W_message_i): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (W_message_h): Linear(in_features=200, out_features=200, bias=False)\n",
      "    (W_message_o): Linear(in_features=293, out_features=150, bias=True)\n",
      "    (W_mol_h): Linear(in_features=150, out_features=100, bias=True)\n",
      "    (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
      "    (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
      "    (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (opt0): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (opt1): Linear(in_features=200, out_features=150, bias=True)\n",
      ")\n",
      "MolOptDecoder(\n",
      "  (fc1_SYMBOLS): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (fc2_SYMBOLS): Linear(in_features=150, out_features=64, bias=True)\n",
      "  (fc1_CHARGES): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (fc2_CHARGES): Linear(in_features=150, out_features=5, bias=True)\n",
      "  (fc1_BONDS): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (fc2_BONDS): Linear(in_features=300, out_features=5, bias=True)\n",
      ")\n",
      "deepsets\n",
      "Penalty params: tau=0.05623 conn_l=0.00032 val_l=0.00030 euler_l=0.00034 epoch=11 mode=[0 0 0] conn=True val=True euler=True\n"
     ]
    }
   ],
   "source": [
    "model = args.init_model\n",
    "model_iter = 11 \n",
    "\n",
    "model_name = \"model_{}_{}\".format(model, model_iter)\n",
    "print(args.output_dir + model_name)\n",
    "\n",
    "# molopt, molopt_decoder, _, pen, recpen, _, _, config, _ = load_checkpoint(args.output_dir + model_name ,init_fc = initialize_models, device = 'cpu')\n",
    "molopt, molopt_decoder, optimizer, penalty, recpenalty, crossatt, scheduler = initialize_models(args)\n",
    "\n",
    "metrics = MolMetrics(SYMBOLS, FORMAL_CHARGES, BOND_TYPES, False, device = 'cpu')\n",
    "fgw_loss = FGW(alpha = 0.5)\n",
    "# pen = PenaltyNew(config, model_iter)\n",
    "\n",
    "molopt_module_list = torch.nn.ModuleList([molopt, molopt_decoder])\n",
    "\n",
    "# molopt = MolOpt(args)\n",
    "# molopt_decoder = MolOptDecoder(args)\n",
    "print (molopt)\n",
    "print (molopt_decoder)\n",
    "print(molopt.args.model_type)\n",
    "pen.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train_pairs\", args.batch_size, True)\n",
    "datatype = \"val_split\"\n",
    "train_data_loader = get_loader(\"molgen/data/chembl50\", datatype, 50, same_number_atoms = True)\n",
    "\n",
    "for i in train_data_loader:\n",
    "#     X = (MolGraph(i[0]))\n",
    "#     Y = (MolGraph(i[1]))\n",
    "    X = MolGraph(i)\n",
    "    Y = X\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:398: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6414093017578124\n",
      "(tensor(0., grad_fn=<DivBackward0>), tensor(25998.8320, grad_fn=<DivBackward0>), tensor(9634.4160, grad_fn=<DivBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_molecular_validity': 100.0,\n",
       "  'batch_correctness': 0.0,\n",
       "  'batch_symbol_accuracy': 0.0,\n",
       "  'batch_molecular_disconnected_validity': 100.0,\n",
       "  'batch_connected_components': 1.0,\n",
       "  'batch_invalid_valency_nodes': 100.0,\n",
       "  'batch_nodes_0degree': 1007,\n",
       "  'batch_nodes_7plus_degree': 1007,\n",
       "  'invalid_euler_toofew': 0.0,\n",
       "  'invalid_euler_toomany': 98.0},\n",
       " {'avg_euler_error': (204.17999999999998, 50, 26766.267600000003),\n",
       "  'batch_node_degree': (22.27606752730884, 1007, 60.30908960020668)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_encoding, x_embedding = molopt.forward(X)\n",
    "yhat_logits = molopt_decoder.forward(x_embedding, X, Y)\n",
    "yhat_labels = molopt_decoder.discretize_argmax(*yhat_logits)\n",
    "# yhat_labels = molopt_decoder.discretize_gumbel(*yhat_logits, tau = pen.tau)\n",
    "pred_pack = (yhat_labels, yhat_logits, Y.scope), Y \n",
    "\n",
    "target = Y.get_graph_outputs()\n",
    "symbols_labels, charges_labels, bonds_labels = yhat_labels\n",
    "symbols_logits, charges_logits, bonds_logits = yhat_logits\n",
    "\n",
    "pen.mirror = \"\"\n",
    "\n",
    "pen.tau = 0.05\n",
    "fgw_loss_item = fgw_loss(*pred_pack, tau = 1)\n",
    "print (fgw_loss_item.item()/args.batch_size)\n",
    "pen_loss = pen(*pred_pack, model_iter)\n",
    "print (pen_loss)\n",
    "metrics.measure_batch(pred_pack[0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000e+03, -2.0000e+03, -2.0000e+03, -2.0000e+03,  0.0000e+00],\n",
       "        [-1.6877e+00, -1.6072e+00, -1.5906e+00, -1.5062e+00, -1.6657e+00],\n",
       "        [-1.6934e+00, -1.6003e+00, -1.5968e+00, -1.5041e+00, -1.6632e+00],\n",
       "        ...,\n",
       "        [-1.6975e+00, -1.6066e+00, -1.5769e+00, -1.5156e+00, -1.6608e+00],\n",
       "        [-1.6979e+00, -1.6006e+00, -1.5813e+00, -1.5149e+00, -1.6627e+00],\n",
       "        [-2.0000e+03, -2.0000e+03, -2.0000e+03, -2.0000e+03,  0.0000e+00]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LogSoftmax(dim=1)(bonds_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0000e+03],\n",
       "        [-5.4358e-02,  2.6137e-02,  4.2725e-02,  1.2717e-01, -3.2361e-02],\n",
       "        [-6.0568e-02,  3.2551e-02,  3.6042e-02,  1.2874e-01, -3.0361e-02],\n",
       "        ...,\n",
       "        [-6.3245e-02,  2.7605e-02,  5.7299e-02,  1.1864e-01, -2.6556e-02],\n",
       "        [-6.5131e-02,  3.2255e-02,  5.1460e-02,  1.1791e-01, -2.9888e-02],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0000e+03]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonds_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a378f4e7612a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bonds_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bonds_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgw_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_bonds_nll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration over a 0-d tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "M, pred_bonds_nll, target_bonds_rescaled = fgw_loss(*pred_pack, tau = 1)\n",
    "num_atoms = M.shape[0]\n",
    "alpha = 0.55\n",
    "device = pred_bonds_nll.device\n",
    "\n",
    "M=M\n",
    "C1= target_bonds_rescaled\n",
    "C2= -1 * pred_bonds_nll\n",
    "p1=np.ones([num_atoms]) / float(num_atoms)\n",
    "p2=np.ones([num_atoms]) / float(num_atoms)\n",
    "dist_type='dot'\n",
    "nce_reg = True\n",
    "alpha=alpha\n",
    "device=device\n",
    "\n",
    "C1_detach = C1.detach().cpu().numpy()\n",
    "C2_detach = C2.detach().cpu().numpy()\n",
    "C1_m = max(1, C1_detach.max())\n",
    "C2_m = max(1, C2_detach.max())\n",
    "C1_detach /= C1_m\n",
    "C2_detach /= C2_m\n",
    "M_detach = M.detach().cpu().numpy()\n",
    "\n",
    "from otgnn.models import np_fused_gw\n",
    "\n",
    "ot_mat = np_fused_gw(M=M_detach, C1 = C1_detach, C2 = C2_detach,\n",
    "                     p1 = p1, p2 = p2, dist_type=dist_type, alpha=alpha)\n",
    "print (ot_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1007, 150]) torch.Size([1007, 150])\n"
     ]
    }
   ],
   "source": [
    "yhat_embedding = molopt.GCN(Y)[0]\n",
    "print (x_embedding.shape, yhat_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0438, 0.9401, 0.9768, 1.0739, 1.0823, 1.0584, 0.9636, 0.9648, 0.9890,\n",
      "        0.9368, 1.0080, 0.9836, 0.9432, 0.9942, 1.0249, 1.0244, 0.9924],\n",
      "       grad_fn=<SumBackward1>)\n",
      "1 23\n",
      "torch.Size([23, 23])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1247, 0.9364, 1.0329, 0.9217, 0.9637, 1.0161, 1.0309, 1.0254, 0.9265,\n",
      "        0.8930, 0.9223, 0.9702, 1.0625, 0.9872, 0.8850, 0.9618, 1.0169, 1.0686,\n",
      "        1.0757, 1.0699, 1.0330, 1.0379, 1.0382], grad_fn=<SumBackward1>)\n",
      "2 28\n",
      "torch.Size([28, 28])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0749, 0.9921, 1.0234, 0.9808, 1.0344, 0.9494, 1.0744, 0.9790, 1.0080,\n",
      "        1.0312, 0.9651, 1.0095, 1.0085, 0.9891, 0.9619, 0.9556, 0.9778, 1.0105,\n",
      "        1.0385, 1.0444, 1.0148, 0.9951, 1.0115, 0.9645, 0.9587, 1.0126, 0.9592,\n",
      "        0.9751], grad_fn=<SumBackward1>)\n",
      "3 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0927, 0.9726, 1.0260, 0.9988, 1.0479, 0.9430, 0.9890, 0.9717, 0.9224,\n",
      "        0.9637, 0.9579, 1.0168, 1.0251, 1.0262, 0.9418, 1.0663, 1.0349, 1.0308,\n",
      "        0.9024, 0.9720, 0.9829, 1.0087, 1.0619, 1.0634, 1.0075, 0.9736],\n",
      "       grad_fn=<SumBackward1>)\n",
      "4 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1662, 0.9983, 0.8951, 0.9983, 1.1662, 0.9054, 0.9270, 0.9397, 1.0304,\n",
      "        0.9430, 0.9279, 0.9428, 0.9227, 1.0976, 1.0976, 1.0976, 0.9442],\n",
      "       grad_fn=<SumBackward1>)\n",
      "5 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0338, 0.9427, 1.0218, 0.9940, 0.9805, 0.9447, 0.9861, 0.9965, 0.9813,\n",
      "        0.9878, 1.0372, 0.9695, 0.9793, 1.0049, 0.9592, 1.0470, 1.0261, 1.0542,\n",
      "        1.0591, 1.0530, 1.0430, 1.0080, 1.0149, 0.9613, 0.9631, 0.9508],\n",
      "       grad_fn=<SumBackward1>)\n",
      "6 15\n",
      "torch.Size([15, 15])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0926, 1.0231, 1.1206, 1.0972, 0.9979, 0.9021, 1.0775, 0.8845, 0.9474,\n",
      "        0.9807, 0.9807, 0.9474, 0.9062, 1.0093, 1.0328],\n",
      "       grad_fn=<SumBackward1>)\n",
      "7 11\n",
      "torch.Size([11, 11])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0066, 0.9881, 1.0387, 1.0588, 1.0570, 1.0135, 1.0162, 0.8805, 1.0033,\n",
      "        0.9686, 0.9686], grad_fn=<SumBackward1>)\n",
      "8 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0341, 0.9913, 0.9850, 0.9973, 0.9942, 0.9892, 0.9768, 0.9777, 1.0009,\n",
      "        1.0009, 1.0151, 1.0160, 0.9645, 1.0251, 1.0181, 0.9844, 1.0291],\n",
      "       grad_fn=<SumBackward1>)\n",
      "9 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1104, 0.9422, 0.9775, 1.0950, 0.9516, 1.0065, 1.0088, 0.9110, 1.0615,\n",
      "        0.9082, 1.0642, 0.9632], grad_fn=<SumBackward1>)\n",
      "10 18\n",
      "torch.Size([18, 18])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0704, 0.9534, 0.9924, 1.0014, 0.9835, 1.0124, 1.0381, 0.9440, 0.9503,\n",
      "        0.9955, 0.9998, 0.9997, 0.9486, 1.0488, 1.0168, 1.0154, 1.0181, 1.0113],\n",
      "       grad_fn=<SumBackward1>)\n",
      "11 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9610, 0.8950, 0.9934, 0.9855, 0.9737, 1.0252, 1.0853, 1.0943, 1.0333,\n",
      "        0.9467, 0.9909, 0.9961, 0.9852, 0.9703, 0.9866, 0.9868, 1.0577, 1.0470,\n",
      "        1.0421, 0.9514, 0.9922], grad_fn=<SumBackward1>)\n",
      "12 40\n",
      "torch.Size([40, 40])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0759, 1.0023, 0.9540, 0.8988, 1.0273, 0.9432, 0.9185, 1.0156, 0.9298,\n",
      "        0.9063, 1.0689, 0.9123, 1.0723, 0.9690, 1.0214, 0.9998, 1.0735, 1.0735,\n",
      "        0.9007, 1.0655, 0.9633, 1.0204, 1.0007, 1.0743, 1.0743, 1.0151, 0.9181,\n",
      "        1.1176, 0.9289, 1.0627, 0.9971, 1.0507, 0.9974, 0.9611, 0.9656, 1.0728,\n",
      "        0.9122, 1.0668, 0.9045, 1.0677], grad_fn=<SumBackward1>)\n",
      "13 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0376, 0.9823, 1.0213, 1.0140, 1.0047, 0.9938, 0.9363, 1.0148, 0.9844,\n",
      "        0.9844, 1.0074, 1.0188], grad_fn=<SumBackward1>)\n",
      "14 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.9499, 1.0056, 0.8755, 0.9583, 0.9839, 1.0365, 1.0518, 1.0500, 0.9712,\n",
      "        1.0069, 0.9918, 1.0186, 1.0537, 1.0333, 1.0165, 0.9499, 0.9418, 1.0021,\n",
      "        0.9851, 1.0119, 1.0271, 0.9847, 1.0247, 1.0427, 1.0284, 0.9981],\n",
      "       grad_fn=<SumBackward1>)\n",
      "15 24\n",
      "torch.Size([24, 24])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0523, 1.0142, 1.0093, 0.9880, 1.0019, 0.9598, 0.9322, 0.9819, 0.9212,\n",
      "        0.9626, 0.9502, 0.9658, 1.0626, 0.9774, 1.0354, 0.9650, 0.9701, 0.9285,\n",
      "        1.0361, 1.0290, 1.0680, 1.0709, 1.0662, 1.0514],\n",
      "       grad_fn=<SumBackward1>)\n",
      "16 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0256, 0.9886, 1.0007, 0.9937, 0.9973, 0.9940, 0.9917, 0.9887, 1.0285,\n",
      "        1.0285, 0.9887, 0.9917, 0.9942, 0.9976, 0.9972, 0.9979, 0.9892, 0.9998,\n",
      "        0.9822, 1.0242], grad_fn=<SumBackward1>)\n",
      "17 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0686, 0.9761, 1.0263, 1.0247, 1.0754, 1.0697, 1.0310, 0.9754, 0.9931,\n",
      "        0.9409, 0.9464, 1.0275, 0.9453, 1.0022, 1.0046, 0.9570, 0.9821, 0.9386,\n",
      "        1.0040, 0.9980, 1.0216, 1.0710, 1.0710, 1.0216, 0.9980, 0.9386, 1.0040,\n",
      "        0.9464, 0.9409], grad_fn=<SumBackward1>)\n",
      "18 14\n",
      "torch.Size([14, 14])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0235, 0.9909, 0.9718, 0.9616, 1.0251, 0.9749, 1.0431, 0.9599, 0.9953,\n",
      "        0.9940, 1.0184, 1.0173, 1.0176, 1.0068], grad_fn=<SumBackward1>)\n",
      "19 22\n",
      "torch.Size([22, 22])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0795, 0.9573, 1.0004, 1.0234, 1.0125, 0.9793, 1.0008, 1.0075, 0.9815,\n",
      "        0.9909, 1.0215, 0.9929, 0.9931, 0.9768, 0.9753, 1.0094, 1.0158, 0.9873,\n",
      "        1.0018, 1.0033, 0.9840, 1.0057], grad_fn=<SumBackward1>)\n",
      "20 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0404, 0.9560, 1.0409, 1.0210, 0.9687, 1.0202, 1.0208, 0.9686, 1.0214,\n",
      "        1.0314, 0.9838, 0.9850, 0.9911, 0.9979, 0.9958, 1.0033, 0.9717, 0.9827,\n",
      "        0.9672, 1.0321], grad_fn=<SumBackward1>)\n",
      "21 7\n",
      "torch.Size([7, 7])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0309, 0.9490, 0.9799, 1.0168, 1.0162, 1.0159, 0.9912],\n",
      "       grad_fn=<SumBackward1>)\n",
      "22 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0099, 1.0078, 0.9551, 1.0396, 1.0029, 0.9671, 0.9832, 0.9750, 1.0407,\n",
      "        1.0008, 1.0168, 1.0082, 0.9790, 1.0516, 0.9878, 1.0170, 0.9574],\n",
      "       grad_fn=<SumBackward1>)\n",
      "23 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0675, 0.9404, 0.9684, 0.9813, 1.0060, 1.0076, 0.9909, 1.0165, 1.0134,\n",
      "        1.0081, 0.9684, 0.9404, 1.0675, 0.9813, 1.0060, 1.0076, 0.9909, 1.0165,\n",
      "        1.0134, 1.0081], grad_fn=<SumBackward1>)\n",
      "24 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9594, 0.9603, 0.9033, 0.9392, 0.9983, 1.0726, 1.0637, 1.0199, 1.0777,\n",
      "        1.0900, 1.0738, 0.9070, 0.9409, 0.9935, 1.0329, 1.0733, 0.9942, 0.9508,\n",
      "        1.0570, 0.8921], grad_fn=<SumBackward1>)\n",
      "25 30\n",
      "torch.Size([30, 30])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0584, 0.9404, 0.9005, 0.9471, 0.9430, 0.9752, 0.8963, 0.9428, 0.9683,\n",
      "        0.9399, 0.9387, 0.9986, 1.0118, 1.0740, 1.0922, 1.0817, 1.0339, 0.9131,\n",
      "        0.9265, 1.0127, 1.0887, 1.0878, 0.9988, 0.9383, 0.9820, 1.0237, 1.0748,\n",
      "        1.0925, 1.0817, 1.0366], grad_fn=<SumBackward1>)\n",
      "26 14\n",
      "torch.Size([14, 14])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0490, 0.9670, 1.0098, 1.0112, 1.0540, 1.0485, 1.0166, 0.9770, 0.9853,\n",
      "        0.9557, 0.9784, 1.0136, 0.9784, 0.9557], grad_fn=<SumBackward1>)\n",
      "27 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0876, 0.9327, 0.9510, 0.9188, 0.9578, 1.0053, 1.0524, 1.0469, 1.0481,\n",
      "        1.0173, 0.9573, 1.0083, 1.0180, 0.9838, 0.9853, 0.9823, 0.9590, 0.9503,\n",
      "        1.0232, 1.0232, 1.0247, 1.0167, 0.9686, 1.0147, 1.0167, 0.9799, 1.0218,\n",
      "        1.0295, 1.0185], grad_fn=<SumBackward1>)\n",
      "28 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0877, 0.8886, 0.9880, 0.9739, 0.8704, 0.9265, 0.8951, 0.8399, 0.9807,\n",
      "        0.8801, 0.9875, 1.0119, 1.0932, 1.1107, 1.0974, 1.0364, 0.8954, 0.9215,\n",
      "        1.0164, 1.1058, 1.1053, 0.9954, 0.9277, 1.0112, 1.0200, 1.0876, 1.1101,\n",
      "        1.0936, 1.0421], grad_fn=<SumBackward1>)\n",
      "29 8\n",
      "torch.Size([8, 8])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0333, 0.9689, 1.0333, 0.9873, 1.0236, 0.9541, 0.9849, 1.0148],\n",
      "       grad_fn=<SumBackward1>)\n",
      "30 7\n",
      "torch.Size([7, 7])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0177, 0.9775, 0.9897, 1.0256, 0.9644, 1.0093, 1.0158],\n",
      "       grad_fn=<SumBackward1>)\n",
      "31 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0346, 1.0272, 0.9022, 1.0272, 1.0346, 0.9498, 0.9987, 0.9022, 1.0272,\n",
      "        1.0346, 1.0272, 1.0346], grad_fn=<SumBackward1>)\n",
      "32 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1160, 0.9308, 1.0043, 1.0366, 1.0173, 0.9775, 0.9559, 0.9924, 0.9841,\n",
      "        0.9516, 0.9971, 1.0109, 0.9283, 1.1202, 1.0354, 1.0246, 0.9548, 0.9130,\n",
      "        0.9707, 1.0313, 1.0471], grad_fn=<SumBackward1>)\n",
      "33 7\n",
      "torch.Size([7, 7])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0397, 0.9694, 0.9906, 0.9884, 0.9967, 0.9860, 1.0292],\n",
      "       grad_fn=<SumBackward1>)\n",
      "34 19\n",
      "torch.Size([19, 19])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9909, 0.9571, 1.0382, 0.9763, 0.9640, 1.0412, 0.9983, 0.9752, 0.9926,\n",
      "        1.0513, 0.9757, 1.0075, 0.9732, 1.0384, 0.9866, 1.0129, 1.0191, 0.9915,\n",
      "        1.0100], grad_fn=<SumBackward1>)\n",
      "35 22\n",
      "torch.Size([22, 22])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0030, 0.9418, 0.8988, 0.9799, 0.9392, 0.9834, 0.9036, 1.0048, 1.0372,\n",
      "        1.1077, 1.1244, 1.1125, 1.0626, 0.9587, 0.9708, 1.0382, 0.9062, 0.9711,\n",
      "        1.0379, 1.0618, 1.0487, 0.9075], grad_fn=<SumBackward1>)\n",
      "36 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0538, 0.9811, 0.9861, 0.9920, 0.9042, 1.0635, 1.0188, 1.0188, 0.9854,\n",
      "        0.9619, 0.9890, 0.8910, 1.0067, 1.0067, 0.9743, 1.0250, 1.0330, 0.9904,\n",
      "        1.0644, 1.0344, 1.0195], grad_fn=<SumBackward1>)\n",
      "37 5\n",
      "torch.Size([5, 5])\n",
      "tensor([1., 1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "tensor([1.0392, 0.9729, 0.9390, 1.0464, 1.0025], grad_fn=<SumBackward1>)\n",
      "38 42\n",
      "torch.Size([42, 42])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0707, 0.9716, 1.0444, 0.9736, 1.0192, 0.9664, 1.0304, 1.0304, 0.9510,\n",
      "        0.9984, 0.9886, 1.0034, 0.9861, 0.9715, 0.9626, 1.0130, 1.0235, 1.0863,\n",
      "        1.0864, 1.0268, 0.9237, 0.9531, 0.8640, 1.0399, 1.0334, 1.0232, 0.9821,\n",
      "        0.9494, 1.0206, 1.0867, 1.0878, 1.0240, 0.9573, 0.9388, 0.9954, 0.9931,\n",
      "        0.9974, 0.9818, 1.0359, 1.0418, 0.8877, 0.9786],\n",
      "       grad_fn=<SumBackward1>)\n",
      "39 9\n",
      "torch.Size([9, 9])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0133, 0.9787, 0.9595, 1.0050, 1.0017, 1.0089, 1.0103, 1.0110, 1.0118],\n",
      "       grad_fn=<SumBackward1>)\n",
      "40 28\n",
      "torch.Size([28, 28])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0694, 0.9688, 1.0028, 0.9768, 0.9083, 1.0055, 0.9703, 1.0281, 0.9606,\n",
      "        0.9172, 0.9963, 1.0177, 1.0336, 1.0527, 1.0479, 0.9800, 0.9385, 0.9837,\n",
      "        1.0368, 1.0881, 1.0641, 1.0113, 0.9275, 1.0750, 1.0277, 1.0228, 0.9381,\n",
      "        0.9503], grad_fn=<SumBackward1>)\n",
      "41 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1237, 0.9265, 0.9627, 0.9885, 0.9161, 0.9217, 0.9298, 0.9561, 1.0327,\n",
      "        1.0962, 1.1040, 1.0999, 1.0544, 0.9869, 0.9214, 1.0724, 0.9221, 0.9797,\n",
      "        0.9562, 0.9249, 1.1242], grad_fn=<SumBackward1>)\n",
      "42 24\n",
      "torch.Size([24, 24])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1598, 0.9492, 1.0109, 1.0569, 1.0633, 0.9399, 0.9538, 1.0195, 0.9333,\n",
      "        1.1087, 0.9276, 1.0260, 0.9532, 0.9565, 1.0274, 0.9382, 0.9500, 1.0018,\n",
      "        0.9355, 1.0004, 0.9652, 0.9477, 1.1522, 1.0231],\n",
      "       grad_fn=<SumBackward1>)\n",
      "43 24\n",
      "torch.Size([24, 24])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1811, 0.9515, 1.0067, 1.0242, 1.0078, 0.9505, 1.1813, 1.0257, 0.9621,\n",
      "        0.9505, 1.0287, 0.9206, 1.1252, 0.9139, 1.0336, 0.9455, 0.9486, 1.0341,\n",
      "        0.9292, 0.9469, 0.9902, 0.9355, 0.9887, 1.0181],\n",
      "       grad_fn=<SumBackward1>)\n",
      "44 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1130, 0.9453, 1.0543, 0.9573, 1.0826, 0.9779, 0.9424, 0.9707, 0.9138,\n",
      "        1.0118, 0.9524, 1.0353, 1.0356, 1.0752, 1.0822, 1.0753, 1.0558, 0.9139,\n",
      "        0.9976, 0.9474, 0.9921, 0.8987, 1.0635, 1.0635, 0.8936, 0.9489],\n",
      "       grad_fn=<SumBackward1>)\n",
      "45 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9998, 1.0201, 0.9980, 1.0017, 0.9724, 1.0135, 0.9638, 0.9613, 0.9837,\n",
      "        1.0147, 0.9896, 1.0054, 1.0299, 1.0185, 0.9691, 0.9933, 0.9932, 0.9932,\n",
      "        0.9932, 1.0005, 0.9613, 0.9638, 1.0229, 1.0121, 1.0186, 1.0233, 1.0272,\n",
      "        1.0298, 1.0260], grad_fn=<SumBackward1>)\n",
      "46 23\n",
      "torch.Size([23, 23])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0614, 1.0180, 0.9404, 1.0329, 1.0034, 0.9418, 1.0323, 0.9162, 0.9141,\n",
      "        0.9821, 1.0406, 1.0516, 0.9469, 1.0811, 0.9554, 1.0237, 1.0004, 0.9478,\n",
      "        1.0290, 0.9959, 0.9351, 1.0256, 1.1243], grad_fn=<SumBackward1>)\n",
      "47 18\n",
      "torch.Size([18, 18])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0706, 1.0051, 1.0593, 1.0334, 0.8956, 0.9039, 1.0684, 0.9478, 0.8805,\n",
      "        0.9475, 1.0394, 1.1266, 1.1404, 1.1320, 1.0655, 0.8653, 0.8502, 0.9686],\n",
      "       grad_fn=<SumBackward1>)\n",
      "48 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0940, 0.9608, 1.0067, 0.9623, 0.9932, 0.9751, 1.0003, 0.9967, 0.9616,\n",
      "        1.0325, 1.0047, 1.0121], grad_fn=<SumBackward1>)\n",
      "49 25\n",
      "torch.Size([25, 25])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0477, 0.9794, 1.0069, 0.9864, 0.9889, 1.0240, 1.0146, 0.9728, 1.0150,\n",
      "        1.0147, 0.9725, 1.0147, 1.0150, 0.9728, 1.0146, 1.0259, 0.9891, 1.0016,\n",
      "        0.9661, 1.0075, 0.9651, 0.9874, 0.9998, 0.9704, 1.0470],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "common_dim = 200\n",
    "eps = 1e-7\n",
    "k = torch.autograd.Variable(torch.randn(args.pc_hidden, common_dim))\n",
    "q = torch.autograd.Variable(torch.randn(args.pc_hidden, common_dim))\n",
    "\n",
    "for idx, (stx, lex) in enumerate(X.scope):\n",
    "    yhat = yhat_embedding[stx:stx+lex]\n",
    "    x = x_embedding[stx:stx+lex]\n",
    "    M = 1/np.sqrt(common_dim) * torch.matmul(torch.matmul(x, k), torch.matmul(q.T, yhat.T))\n",
    "    attn = torch.softmax(M, dim = 1) + eps\n",
    "    W = (attn / attn.sum(axis = 0))\n",
    "   \n",
    "    print (idx, lex)\n",
    "    print (W.shape)\n",
    "    print (W.sum(axis = 0))\n",
    "    print (W.sum(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3210,  1.0000,  0.8900,  0.9833,  0.8405, -0.6980, -0.7123,  0.7128,\n",
       "         -0.7083, -0.7085,  0.7059, -0.7085, -0.7083,  0.7128, -0.7167, -0.7052,\n",
       "          0.8089,  0.9047,  0.7706,  0.2424,  0.4358, -0.0064,  0.5527,  0.7171,\n",
       "         -0.1748],\n",
       "        [-0.0768,  0.9521,  0.7138,  0.8073,  0.8134, -1.0000, -1.0000,  0.7921,\n",
       "         -1.0000, -1.0000,  0.7976, -1.0000, -1.0000,  0.7921, -1.0000, -1.0000,\n",
       "          0.7575,  0.6841,  0.4326,  0.2975,  0.2759, -0.3350,  0.2958,  0.3458,\n",
       "         -0.6696],\n",
       "        [-0.0618,  1.0000,  0.7254,  0.8289,  0.8658, -0.8293, -0.8603,  0.8876,\n",
       "         -0.8590, -0.8605,  0.8909, -0.8605, -0.8590,  0.8876, -0.8662, -0.8450,\n",
       "          0.8188,  0.6882,  0.4418,  0.2033,  0.1568, -0.2202,  0.3427,  0.4994,\n",
       "         -0.5441],\n",
       "        [-0.0192,  1.0000,  0.7863,  0.8996,  0.9311, -0.8528, -0.8738,  0.9575,\n",
       "         -0.8741, -0.8753,  0.9593, -0.8753, -0.8741,  0.9575, -0.8796, -0.8684,\n",
       "          0.8789,  0.7613,  0.4952,  0.2455,  0.2259, -0.2167,  0.3993,  0.5440,\n",
       "         -0.5132],\n",
       "        [-0.0540,  1.0000,  0.7858,  0.8792,  0.9124, -0.8633, -0.8823,  0.9306,\n",
       "         -0.8800, -0.8814,  0.9348, -0.8814, -0.8800,  0.9306, -0.8893, -0.8773,\n",
       "          0.8559,  0.7518,  0.5011,  0.2058,  0.1133, -0.2430,  0.4196,  0.4911,\n",
       "         -0.5799],\n",
       "        [ 0.1913,  1.0000,  0.8408,  0.9072,  0.8898, -0.7313, -0.7559,  0.8650,\n",
       "         -0.7550, -0.7567,  0.8702, -0.7567, -0.7550,  0.8650, -0.7621, -0.7466,\n",
       "          0.8511,  0.7578,  0.7033,  0.3260,  0.6189,  0.0355,  0.4635,  0.5894,\n",
       "         -0.3260],\n",
       "        [ 0.1748,  1.0000,  0.8246,  0.9007,  0.8851, -0.7684, -0.7934,  0.8636,\n",
       "         -0.7925, -0.7942,  0.8688, -0.7942, -0.7925,  0.8636, -0.7997, -0.7842,\n",
       "          0.8463,  0.7475,  0.6892,  0.3383,  0.6123,  0.0179,  0.4585,  0.6213,\n",
       "         -0.3545],\n",
       "        [-0.1168,  1.0000,  0.7819,  0.8699,  0.8899, -0.9534, -0.9669,  0.8923,\n",
       "         -0.9624, -0.9638,  0.8979, -0.9638, -0.9624,  0.8923, -0.9754, -0.9653,\n",
       "          0.8297,  0.7463,  0.5048,  0.1262,  0.0459, -0.3058,  0.4273,  0.4695,\n",
       "         -0.6701],\n",
       "        [ 0.1579,  1.0000,  0.8310,  0.9103,  0.8929, -0.7579, -0.7819,  0.8699,\n",
       "         -0.7812, -0.7830,  0.8753, -0.7830, -0.7812,  0.8699, -0.7883, -0.7739,\n",
       "          0.8532,  0.7558,  0.6950,  0.3469,  0.6016,  0.0264,  0.4670,  0.6286,\n",
       "         -0.3718],\n",
       "        [ 0.1556,  1.0000,  0.8296,  0.9089,  0.8917, -0.7605, -0.7845,  0.8687,\n",
       "         -0.7839, -0.7858,  0.8741, -0.7858, -0.7839,  0.8687, -0.7908, -0.7763,\n",
       "          0.8521,  0.7542,  0.6941,  0.3433,  0.6001,  0.0254,  0.4646,  0.6268,\n",
       "         -0.3735],\n",
       "        [-0.1181,  1.0000,  0.7773,  0.8662,  0.8867, -0.9576, -0.9713,  0.8890,\n",
       "         -0.9668, -0.9683,  0.8947, -0.9683, -0.9668,  0.8890, -0.9797, -0.9697,\n",
       "          0.8264,  0.7428,  0.5010,  0.1341,  0.0385, -0.3110,  0.4258,  0.4677,\n",
       "         -0.6772],\n",
       "        [ 0.1556,  1.0000,  0.8296,  0.9089,  0.8917, -0.7605, -0.7845,  0.8687,\n",
       "         -0.7839, -0.7858,  0.8741, -0.7858, -0.7839,  0.8687, -0.7908, -0.7763,\n",
       "          0.8521,  0.7542,  0.6941,  0.3433,  0.6001,  0.0254,  0.4646,  0.6268,\n",
       "         -0.3735],\n",
       "        [ 0.1579,  1.0000,  0.8310,  0.9103,  0.8929, -0.7579, -0.7819,  0.8699,\n",
       "         -0.7812, -0.7830,  0.8753, -0.7830, -0.7812,  0.8699, -0.7883, -0.7739,\n",
       "          0.8532,  0.7558,  0.6950,  0.3469,  0.6016,  0.0264,  0.4670,  0.6286,\n",
       "         -0.3718],\n",
       "        [-0.1168,  1.0000,  0.7819,  0.8699,  0.8899, -0.9534, -0.9669,  0.8923,\n",
       "         -0.9624, -0.9638,  0.8979, -0.9638, -0.9624,  0.8923, -0.9754, -0.9653,\n",
       "          0.8297,  0.7463,  0.5048,  0.1262,  0.0459, -0.3058,  0.4273,  0.4695,\n",
       "         -0.6701],\n",
       "        [ 0.1741,  1.0000,  0.8257,  0.9015,  0.8863, -0.7673, -0.7924,  0.8650,\n",
       "         -0.7915, -0.7932,  0.8702, -0.7932, -0.7915,  0.8650, -0.7988, -0.7830,\n",
       "          0.8474,  0.7488,  0.6906,  0.3349,  0.6124,  0.0197,  0.4597,  0.6223,\n",
       "         -0.3536],\n",
       "        [ 0.1936,  1.0000,  0.8394,  0.9046,  0.8876, -0.7248, -0.7499,  0.8630,\n",
       "         -0.7487, -0.7504,  0.8684, -0.7504, -0.7487,  0.8630, -0.7560, -0.7402,\n",
       "          0.8491,  0.7562,  0.7006,  0.3284,  0.6140,  0.0355,  0.4644,  0.5920,\n",
       "         -0.3244],\n",
       "        [-0.0572,  1.0000,  0.7950,  0.8908,  0.9088, -0.8754, -0.8905,  0.9144,\n",
       "         -0.8892, -0.8905,  0.9185, -0.8905, -0.8892,  0.9144, -0.8974, -0.8883,\n",
       "          0.8511,  0.7658,  0.5079,  0.2142,  0.1773, -0.2236,  0.4106,  0.4788,\n",
       "         -0.5576],\n",
       "        [ 0.0779,  1.0000,  0.8348,  0.9467,  0.9772, -0.7495, -0.7766,  1.0000,\n",
       "         -0.7750, -0.7761,  1.0000, -0.7761, -0.7750,  1.0000, -0.7828, -0.7665,\n",
       "          0.9260,  0.8031,  0.5606,  0.3661,  0.2765, -0.1284,  0.4314,  0.5667,\n",
       "         -0.4317],\n",
       "        [ 0.0065,  1.0000,  0.8805,  1.0000,  1.0000, -0.8179, -0.8222,  1.0000,\n",
       "         -0.8222, -0.8232,  1.0000, -0.8232, -0.8222,  1.0000, -0.8286, -0.8337,\n",
       "          1.0000,  0.8930,  0.6264,  0.4371,  0.4260, -0.1267,  0.5024,  0.6390,\n",
       "         -0.5011],\n",
       "        [ 0.2210,  1.0000,  1.0000,  1.0000,  1.0000, -0.3084, -0.2904,  1.0000,\n",
       "         -0.2992, -0.3019,  1.0000, -0.3019, -0.2992,  1.0000, -0.2950, -0.3206,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000,  0.8682,  0.5185,  0.8965,  0.8302,\n",
       "         -0.1449],\n",
       "        [ 0.2311,  1.0000,  1.0000,  1.0000,  1.0000, -0.7886, -0.7698,  1.0000,\n",
       "         -0.7739, -0.7761,  1.0000, -0.7761, -0.7739,  1.0000, -0.7745, -0.7921,\n",
       "          1.0000,  1.0000,  0.7905,  0.6607,  0.6492, -0.2048,  0.8705,  0.7426,\n",
       "         -0.3263],\n",
       "        [ 0.0057,  1.0000,  0.9610,  1.0000,  1.0000, -0.7389, -0.6954,  1.0000,\n",
       "         -0.7076, -0.7094,  1.0000, -0.7094, -0.7076,  1.0000, -0.7004, -0.7467,\n",
       "          1.0000,  0.9587,  0.6473,  0.2153,  0.5956, -0.1420,  0.5585,  0.6801,\n",
       "         -0.4250],\n",
       "        [ 0.0800,  1.0000,  0.9113,  1.0000,  1.0000, -0.6885, -0.7165,  1.0000,\n",
       "         -0.7153, -0.7162,  1.0000, -0.7162, -0.7153,  1.0000, -0.7239, -0.7028,\n",
       "          0.9969,  0.8811,  0.6500,  0.5345,  0.3037, -0.0148,  0.5109,  0.6185,\n",
       "         -0.5135],\n",
       "        [-0.0883,  1.0000,  0.7669,  0.8562,  0.8553, -1.0000, -1.0000,  0.8135,\n",
       "         -1.0000, -1.0000,  0.8189, -1.0000, -1.0000,  0.8135, -1.0000, -1.0000,\n",
       "          0.7994,  0.7409,  0.4324,  0.2198,  0.3831, -0.3258,  0.2926,  0.3572,\n",
       "         -0.5995],\n",
       "        [ 0.2125,  1.0000,  0.8218,  0.9040,  0.8035, -0.7332, -0.7202,  0.7343,\n",
       "         -0.7226, -0.7233,  0.7292, -0.7233, -0.7226,  0.7343, -0.7252, -0.7413,\n",
       "          0.7677,  0.8395,  0.6586,  0.2859,  0.4868, -0.0438,  0.5978,  0.7242,\n",
       "         -0.2707]], grad_fn=<ClampBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 25])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8806e+01,  1.2745e+02,  8.5013e+01,  1.6420e+02,  1.8269e+01,\n",
       "         -1.2526e+02, -6.7990e+01,  2.9985e+01, -6.0364e+01, -6.3572e+01,\n",
       "          2.8890e+01, -6.3572e+01, -6.0364e+01,  2.9985e+01, -5.5506e+01,\n",
       "         -1.0067e+02,  5.0763e+01,  2.1775e+02,  9.6130e+01,  1.8065e+02,\n",
       "         -3.5103e+01,  2.1741e+02,  1.9373e+02,  1.2703e+02,  5.9381e+01],\n",
       "        [-1.8349e+01,  9.2621e+01,  1.3784e+02,  1.6916e+02,  8.9967e+00,\n",
       "         -1.7360e+02, -1.5138e+02, -4.8960e+01, -1.5916e+02, -1.6577e+02,\n",
       "         -4.5353e+01, -1.6577e+02, -1.5916e+02, -4.8960e+01, -1.4277e+02,\n",
       "         -1.3320e+02,  5.1016e+01,  9.9278e+01,  8.4654e+01,  1.2031e+02,\n",
       "         -9.5534e+01,  1.5498e+02,  1.2172e+02,  5.0620e+01,  4.9736e+01],\n",
       "        [ 1.3419e+01,  1.7614e+02,  2.3679e+02,  3.0860e+02,  2.7714e+01,\n",
       "         -1.3887e+02, -7.2370e+01, -6.2119e+01, -8.8330e+01, -9.7444e+01,\n",
       "         -6.0173e+01, -9.7444e+01, -8.8330e+01, -6.2119e+01, -6.4899e+01,\n",
       "         -8.9064e+01,  7.9825e+01,  2.6198e+02,  1.9640e+02,  1.9484e+02,\n",
       "         -2.9178e+01,  3.4556e+02,  1.9628e+02,  1.3766e+02,  1.3186e+02],\n",
       "        [-3.4180e+01,  1.0178e+02,  9.5928e+01,  1.2640e+02, -2.8854e+01,\n",
       "         -1.4133e+02, -1.0965e+02, -8.2269e+01, -1.2018e+02, -1.2538e+02,\n",
       "         -8.0476e+01, -1.2538e+02, -1.2018e+02, -8.2269e+01, -9.9499e+01,\n",
       "         -1.0409e+02,  1.2272e-01,  9.2307e+01,  1.0439e+02,  1.5120e+02,\n",
       "         -4.2957e+01,  2.5857e+02,  1.2685e+02,  4.1371e+01,  6.3052e+01],\n",
       "        [-8.5577e+01,  7.7856e+01,  7.7830e+01,  9.6812e+01,  1.1632e+01,\n",
       "         -1.3842e+02, -7.1884e+01,  4.3793e+01, -6.8222e+01, -7.0802e+01,\n",
       "          3.6130e+01, -7.0802e+01, -6.8222e+01,  4.3793e+01, -5.6561e+01,\n",
       "         -1.1638e+02,  3.1914e+01,  9.5220e+01,  9.6312e+01,  1.5614e+02,\n",
       "          1.2577e+01,  2.0649e+02,  1.5214e+02,  1.2910e+02,  7.2711e+01],\n",
       "        [-1.0361e+02,  4.0324e+00, -5.5896e+01, -3.1929e+01, -1.6995e+02,\n",
       "         -3.7697e+02, -2.4763e+02, -1.1928e+02, -2.2508e+02, -2.2647e+02,\n",
       "         -1.3082e+02, -2.2647e+02, -2.2508e+02, -1.1928e+02, -2.2862e+02,\n",
       "         -3.3967e+02, -1.1422e+02,  6.9952e+01, -5.5981e+01, -9.1695e+01,\n",
       "          7.8900e+00,  2.4858e+02,  3.1941e+01,  1.8945e+01,  1.6882e+02],\n",
       "        [-1.4226e+02, -5.4908e+01, -6.8499e+01, -6.4735e+01, -1.6340e+02,\n",
       "         -4.4183e+02, -2.9454e+02, -6.9716e+01, -2.6782e+02, -2.6787e+02,\n",
       "         -8.3955e+01, -2.6787e+02, -2.6782e+02, -6.9716e+01, -2.7137e+02,\n",
       "         -3.9315e+02, -9.5103e+01,  7.7355e+01, -7.1096e+01, -8.9529e+01,\n",
       "          2.4529e+01,  2.5405e+02,  4.4291e+01,  1.7562e+01,  1.7040e+02],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-1.4175e+02,  6.9503e+01,  1.0256e+02,  7.8622e+01,  3.3251e+01,\n",
       "         -1.3056e+02, -1.0908e+02,  3.3809e+01, -8.5626e+01, -8.7258e+01,\n",
       "          3.8418e+01, -8.7258e+01, -8.5626e+01,  3.3809e+01, -8.8714e+01,\n",
       "         -9.8440e+01,  4.1398e+01,  2.8889e+01,  5.9545e+01,  1.1578e+02,\n",
       "          8.7794e+01,  2.0508e+02,  6.8253e+01,  7.9645e+01,  8.6628e+01],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [-1.3260e+02, -2.8387e+01, -6.5230e+01, -5.2705e+01, -1.5164e+02,\n",
       "         -4.3932e+02, -2.9490e+02, -5.9763e+01, -2.7242e+02, -2.7222e+02,\n",
       "         -7.2692e+01, -2.7222e+02, -2.7242e+02, -5.9763e+01, -2.7225e+02,\n",
       "         -3.9949e+02, -8.4544e+01,  9.3551e+01, -6.2804e+01, -9.5592e+01,\n",
       "          1.9358e+01,  2.4522e+02,  5.0873e+01,  2.9236e+01,  1.6399e+02],\n",
       "        [-1.1108e+02,  3.0390e+01, -5.2469e+01, -2.3003e+01, -1.5536e+02,\n",
       "         -4.1227e+02, -2.7429e+02, -8.6056e+01, -2.5178e+02, -2.5279e+02,\n",
       "         -9.6545e+01, -2.5279e+02, -2.5178e+02, -8.6056e+01, -2.5256e+02,\n",
       "         -3.7861e+02, -9.3677e+01,  9.3129e+01, -4.9324e+01, -9.2061e+01,\n",
       "         -8.4151e+00,  2.6010e+02,  5.2161e+01,  3.9355e+01,  1.6669e+02],\n",
       "        [-1.0237e+02,  4.4220e+01,  8.6363e+01,  1.0266e+02,  1.9387e+01,\n",
       "         -1.3108e+02, -7.1542e+01,  5.0727e+01, -6.4031e+01, -6.5911e+01,\n",
       "          4.5624e+01, -6.5911e+01, -6.4031e+01,  5.0727e+01, -6.0926e+01,\n",
       "         -1.0589e+02,  4.6251e+01,  1.0855e+02,  1.2764e+02,  2.0013e+02,\n",
       "          2.7195e+01,  2.0535e+02,  1.6045e+02,  1.2593e+02,  5.8524e+01],\n",
       "        [-1.9427e+02, -9.3319e+01, -8.6999e+01, -7.4099e+01,  1.4269e+01,\n",
       "         -2.6058e+02, -2.3335e+02,  1.5223e+02, -2.2765e+02, -2.2457e+02,\n",
       "          1.5967e+02, -2.2457e+02, -2.2765e+02,  1.5223e+02, -2.1992e+02,\n",
       "         -2.5309e+02,  3.1494e+01, -7.3894e+01,  5.6645e+01,  1.1840e+02,\n",
       "         -4.9226e+00,  1.4450e+02,  3.5715e+01, -1.8686e+01, -6.3116e+01],\n",
       "        [-1.1923e+02, -5.9629e+01, -3.5477e+01, -6.2287e+01, -6.7956e+01,\n",
       "         -1.3300e+02, -5.6052e+01, -1.0629e+01, -5.7595e+01, -5.8856e+01,\n",
       "         -2.3312e+01, -5.8856e+01, -5.7595e+01, -1.0629e+01, -4.9471e+01,\n",
       "         -9.8253e+01, -2.9414e+01,  5.3016e+01,  1.4275e+02,  2.0140e+02,\n",
       "          2.5368e+00,  1.6847e+02,  1.6342e+02,  1.0452e+02,  2.9112e+01],\n",
       "        [-5.0592e+01, -1.1114e+02, -2.4645e+01, -2.0936e+02, -1.4528e+02,\n",
       "         -1.5217e+01, -6.7821e+01, -2.8649e+02, -3.2025e+01, -3.9599e+01,\n",
       "         -2.8217e+02, -3.9599e+01, -3.2025e+01, -2.8649e+02, -6.1862e+01,\n",
       "          5.8680e+01, -1.2127e+02, -8.9990e+01, -4.7383e+01,  5.6195e+01,\n",
       "         -1.9670e+01,  5.3916e+01, -2.1905e+01, -2.3979e+01,  8.4365e+01],\n",
       "        [-8.9948e+01,  7.5621e+00,  6.8850e+00,  1.6208e+00, -7.2264e+01,\n",
       "          3.4406e+01,  5.9855e+01, -1.1907e+02,  1.0299e+02,  9.9488e+01,\n",
       "         -1.1880e+02,  9.9488e+01,  1.0299e+02, -1.1907e+02,  6.8117e+01,\n",
       "          1.0220e+02, -2.6015e+01,  1.5597e+02,  2.9095e+01,  1.2512e+02,\n",
       "         -2.9149e+01,  1.3111e+02,  8.7560e+01, -1.8449e+00,  1.6903e+01],\n",
       "        [-5.4560e+01,  1.0016e+02,  1.0596e+02, -2.3179e+01,  1.0314e+02,\n",
       "          1.1376e+02,  4.2291e+01,  1.1896e+02,  5.5046e+01,  5.0743e+01,\n",
       "          1.2211e+02,  5.0743e+01,  5.5046e+01,  1.1896e+02,  3.9664e+01,\n",
       "          1.5812e+02,  1.5471e+02, -8.9072e+00,  1.7950e+02,  1.2768e+02,\n",
       "          2.7970e+00,  7.1505e+01,  1.0331e+02,  7.6419e+01,  4.5112e+01],\n",
       "        [-7.8885e+01,  7.2556e+01,  1.0373e+02,  1.1950e+02,  4.8719e+01,\n",
       "         -1.8229e+02, -1.6753e+02,  3.0221e+01, -1.5645e+02, -1.5841e+02,\n",
       "          3.8944e+01, -1.5841e+02, -1.5645e+02,  3.0221e+01, -1.6239e+02,\n",
       "         -1.4762e+02,  7.8007e+01,  1.0311e+02,  1.3401e+02,  2.9438e+02,\n",
       "          1.1596e+00,  2.4554e+02,  1.0706e+02,  4.1670e+01,  5.8804e+01],\n",
       "        [-9.0737e+01, -8.2141e+00,  1.8435e+01,  4.8170e+01, -4.1254e+01,\n",
       "         -2.2802e+02, -1.9034e+02, -2.5503e+01, -1.9098e+02, -1.9185e+02,\n",
       "         -2.4767e+01, -1.9185e+02, -1.9098e+02, -2.5503e+01, -1.8670e+02,\n",
       "         -2.0945e+02,  4.1963e+00,  5.1351e+01,  7.6705e+01,  1.5329e+02,\n",
       "         -1.5772e+01,  1.3750e+02,  1.0138e+02,  5.1821e+01,  5.6784e+01],\n",
       "        [ 6.9156e+01, -7.7571e+00,  2.0306e+02,  3.8969e+01,  6.6164e+01,\n",
       "          1.7069e+02,  5.3064e+01, -4.5214e+01,  9.8600e+01,  9.0422e+01,\n",
       "         -4.2173e+01,  9.0422e+01,  9.8600e+01, -4.5214e+01,  4.0607e+01,\n",
       "          2.4738e+02,  1.2399e+02,  4.4344e+01,  1.7271e+02,  2.4028e+02,\n",
       "          5.4295e+01,  1.0368e+02,  6.2485e+01,  3.5069e+01,  9.9739e+01]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdet_orig = M.detach().cpu().numpy().copy()\n",
    "Mdet = M.detach().cpu().numpy().copy()\n",
    "np.random.shuffle(Mdet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36550903e+02,  6.81647415e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319481e+01, -1.35173340e+02,\n",
       "        -1.08069221e+02,  3.83839455e+01, -8.44185638e+01,\n",
       "        -8.56652298e+01,  4.37059669e+01, -8.56652298e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548050e+01,  4.25657501e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223709e+01,\n",
       "         2.01263702e+02,  6.49279480e+01,  7.15621567e+01,\n",
       "         8.77687454e+01],\n",
       "       [-1.41745499e+02,  6.95025024e+01,  1.02559906e+02,\n",
       "         7.86224289e+01,  3.32511063e+01, -1.30562500e+02,\n",
       "        -1.09084831e+02,  3.38087959e+01, -8.56264267e+01,\n",
       "        -8.72580566e+01,  3.84175034e+01, -8.72580566e+01,\n",
       "        -8.56264267e+01,  3.38088036e+01, -8.87138443e+01,\n",
       "        -9.84396439e+01,  4.13976135e+01,  2.88886242e+01,\n",
       "         5.95451431e+01,  1.15779877e+02,  8.77940063e+01,\n",
       "         2.05081360e+02,  6.82530594e+01,  7.96451645e+01,\n",
       "         8.66283646e+01],\n",
       "       [-1.83492146e+01,  9.26209259e+01,  1.37842575e+02,\n",
       "         1.69162537e+02,  8.99667835e+00, -1.73602600e+02,\n",
       "        -1.51378342e+02, -4.89596748e+01, -1.59155289e+02,\n",
       "        -1.65768341e+02, -4.53528862e+01, -1.65768341e+02,\n",
       "        -1.59155289e+02, -4.89596748e+01, -1.42774399e+02,\n",
       "        -1.33195892e+02,  5.10164108e+01,  9.92778549e+01,\n",
       "         8.46540451e+01,  1.20313560e+02, -9.55340500e+01,\n",
       "         1.54979660e+02,  1.21715820e+02,  5.06204796e+01,\n",
       "         4.97362747e+01],\n",
       "       [-1.02365128e+02,  4.42197723e+01,  8.63626709e+01,\n",
       "         1.02662292e+02,  1.93874683e+01, -1.31079193e+02,\n",
       "        -7.15418625e+01,  5.07268791e+01, -6.40310364e+01,\n",
       "        -6.59105530e+01,  4.56244392e+01, -6.59105530e+01,\n",
       "        -6.40310364e+01,  5.07268791e+01, -6.09264412e+01,\n",
       "        -1.05887657e+02,  4.62507591e+01,  1.08548080e+02,\n",
       "         1.27635468e+02,  2.00126785e+02,  2.71951561e+01,\n",
       "         2.05350586e+02,  1.60445786e+02,  1.25930275e+02,\n",
       "         5.85239143e+01],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-1.11082222e+02,  3.03898048e+01, -5.24693451e+01,\n",
       "        -2.30031281e+01, -1.55363968e+02, -4.12267548e+02,\n",
       "        -2.74289490e+02, -8.60564117e+01, -2.51776825e+02,\n",
       "        -2.52794312e+02, -9.65450439e+01, -2.52794312e+02,\n",
       "        -2.51776825e+02, -8.60564117e+01, -2.52561707e+02,\n",
       "        -3.78611755e+02, -9.36768112e+01,  9.31287613e+01,\n",
       "        -4.93243065e+01, -9.20607681e+01, -8.41514111e+00,\n",
       "         2.60104584e+02,  5.21609955e+01,  3.93547935e+01,\n",
       "         1.66690750e+02],\n",
       "       [-1.36550873e+02,  6.81647491e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319443e+01, -1.35173370e+02,\n",
       "        -1.08069221e+02,  3.83839607e+01, -8.44185638e+01,\n",
       "        -8.56652756e+01,  4.37059593e+01, -8.56652756e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548431e+01,  4.25657425e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223557e+01,\n",
       "         2.01263657e+02,  6.49279404e+01,  7.15621414e+01,\n",
       "         8.77687378e+01],\n",
       "       [ 1.34186239e+01,  1.76136963e+02,  2.36792114e+02,\n",
       "         3.08596344e+02,  2.77139816e+01, -1.38867889e+02,\n",
       "        -7.23698807e+01, -6.21188812e+01, -8.83300476e+01,\n",
       "        -9.74438477e+01, -6.01728668e+01, -9.74438477e+01,\n",
       "        -8.83300476e+01, -6.21188812e+01, -6.48987961e+01,\n",
       "        -8.90636063e+01,  7.98253708e+01,  2.61980255e+02,\n",
       "         1.96402252e+02,  1.94839828e+02, -2.91775169e+01,\n",
       "         3.45563812e+02,  1.96279922e+02,  1.37662170e+02,\n",
       "         1.31858047e+02],\n",
       "       [-1.01353043e+02, -1.62935600e+01, -4.81409302e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-9.07371368e+01, -8.21410179e+00,  1.84349041e+01,\n",
       "         4.81701889e+01, -4.12543602e+01, -2.28016327e+02,\n",
       "        -1.90343597e+02, -2.55028915e+01, -1.90976151e+02,\n",
       "        -1.91850769e+02, -2.47672958e+01, -1.91850769e+02,\n",
       "        -1.90976151e+02, -2.55028915e+01, -1.86695374e+02,\n",
       "        -2.09454132e+02,  4.19630194e+00,  5.13508949e+01,\n",
       "         7.67049484e+01,  1.53291550e+02, -1.57724085e+01,\n",
       "         1.37503357e+02,  1.01375107e+02,  5.18212547e+01,\n",
       "         5.67843666e+01],\n",
       "       [-7.88852692e+01,  7.25557861e+01,  1.03729790e+02,\n",
       "         1.19504967e+02,  4.87192879e+01, -1.82292557e+02,\n",
       "        -1.67526459e+02,  3.02212849e+01, -1.56447525e+02,\n",
       "        -1.58408875e+02,  3.89437447e+01, -1.58408875e+02,\n",
       "        -1.56447525e+02,  3.02212849e+01, -1.62388000e+02,\n",
       "        -1.47620087e+02,  7.80071945e+01,  1.03107742e+02,\n",
       "         1.34013702e+02,  2.94375854e+02,  1.15958142e+00,\n",
       "         2.45539108e+02,  1.07058586e+02,  4.16696701e+01,\n",
       "         5.88036499e+01],\n",
       "       [-1.94267349e+02, -9.33194885e+01, -8.69994965e+01,\n",
       "        -7.40991135e+01,  1.42685404e+01, -2.60582245e+02,\n",
       "        -2.33354507e+02,  1.52231323e+02, -2.27652618e+02,\n",
       "        -2.24569138e+02,  1.59670258e+02, -2.24569138e+02,\n",
       "        -2.27652618e+02,  1.52231323e+02, -2.19920303e+02,\n",
       "        -2.53092010e+02,  3.14940853e+01, -7.38941040e+01,\n",
       "         5.66454620e+01,  1.18396759e+02, -4.92256498e+00,\n",
       "         1.44501602e+02,  3.57148056e+01, -1.86855354e+01,\n",
       "        -6.31158371e+01],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-4.88056641e+01,  1.27446671e+02,  8.50131836e+01,\n",
       "         1.64195267e+02,  1.82686081e+01, -1.25264709e+02,\n",
       "        -6.79895096e+01,  2.99845352e+01, -6.03640709e+01,\n",
       "        -6.35715599e+01,  2.88896904e+01, -6.35715599e+01,\n",
       "        -6.03640709e+01,  2.99845352e+01, -5.55064354e+01,\n",
       "        -1.00666046e+02,  5.07632561e+01,  2.17748779e+02,\n",
       "         9.61298676e+01,  1.80651260e+02, -3.51030121e+01,\n",
       "         2.17405273e+02,  1.93726181e+02,  1.27026718e+02,\n",
       "         5.93812599e+01],\n",
       "       [-5.45599861e+01,  1.00158745e+02,  1.05964836e+02,\n",
       "        -2.31788368e+01,  1.03137474e+02,  1.13762985e+02,\n",
       "         4.22908745e+01,  1.18958099e+02,  5.50460625e+01,\n",
       "         5.07430649e+01,  1.22109154e+02,  5.07430649e+01,\n",
       "         5.50460625e+01,  1.18958084e+02,  3.96638756e+01,\n",
       "         1.58115173e+02,  1.54708847e+02, -8.90717983e+00,\n",
       "         1.79497879e+02,  1.27680420e+02,  2.79696488e+00,\n",
       "         7.15046005e+01,  1.03312851e+02,  7.64186859e+01,\n",
       "         4.51117783e+01],\n",
       "       [-3.41802597e+01,  1.01781570e+02,  9.59276352e+01,\n",
       "         1.26400780e+02, -2.88540478e+01, -1.41332748e+02,\n",
       "        -1.09651588e+02, -8.22688065e+01, -1.20184616e+02,\n",
       "        -1.25382523e+02, -8.04758759e+01, -1.25382523e+02,\n",
       "        -1.20184616e+02, -8.22688065e+01, -9.94991913e+01,\n",
       "        -1.04089645e+02,  1.22722663e-01,  9.23067322e+01,\n",
       "         1.04388435e+02,  1.51203842e+02, -4.29573746e+01,\n",
       "         2.58570312e+02,  1.26849747e+02,  4.13706169e+01,\n",
       "         6.30515633e+01],\n",
       "       [-5.05915604e+01, -1.11137825e+02, -2.46446323e+01,\n",
       "        -2.09355728e+02, -1.45283829e+02, -1.52174692e+01,\n",
       "        -6.78208542e+01, -2.86494415e+02, -3.20254326e+01,\n",
       "        -3.95985756e+01, -2.82174957e+02, -3.95985756e+01,\n",
       "        -3.20254326e+01, -2.86494415e+02, -6.18615494e+01,\n",
       "         5.86800423e+01, -1.21269150e+02, -8.99904022e+01,\n",
       "        -4.73829536e+01,  5.61949043e+01, -1.96696320e+01,\n",
       "         5.39164009e+01, -2.19052486e+01, -2.39790688e+01,\n",
       "         8.43652802e+01],\n",
       "       [ 6.91557465e+01, -7.75707722e+00,  2.03064453e+02,\n",
       "         3.89688568e+01,  6.61638870e+01,  1.70689346e+02,\n",
       "         5.30642090e+01, -4.52142029e+01,  9.85995789e+01,\n",
       "         9.04224091e+01, -4.21729965e+01,  9.04224091e+01,\n",
       "         9.85995789e+01, -4.52142105e+01,  4.06072273e+01,\n",
       "         2.47382370e+02,  1.23985901e+02,  4.43443184e+01,\n",
       "         1.72711823e+02,  2.40278519e+02,  5.42948418e+01,\n",
       "         1.03681747e+02,  6.24854622e+01,  3.50694237e+01,\n",
       "         9.97391357e+01],\n",
       "       [-8.55771942e+01,  7.78556366e+01,  7.78295135e+01,\n",
       "         9.68123550e+01,  1.16317530e+01, -1.38424561e+02,\n",
       "        -7.18837509e+01,  4.37928772e+01, -6.82218170e+01,\n",
       "        -7.08022308e+01,  3.61296844e+01, -7.08022308e+01,\n",
       "        -6.82218170e+01,  4.37928772e+01, -5.65611610e+01,\n",
       "        -1.16380333e+02,  3.19141293e+01,  9.52203903e+01,\n",
       "         9.63119049e+01,  1.56136108e+02,  1.25771351e+01,\n",
       "         2.06493317e+02,  1.52142303e+02,  1.29101456e+02,\n",
       "         7.27111893e+01],\n",
       "       [-1.32601089e+02, -2.83870506e+01, -6.52298203e+01,\n",
       "        -5.27048187e+01, -1.51636551e+02, -4.39321747e+02,\n",
       "        -2.94904388e+02, -5.97630577e+01, -2.72415894e+02,\n",
       "        -2.72224030e+02, -7.26923523e+01, -2.72224030e+02,\n",
       "        -2.72415894e+02, -5.97630692e+01, -2.72250702e+02,\n",
       "        -3.99491547e+02, -8.45443573e+01,  9.35509109e+01,\n",
       "        -6.28044281e+01, -9.55923538e+01,  1.93577957e+01,\n",
       "         2.45220795e+02,  5.08734131e+01,  2.92363091e+01,\n",
       "         1.63989105e+02],\n",
       "       [-1.01353043e+02, -1.62935486e+01, -4.81409454e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-8.99477539e+01,  7.56210232e+00,  6.88499069e+00,\n",
       "         1.62078476e+00, -7.22636414e+01,  3.44055786e+01,\n",
       "         5.98550415e+01, -1.19069115e+02,  1.02992706e+02,\n",
       "         9.94882050e+01, -1.18800636e+02,  9.94882050e+01,\n",
       "         1.02992706e+02, -1.19069099e+02,  6.81170349e+01,\n",
       "         1.02202347e+02, -2.60145473e+01,  1.55966446e+02,\n",
       "         2.90947914e+01,  1.25119064e+02, -2.91494045e+01,\n",
       "         1.31105179e+02,  8.75604782e+01, -1.84493661e+00,\n",
       "         1.69025841e+01],\n",
       "       [-1.19229172e+02, -5.96294746e+01, -3.54770164e+01,\n",
       "        -6.22872696e+01, -6.79555588e+01, -1.33002975e+02,\n",
       "        -5.60519295e+01, -1.06289597e+01, -5.75945892e+01,\n",
       "        -5.88556023e+01, -2.33123817e+01, -5.88556023e+01,\n",
       "        -5.75945892e+01, -1.06289587e+01, -4.94709129e+01,\n",
       "        -9.82530899e+01, -2.94137039e+01,  5.30157661e+01,\n",
       "         1.42747665e+02,  2.01400970e+02,  2.53682733e+00,\n",
       "         1.68473206e+02,  1.63419891e+02,  1.04522156e+02,\n",
       "         2.91124153e+01],\n",
       "       [-1.42264709e+02, -5.49079819e+01, -6.84985352e+01,\n",
       "        -6.47350235e+01, -1.63396500e+02, -4.41831390e+02,\n",
       "        -2.94542755e+02, -6.97163086e+01, -2.67818451e+02,\n",
       "        -2.67872864e+02, -8.39545441e+01, -2.67872864e+02,\n",
       "        -2.67818451e+02, -6.97163010e+01, -2.71367615e+02,\n",
       "        -3.93151459e+02, -9.51026230e+01,  7.73551102e+01,\n",
       "        -7.10961914e+01, -8.95292664e+01,  2.45286694e+01,\n",
       "         2.54052979e+02,  4.42912254e+01,  1.75615902e+01,\n",
       "         1.70402695e+02],\n",
       "       [-1.03609627e+02,  4.03235579e+00, -5.58961792e+01,\n",
       "        -3.19293747e+01, -1.69948975e+02, -3.76969299e+02,\n",
       "        -2.47625702e+02, -1.19275635e+02, -2.25075485e+02,\n",
       "        -2.26471771e+02, -1.30822815e+02, -2.26471771e+02,\n",
       "        -2.25075485e+02, -1.19275635e+02, -2.28617111e+02,\n",
       "        -3.39665985e+02, -1.14217369e+02,  6.99518433e+01,\n",
       "        -5.59809036e+01, -9.16953354e+01,  7.88998842e+00,\n",
       "         2.48581375e+02,  3.19408703e+01,  1.89452496e+01,\n",
       "         1.68819168e+02]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36550903e+02,  6.81647415e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319481e+01, -1.35173340e+02,\n",
       "        -1.08069221e+02,  3.83839455e+01, -8.44185638e+01,\n",
       "        -8.56652298e+01,  4.37059669e+01, -8.56652298e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548050e+01,  4.25657501e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223709e+01,\n",
       "         2.01263702e+02,  6.49279480e+01,  7.15621567e+01,\n",
       "         8.77687454e+01],\n",
       "       [-5.45599861e+01,  1.00158745e+02,  1.05964836e+02,\n",
       "        -2.31788368e+01,  1.03137474e+02,  1.13762985e+02,\n",
       "         4.22908745e+01,  1.18958099e+02,  5.50460625e+01,\n",
       "         5.07430649e+01,  1.22109154e+02,  5.07430649e+01,\n",
       "         5.50460625e+01,  1.18958084e+02,  3.96638756e+01,\n",
       "         1.58115173e+02,  1.54708847e+02, -8.90717983e+00,\n",
       "         1.79497879e+02,  1.27680420e+02,  2.79696488e+00,\n",
       "         7.15046005e+01,  1.03312851e+02,  7.64186859e+01,\n",
       "         4.51117783e+01],\n",
       "       [-1.41745499e+02,  6.95025024e+01,  1.02559906e+02,\n",
       "         7.86224289e+01,  3.32511063e+01, -1.30562500e+02,\n",
       "        -1.09084831e+02,  3.38087959e+01, -8.56264267e+01,\n",
       "        -8.72580566e+01,  3.84175034e+01, -8.72580566e+01,\n",
       "        -8.56264267e+01,  3.38088036e+01, -8.87138443e+01,\n",
       "        -9.84396439e+01,  4.13976135e+01,  2.88886242e+01,\n",
       "         5.95451431e+01,  1.15779877e+02,  8.77940063e+01,\n",
       "         2.05081360e+02,  6.82530594e+01,  7.96451645e+01,\n",
       "         8.66283646e+01],\n",
       "       [-1.36550873e+02,  6.81647491e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319443e+01, -1.35173370e+02,\n",
       "        -1.08069221e+02,  3.83839607e+01, -8.44185638e+01,\n",
       "        -8.56652756e+01,  4.37059593e+01, -8.56652756e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548431e+01,  4.25657425e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223557e+01,\n",
       "         2.01263657e+02,  6.49279404e+01,  7.15621414e+01,\n",
       "         8.77687378e+01],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-8.55771942e+01,  7.78556366e+01,  7.78295135e+01,\n",
       "         9.68123550e+01,  1.16317530e+01, -1.38424561e+02,\n",
       "        -7.18837509e+01,  4.37928772e+01, -6.82218170e+01,\n",
       "        -7.08022308e+01,  3.61296844e+01, -7.08022308e+01,\n",
       "        -6.82218170e+01,  4.37928772e+01, -5.65611610e+01,\n",
       "        -1.16380333e+02,  3.19141293e+01,  9.52203903e+01,\n",
       "         9.63119049e+01,  1.56136108e+02,  1.25771351e+01,\n",
       "         2.06493317e+02,  1.52142303e+02,  1.29101456e+02,\n",
       "         7.27111893e+01],\n",
       "       [-5.05915604e+01, -1.11137825e+02, -2.46446323e+01,\n",
       "        -2.09355728e+02, -1.45283829e+02, -1.52174692e+01,\n",
       "        -6.78208542e+01, -2.86494415e+02, -3.20254326e+01,\n",
       "        -3.95985756e+01, -2.82174957e+02, -3.95985756e+01,\n",
       "        -3.20254326e+01, -2.86494415e+02, -6.18615494e+01,\n",
       "         5.86800423e+01, -1.21269150e+02, -8.99904022e+01,\n",
       "        -4.73829536e+01,  5.61949043e+01, -1.96696320e+01,\n",
       "         5.39164009e+01, -2.19052486e+01, -2.39790688e+01,\n",
       "         8.43652802e+01],\n",
       "       [-1.03609627e+02,  4.03235579e+00, -5.58961792e+01,\n",
       "        -3.19293747e+01, -1.69948975e+02, -3.76969299e+02,\n",
       "        -2.47625702e+02, -1.19275635e+02, -2.25075485e+02,\n",
       "        -2.26471771e+02, -1.30822815e+02, -2.26471771e+02,\n",
       "        -2.25075485e+02, -1.19275635e+02, -2.28617111e+02,\n",
       "        -3.39665985e+02, -1.14217369e+02,  6.99518433e+01,\n",
       "        -5.59809036e+01, -9.16953354e+01,  7.88998842e+00,\n",
       "         2.48581375e+02,  3.19408703e+01,  1.89452496e+01,\n",
       "         1.68819168e+02],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-1.01353043e+02, -1.62935600e+01, -4.81409302e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-1.01353043e+02, -1.62935486e+01, -4.81409454e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-7.88852692e+01,  7.25557861e+01,  1.03729790e+02,\n",
       "         1.19504967e+02,  4.87192879e+01, -1.82292557e+02,\n",
       "        -1.67526459e+02,  3.02212849e+01, -1.56447525e+02,\n",
       "        -1.58408875e+02,  3.89437447e+01, -1.58408875e+02,\n",
       "        -1.56447525e+02,  3.02212849e+01, -1.62388000e+02,\n",
       "        -1.47620087e+02,  7.80071945e+01,  1.03107742e+02,\n",
       "         1.34013702e+02,  2.94375854e+02,  1.15958142e+00,\n",
       "         2.45539108e+02,  1.07058586e+02,  4.16696701e+01,\n",
       "         5.88036499e+01],\n",
       "       [-1.02365128e+02,  4.42197723e+01,  8.63626709e+01,\n",
       "         1.02662292e+02,  1.93874683e+01, -1.31079193e+02,\n",
       "        -7.15418625e+01,  5.07268791e+01, -6.40310364e+01,\n",
       "        -6.59105530e+01,  4.56244392e+01, -6.59105530e+01,\n",
       "        -6.40310364e+01,  5.07268791e+01, -6.09264412e+01,\n",
       "        -1.05887657e+02,  4.62507591e+01,  1.08548080e+02,\n",
       "         1.27635468e+02,  2.00126785e+02,  2.71951561e+01,\n",
       "         2.05350586e+02,  1.60445786e+02,  1.25930275e+02,\n",
       "         5.85239143e+01],\n",
       "       [-1.19229172e+02, -5.96294746e+01, -3.54770164e+01,\n",
       "        -6.22872696e+01, -6.79555588e+01, -1.33002975e+02,\n",
       "        -5.60519295e+01, -1.06289597e+01, -5.75945892e+01,\n",
       "        -5.88556023e+01, -2.33123817e+01, -5.88556023e+01,\n",
       "        -5.75945892e+01, -1.06289587e+01, -4.94709129e+01,\n",
       "        -9.82530899e+01, -2.94137039e+01,  5.30157661e+01,\n",
       "         1.42747665e+02,  2.01400970e+02,  2.53682733e+00,\n",
       "         1.68473206e+02,  1.63419891e+02,  1.04522156e+02,\n",
       "         2.91124153e+01],\n",
       "       [-8.99477539e+01,  7.56210232e+00,  6.88499069e+00,\n",
       "         1.62078476e+00, -7.22636414e+01,  3.44055786e+01,\n",
       "         5.98550415e+01, -1.19069115e+02,  1.02992706e+02,\n",
       "         9.94882050e+01, -1.18800636e+02,  9.94882050e+01,\n",
       "         1.02992706e+02, -1.19069099e+02,  6.81170349e+01,\n",
       "         1.02202347e+02, -2.60145473e+01,  1.55966446e+02,\n",
       "         2.90947914e+01,  1.25119064e+02, -2.91494045e+01,\n",
       "         1.31105179e+02,  8.75604782e+01, -1.84493661e+00,\n",
       "         1.69025841e+01],\n",
       "       [-1.42264709e+02, -5.49079819e+01, -6.84985352e+01,\n",
       "        -6.47350235e+01, -1.63396500e+02, -4.41831390e+02,\n",
       "        -2.94542755e+02, -6.97163086e+01, -2.67818451e+02,\n",
       "        -2.67872864e+02, -8.39545441e+01, -2.67872864e+02,\n",
       "        -2.67818451e+02, -6.97163010e+01, -2.71367615e+02,\n",
       "        -3.93151459e+02, -9.51026230e+01,  7.73551102e+01,\n",
       "        -7.10961914e+01, -8.95292664e+01,  2.45286694e+01,\n",
       "         2.54052979e+02,  4.42912254e+01,  1.75615902e+01,\n",
       "         1.70402695e+02],\n",
       "       [-9.07371368e+01, -8.21410179e+00,  1.84349041e+01,\n",
       "         4.81701889e+01, -4.12543602e+01, -2.28016327e+02,\n",
       "        -1.90343597e+02, -2.55028915e+01, -1.90976151e+02,\n",
       "        -1.91850769e+02, -2.47672958e+01, -1.91850769e+02,\n",
       "        -1.90976151e+02, -2.55028915e+01, -1.86695374e+02,\n",
       "        -2.09454132e+02,  4.19630194e+00,  5.13508949e+01,\n",
       "         7.67049484e+01,  1.53291550e+02, -1.57724085e+01,\n",
       "         1.37503357e+02,  1.01375107e+02,  5.18212547e+01,\n",
       "         5.67843666e+01],\n",
       "       [-3.41802597e+01,  1.01781570e+02,  9.59276352e+01,\n",
       "         1.26400780e+02, -2.88540478e+01, -1.41332748e+02,\n",
       "        -1.09651588e+02, -8.22688065e+01, -1.20184616e+02,\n",
       "        -1.25382523e+02, -8.04758759e+01, -1.25382523e+02,\n",
       "        -1.20184616e+02, -8.22688065e+01, -9.94991913e+01,\n",
       "        -1.04089645e+02,  1.22722663e-01,  9.23067322e+01,\n",
       "         1.04388435e+02,  1.51203842e+02, -4.29573746e+01,\n",
       "         2.58570312e+02,  1.26849747e+02,  4.13706169e+01,\n",
       "         6.30515633e+01],\n",
       "       [-1.11082222e+02,  3.03898048e+01, -5.24693451e+01,\n",
       "        -2.30031281e+01, -1.55363968e+02, -4.12267548e+02,\n",
       "        -2.74289490e+02, -8.60564117e+01, -2.51776825e+02,\n",
       "        -2.52794312e+02, -9.65450439e+01, -2.52794312e+02,\n",
       "        -2.51776825e+02, -8.60564117e+01, -2.52561707e+02,\n",
       "        -3.78611755e+02, -9.36768112e+01,  9.31287613e+01,\n",
       "        -4.93243065e+01, -9.20607681e+01, -8.41514111e+00,\n",
       "         2.60104584e+02,  5.21609955e+01,  3.93547935e+01,\n",
       "         1.66690750e+02],\n",
       "       [ 1.34186239e+01,  1.76136963e+02,  2.36792114e+02,\n",
       "         3.08596344e+02,  2.77139816e+01, -1.38867889e+02,\n",
       "        -7.23698807e+01, -6.21188812e+01, -8.83300476e+01,\n",
       "        -9.74438477e+01, -6.01728668e+01, -9.74438477e+01,\n",
       "        -8.83300476e+01, -6.21188812e+01, -6.48987961e+01,\n",
       "        -8.90636063e+01,  7.98253708e+01,  2.61980255e+02,\n",
       "         1.96402252e+02,  1.94839828e+02, -2.91775169e+01,\n",
       "         3.45563812e+02,  1.96279922e+02,  1.37662170e+02,\n",
       "         1.31858047e+02],\n",
       "       [-1.83492146e+01,  9.26209259e+01,  1.37842575e+02,\n",
       "         1.69162537e+02,  8.99667835e+00, -1.73602600e+02,\n",
       "        -1.51378342e+02, -4.89596748e+01, -1.59155289e+02,\n",
       "        -1.65768341e+02, -4.53528862e+01, -1.65768341e+02,\n",
       "        -1.59155289e+02, -4.89596748e+01, -1.42774399e+02,\n",
       "        -1.33195892e+02,  5.10164108e+01,  9.92778549e+01,\n",
       "         8.46540451e+01,  1.20313560e+02, -9.55340500e+01,\n",
       "         1.54979660e+02,  1.21715820e+02,  5.06204796e+01,\n",
       "         4.97362747e+01],\n",
       "       [-1.32601089e+02, -2.83870506e+01, -6.52298203e+01,\n",
       "        -5.27048187e+01, -1.51636551e+02, -4.39321747e+02,\n",
       "        -2.94904388e+02, -5.97630577e+01, -2.72415894e+02,\n",
       "        -2.72224030e+02, -7.26923523e+01, -2.72224030e+02,\n",
       "        -2.72415894e+02, -5.97630692e+01, -2.72250702e+02,\n",
       "        -3.99491547e+02, -8.45443573e+01,  9.35509109e+01,\n",
       "        -6.28044281e+01, -9.55923538e+01,  1.93577957e+01,\n",
       "         2.45220795e+02,  5.08734131e+01,  2.92363091e+01,\n",
       "         1.63989105e+02],\n",
       "       [ 6.91557465e+01, -7.75707722e+00,  2.03064453e+02,\n",
       "         3.89688568e+01,  6.61638870e+01,  1.70689346e+02,\n",
       "         5.30642090e+01, -4.52142029e+01,  9.85995789e+01,\n",
       "         9.04224091e+01, -4.21729965e+01,  9.04224091e+01,\n",
       "         9.85995789e+01, -4.52142105e+01,  4.06072273e+01,\n",
       "         2.47382370e+02,  1.23985901e+02,  4.43443184e+01,\n",
       "         1.72711823e+02,  2.40278519e+02,  5.42948418e+01,\n",
       "         1.03681747e+02,  6.24854622e+01,  3.50694237e+01,\n",
       "         9.97391357e+01],\n",
       "       [-1.94267349e+02, -9.33194885e+01, -8.69994965e+01,\n",
       "        -7.40991135e+01,  1.42685404e+01, -2.60582245e+02,\n",
       "        -2.33354507e+02,  1.52231323e+02, -2.27652618e+02,\n",
       "        -2.24569138e+02,  1.59670258e+02, -2.24569138e+02,\n",
       "        -2.27652618e+02,  1.52231323e+02, -2.19920303e+02,\n",
       "        -2.53092010e+02,  3.14940853e+01, -7.38941040e+01,\n",
       "         5.66454620e+01,  1.18396759e+02, -4.92256498e+00,\n",
       "         1.44501602e+02,  3.57148056e+01, -1.86855354e+01,\n",
       "        -6.31158371e+01],\n",
       "       [-4.88056641e+01,  1.27446671e+02,  8.50131836e+01,\n",
       "         1.64195267e+02,  1.82686081e+01, -1.25264709e+02,\n",
       "        -6.79895096e+01,  2.99845352e+01, -6.03640709e+01,\n",
       "        -6.35715599e+01,  2.88896904e+01, -6.35715599e+01,\n",
       "        -6.03640709e+01,  2.99845352e+01, -5.55064354e+01,\n",
       "        -1.00666046e+02,  5.07632561e+01,  2.17748779e+02,\n",
       "         9.61298676e+01,  1.80651260e+02, -3.51030121e+01,\n",
       "         2.17405273e+02,  1.93726181e+02,  1.27026718e+02,\n",
       "         5.93812599e+01]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mdet_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-5.4560e+01,  1.0016e+02,  1.0596e+02, -2.3179e+01,  1.0314e+02,\n",
       "          1.1376e+02,  4.2291e+01,  1.1896e+02,  5.5046e+01,  5.0743e+01,\n",
       "          1.2211e+02,  5.0743e+01,  5.5046e+01,  1.1896e+02,  3.9664e+01,\n",
       "          1.5812e+02,  1.5471e+02, -8.9072e+00,  1.7950e+02,  1.2768e+02,\n",
       "          2.7970e+00,  7.1505e+01,  1.0331e+02,  7.6419e+01,  4.5112e+01],\n",
       "        [-1.4175e+02,  6.9503e+01,  1.0256e+02,  7.8622e+01,  3.3251e+01,\n",
       "         -1.3056e+02, -1.0908e+02,  3.3809e+01, -8.5626e+01, -8.7258e+01,\n",
       "          3.8418e+01, -8.7258e+01, -8.5626e+01,  3.3809e+01, -8.8714e+01,\n",
       "         -9.8440e+01,  4.1398e+01,  2.8889e+01,  5.9545e+01,  1.1578e+02,\n",
       "          8.7794e+01,  2.0508e+02,  6.8253e+01,  7.9645e+01,  8.6628e+01],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [-1.8349e+01,  9.2621e+01,  1.3784e+02,  1.6916e+02,  8.9967e+00,\n",
       "         -1.7360e+02, -1.5138e+02, -4.8960e+01, -1.5916e+02, -1.6577e+02,\n",
       "         -4.5353e+01, -1.6577e+02, -1.5916e+02, -4.8960e+01, -1.4277e+02,\n",
       "         -1.3320e+02,  5.1016e+01,  9.9278e+01,  8.4654e+01,  1.2031e+02,\n",
       "         -9.5534e+01,  1.5498e+02,  1.2172e+02,  5.0620e+01,  4.9736e+01],\n",
       "        [-5.0592e+01, -1.1114e+02, -2.4645e+01, -2.0936e+02, -1.4528e+02,\n",
       "         -1.5217e+01, -6.7821e+01, -2.8649e+02, -3.2025e+01, -3.9599e+01,\n",
       "         -2.8217e+02, -3.9599e+01, -3.2025e+01, -2.8649e+02, -6.1862e+01,\n",
       "          5.8680e+01, -1.2127e+02, -8.9990e+01, -4.7383e+01,  5.6195e+01,\n",
       "         -1.9670e+01,  5.3916e+01, -2.1905e+01, -2.3979e+01,  8.4365e+01],\n",
       "        [-9.0737e+01, -8.2141e+00,  1.8435e+01,  4.8170e+01, -4.1254e+01,\n",
       "         -2.2802e+02, -1.9034e+02, -2.5503e+01, -1.9098e+02, -1.9185e+02,\n",
       "         -2.4767e+01, -1.9185e+02, -1.9098e+02, -2.5503e+01, -1.8670e+02,\n",
       "         -2.0945e+02,  4.1963e+00,  5.1351e+01,  7.6705e+01,  1.5329e+02,\n",
       "         -1.5772e+01,  1.3750e+02,  1.0138e+02,  5.1821e+01,  5.6784e+01],\n",
       "        [-1.9427e+02, -9.3319e+01, -8.6999e+01, -7.4099e+01,  1.4269e+01,\n",
       "         -2.6058e+02, -2.3335e+02,  1.5223e+02, -2.2765e+02, -2.2457e+02,\n",
       "          1.5967e+02, -2.2457e+02, -2.2765e+02,  1.5223e+02, -2.1992e+02,\n",
       "         -2.5309e+02,  3.1494e+01, -7.3894e+01,  5.6645e+01,  1.1840e+02,\n",
       "         -4.9226e+00,  1.4450e+02,  3.5715e+01, -1.8686e+01, -6.3116e+01],\n",
       "        [-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-3.4180e+01,  1.0178e+02,  9.5928e+01,  1.2640e+02, -2.8854e+01,\n",
       "         -1.4133e+02, -1.0965e+02, -8.2269e+01, -1.2018e+02, -1.2538e+02,\n",
       "         -8.0476e+01, -1.2538e+02, -1.2018e+02, -8.2269e+01, -9.9499e+01,\n",
       "         -1.0409e+02,  1.2272e-01,  9.2307e+01,  1.0439e+02,  1.5120e+02,\n",
       "         -4.2957e+01,  2.5857e+02,  1.2685e+02,  4.1371e+01,  6.3052e+01],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-8.9948e+01,  7.5621e+00,  6.8850e+00,  1.6208e+00, -7.2264e+01,\n",
       "          3.4406e+01,  5.9855e+01, -1.1907e+02,  1.0299e+02,  9.9488e+01,\n",
       "         -1.1880e+02,  9.9488e+01,  1.0299e+02, -1.1907e+02,  6.8117e+01,\n",
       "          1.0220e+02, -2.6015e+01,  1.5597e+02,  2.9095e+01,  1.2512e+02,\n",
       "         -2.9149e+01,  1.3111e+02,  8.7560e+01, -1.8449e+00,  1.6903e+01],\n",
       "        [-1.1923e+02, -5.9629e+01, -3.5477e+01, -6.2287e+01, -6.7956e+01,\n",
       "         -1.3300e+02, -5.6052e+01, -1.0629e+01, -5.7595e+01, -5.8856e+01,\n",
       "         -2.3312e+01, -5.8856e+01, -5.7595e+01, -1.0629e+01, -4.9471e+01,\n",
       "         -9.8253e+01, -2.9414e+01,  5.3016e+01,  1.4275e+02,  2.0140e+02,\n",
       "          2.5368e+00,  1.6847e+02,  1.6342e+02,  1.0452e+02,  2.9112e+01],\n",
       "        [-1.0361e+02,  4.0324e+00, -5.5896e+01, -3.1929e+01, -1.6995e+02,\n",
       "         -3.7697e+02, -2.4763e+02, -1.1928e+02, -2.2508e+02, -2.2647e+02,\n",
       "         -1.3082e+02, -2.2647e+02, -2.2508e+02, -1.1928e+02, -2.2862e+02,\n",
       "         -3.3967e+02, -1.1422e+02,  6.9952e+01, -5.5981e+01, -9.1695e+01,\n",
       "          7.8900e+00,  2.4858e+02,  3.1941e+01,  1.8945e+01,  1.6882e+02],\n",
       "        [-1.4226e+02, -5.4908e+01, -6.8499e+01, -6.4735e+01, -1.6340e+02,\n",
       "         -4.4183e+02, -2.9454e+02, -6.9716e+01, -2.6782e+02, -2.6787e+02,\n",
       "         -8.3955e+01, -2.6787e+02, -2.6782e+02, -6.9716e+01, -2.7137e+02,\n",
       "         -3.9315e+02, -9.5103e+01,  7.7355e+01, -7.1096e+01, -8.9529e+01,\n",
       "          2.4529e+01,  2.5405e+02,  4.4291e+01,  1.7562e+01,  1.7040e+02],\n",
       "        [-1.1108e+02,  3.0390e+01, -5.2469e+01, -2.3003e+01, -1.5536e+02,\n",
       "         -4.1227e+02, -2.7429e+02, -8.6056e+01, -2.5178e+02, -2.5279e+02,\n",
       "         -9.6545e+01, -2.5279e+02, -2.5178e+02, -8.6056e+01, -2.5256e+02,\n",
       "         -3.7861e+02, -9.3677e+01,  9.3129e+01, -4.9324e+01, -9.2061e+01,\n",
       "         -8.4151e+00,  2.6010e+02,  5.2161e+01,  3.9355e+01,  1.6669e+02],\n",
       "        [-7.8885e+01,  7.2556e+01,  1.0373e+02,  1.1950e+02,  4.8719e+01,\n",
       "         -1.8229e+02, -1.6753e+02,  3.0221e+01, -1.5645e+02, -1.5841e+02,\n",
       "          3.8944e+01, -1.5841e+02, -1.5645e+02,  3.0221e+01, -1.6239e+02,\n",
       "         -1.4762e+02,  7.8007e+01,  1.0311e+02,  1.3401e+02,  2.9438e+02,\n",
       "          1.1596e+00,  2.4554e+02,  1.0706e+02,  4.1670e+01,  5.8804e+01],\n",
       "        [-8.5577e+01,  7.7856e+01,  7.7830e+01,  9.6812e+01,  1.1632e+01,\n",
       "         -1.3842e+02, -7.1884e+01,  4.3793e+01, -6.8222e+01, -7.0802e+01,\n",
       "          3.6130e+01, -7.0802e+01, -6.8222e+01,  4.3793e+01, -5.6561e+01,\n",
       "         -1.1638e+02,  3.1914e+01,  9.5220e+01,  9.6312e+01,  1.5614e+02,\n",
       "          1.2577e+01,  2.0649e+02,  1.5214e+02,  1.2910e+02,  7.2711e+01],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-1.3260e+02, -2.8387e+01, -6.5230e+01, -5.2705e+01, -1.5164e+02,\n",
       "         -4.3932e+02, -2.9490e+02, -5.9763e+01, -2.7242e+02, -2.7222e+02,\n",
       "         -7.2692e+01, -2.7222e+02, -2.7242e+02, -5.9763e+01, -2.7225e+02,\n",
       "         -3.9949e+02, -8.4544e+01,  9.3551e+01, -6.2804e+01, -9.5592e+01,\n",
       "          1.9358e+01,  2.4522e+02,  5.0873e+01,  2.9236e+01,  1.6399e+02],\n",
       "        [-1.0237e+02,  4.4220e+01,  8.6363e+01,  1.0266e+02,  1.9387e+01,\n",
       "         -1.3108e+02, -7.1542e+01,  5.0727e+01, -6.4031e+01, -6.5911e+01,\n",
       "          4.5624e+01, -6.5911e+01, -6.4031e+01,  5.0727e+01, -6.0926e+01,\n",
       "         -1.0589e+02,  4.6251e+01,  1.0855e+02,  1.2764e+02,  2.0013e+02,\n",
       "          2.7195e+01,  2.0535e+02,  1.6045e+02,  1.2593e+02,  5.8524e+01],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [ 6.9156e+01, -7.7571e+00,  2.0306e+02,  3.8969e+01,  6.6164e+01,\n",
       "          1.7069e+02,  5.3064e+01, -4.5214e+01,  9.8600e+01,  9.0422e+01,\n",
       "         -4.2173e+01,  9.0422e+01,  9.8600e+01, -4.5214e+01,  4.0607e+01,\n",
       "          2.4738e+02,  1.2399e+02,  4.4344e+01,  1.7271e+02,  2.4028e+02,\n",
       "          5.4295e+01,  1.0368e+02,  6.2485e+01,  3.5069e+01,  9.9739e+01],\n",
       "        [-4.8806e+01,  1.2745e+02,  8.5013e+01,  1.6420e+02,  1.8269e+01,\n",
       "         -1.2526e+02, -6.7990e+01,  2.9985e+01, -6.0364e+01, -6.3572e+01,\n",
       "          2.8890e+01, -6.3572e+01, -6.0364e+01,  2.9985e+01, -5.5506e+01,\n",
       "         -1.0067e+02,  5.0763e+01,  2.1775e+02,  9.6130e+01,  1.8065e+02,\n",
       "         -3.5103e+01,  2.1741e+02,  1.9373e+02,  1.2703e+02,  5.9381e+01],\n",
       "        [ 1.3419e+01,  1.7614e+02,  2.3679e+02,  3.0860e+02,  2.7714e+01,\n",
       "         -1.3887e+02, -7.2370e+01, -6.2119e+01, -8.8330e+01, -9.7444e+01,\n",
       "         -6.0173e+01, -9.7444e+01, -8.8330e+01, -6.2119e+01, -6.4899e+01,\n",
       "         -8.9064e+01,  7.9825e+01,  2.6198e+02,  1.9640e+02,  1.9484e+02,\n",
       "         -2.9178e+01,  3.4556e+02,  1.9628e+02,  1.3766e+02,  1.3186e+02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[torch.randperm(M.size()[0])].detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 1.0542e-06, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 1.5957e+05, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 4.0323e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 6.0959e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 2.1699e+05, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 6.0959e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5044e+00, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.4005e+03, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1949e-01],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.3267e-03, 3.9987e-02, 1.7760e+05, 3.9973e+05, 3.3471e+03,\n",
       "         4.0000e+05, 3.9179e-02, 4.0000e+05, 4.0000e+05, 1.8434e-07, 4.0000e+05,\n",
       "         4.0000e+05, 3.9179e-02, 4.0000e+05, 1.0009e+00, 4.0000e-02, 9.9163e-01,\n",
       "         4.0000e+05, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e+05, 2.5068e-07, 3.9987e-02, 1.6759e+00, 2.7162e+02, 3.9665e+05,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0405e-07, 1.2991e+02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-01, 4.0000e-02, 5.2211e-02, 1.7043e+01,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8538e-02, 2.5068e-07, 3.9646e+05, 5.2613e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-02, 2.4148e-08, 4.0000e-02, 2.9952e-01, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 2.3442e+04, 3.5173e-08, 1.7043e-06,\n",
       "         1.4761e-05],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 2.2240e+05, 9.4280e-01, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e+05, 4.0000e-02, 4.0000e-02, 1.8434e+00, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e+05, 4.0000e-02, 1.0009e-07, 3.9987e+05, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 5.9244e-08, 1.7043e-06,\n",
       "         2.1951e-08]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.T / attn.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-16-bfc19aa26183>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-bfc19aa26183>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (attn / attn.sum(axis = 0)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "(attn / attn.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3970e-06, 3.9892e-01, 2.5008e-06, 2.5000e-06, 2.5000e-06, 2.5000e-06,\n",
       "        2.5000e-06, 2.5524e-06, 2.5000e-06, 2.5000e-06, 5.4248e-01, 2.5000e-06,\n",
       "        2.5000e-06, 2.5524e-06, 2.5000e-06, 9.9907e-01, 2.5000e-06, 1.0084e+00,\n",
       "        2.5000e-06, 1.0453e+01, 4.1411e+00, 2.5000e-06, 2.8431e+00, 5.8674e-02,\n",
       "        4.5557e+00], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): None\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.ModuleList([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
