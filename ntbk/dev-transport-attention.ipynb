{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"molgen\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"iclr19-graph2graph/props\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from otgnn.models import GCN, fused_gw_torch\n",
    "# from molgen.dataloading.MolGraphBatchPreprocessor import MolGraph\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "from otgnn.graph import SYMBOLS, FORMAL_CHARGES, BOND_TYPES\n",
    "\n",
    "\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, load_checkpoint, initialize_models\n",
    "from mol_opt.mol_opt import MolOpt\n",
    "from mol_opt.decoder_mol_opt import MolOptDecoder\n",
    "from mol_opt.ot_utils import encode_target\n",
    "from mol_opt.ot_utils import FGW \n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "\n",
    "from molgen.dataloading.feat2smiles import feat2smiles\n",
    "from molgen.dataloading.mol_drawer import MolDrawer\n",
    "from molgen.metrics.Penalty import Penalty\n",
    "from molgen.metrics.mol_metrics import MolMetrics\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import time\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from molgen.metrics.Penalty import Penalty as PenaltyNew\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/octav/data-volume/tum-thesis/output_dev3_saves/deepsets-chembl1/\n",
      "mol_opt/logs_dev3_saves/deepsets-chembl1/\n"
     ]
    }
   ],
   "source": [
    "model_type = \"deepsets\"\n",
    "sys.argv = [\"\", \"-model_type\", model_type, \"-one_batch_train\"]\n",
    "args = get_args()\n",
    "outdir_suffix = \"dev3_saves\"\n",
    "args.init_model = \"{}-chembl1\".format(model_type)\n",
    "args.output_dir = \"/run/media/octav/data-volume/tum-thesis/output_{}/{}/\".format(outdir_suffix, args.init_model)\n",
    "args.tb_logs_dir = \"mol_opt/logs_{}/{}/\".format(outdir_suffix, args.init_model)\n",
    "\n",
    "print (args.output_dir)\n",
    "print (args.tb_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/octav/data-volume/tum-thesis/output_dev3_saves/deepsets-chembl1/model_deepsets-chembl1_11\n",
      "MolOpt(\n",
      "  (GCN): GCN(\n",
      "    (W_message_i): Linear(in_features=100, out_features=400, bias=False)\n",
      "    (W_message_h): Linear(in_features=400, out_features=400, bias=False)\n",
      "    (W_message_o): Linear(in_features=493, out_features=150, bias=True)\n",
      "    (W_mol_h): Linear(in_features=150, out_features=100, bias=True)\n",
      "    (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
      "    (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
      "    (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (opt0): Linear(in_features=300, out_features=400, bias=True)\n",
      "  (opt1): Linear(in_features=400, out_features=150, bias=True)\n",
      ")\n",
      "MolOptDecoder(\n",
      "  (fc1_SYMBOLS): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (fc2_SYMBOLS): Linear(in_features=150, out_features=64, bias=True)\n",
      "  (fc1_CHARGES): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (fc2_CHARGES): Linear(in_features=150, out_features=5, bias=True)\n",
      "  (fc1_BONDS): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (fc2_BONDS): Linear(in_features=300, out_features=5, bias=True)\n",
      ")\n",
      "deepsets\n",
      "Penalty params: tau=0.05623 conn_l=0.00032 val_l=0.00030 euler_l=0.00034 epoch=11 mode=[0 0 0] conn=True val=True euler=True\n"
     ]
    }
   ],
   "source": [
    "model = args.init_model\n",
    "model_iter = 11 \n",
    "\n",
    "model_name = \"model_{}_{}\".format(model, model_iter)\n",
    "print(args.output_dir + model_name)\n",
    "\n",
    "molopt, molopt_decoder, _, pen, recpen, _, _, config, _ = load_checkpoint(args.output_dir + model_name ,init_fc = initialize_models, device = 'cpu')\n",
    "\n",
    "metrics = MolMetrics(SYMBOLS, FORMAL_CHARGES, BOND_TYPES, False, device = 'cpu')\n",
    "fgw_loss = FGW(alpha = 0.5)\n",
    "# pen = PenaltyNew(config, model_iter)\n",
    "\n",
    "molopt_module_list = torch.nn.ModuleList([molopt, molopt_decoder])\n",
    "\n",
    "# molopt = MolOpt(args)\n",
    "# molopt_decoder = MolOptDecoder(args)\n",
    "print (molopt)\n",
    "print (molopt_decoder)\n",
    "print(molopt.args.model_type)\n",
    "pen.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train_pairs\", args.batch_size, True)\n",
    "datatype = \"val_split\"\n",
    "train_data_loader = get_loader(\"molgen/data/chembl50\", datatype, 50, same_number_atoms = True)\n",
    "\n",
    "for i in train_data_loader:\n",
    "#     X = (MolGraph(i[0]))\n",
    "#     Y = (MolGraph(i[1]))\n",
    "    X = MolGraph(i)\n",
    "    Y = X\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:398: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23088953018188477\n",
      "(tensor(3355.8071, grad_fn=<DivBackward0>), tensor(232.7259, grad_fn=<DivBackward0>), tensor(453.4835, grad_fn=<DivBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_molecular_validity': 2.0,\n",
       "  'batch_correctness': 2.0,\n",
       "  'batch_symbol_accuracy': 100.0,\n",
       "  'batch_molecular_disconnected_validity': 80.0,\n",
       "  'batch_connected_components': 10.6,\n",
       "  'batch_invalid_valency_nodes': 21.747765640516384,\n",
       "  'batch_nodes_0degree': 195,\n",
       "  'batch_nodes_7plus_degree': 1,\n",
       "  'invalid_euler_toofew': 90.0,\n",
       "  'invalid_euler_toomany': 0.0},\n",
       " {'avg_euler_error': (-9.92, 50, 34.193599999999996),\n",
       "  'batch_node_degree': (1.6583912611717972, 1007, 1.297404760519462)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_encoding, x_embedding = molopt.forward(X)\n",
    "yhat_logits = molopt_decoder.forward(x_embedding, X, Y)\n",
    "yhat_labels = molopt_decoder.discretize_argmax(*yhat_logits)\n",
    "# yhat_labels = molopt_decoder.discretize_gumbel(*yhat_logits, tau = pen.tau)\n",
    "pred_pack = (yhat_labels, yhat_logits, Y.scope), Y \n",
    "\n",
    "target = Y.get_graph_outputs()\n",
    "symbols_labels, charges_labels, bonds_labels = yhat_labels\n",
    "symbols_logits, charges_logits, bonds_logits = yhat_logits\n",
    "\n",
    "pen.mirror = \"\"\n",
    "\n",
    "pen.tau = 0.05\n",
    "fgw_loss_item = fgw_loss(*pred_pack, tau = 1)\n",
    "print (fgw_loss_item.item()/args.batch_size)\n",
    "pen_loss = pen(*pred_pack, model_iter)\n",
    "print (pen_loss)\n",
    "metrics.measure_batch(pred_pack[0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000e+03, -2.0000e+03, -2.0000e+03, -2.0000e+03,  0.0000e+00],\n",
       "        [-1.8230e+00, -6.4977e+00, -1.6555e+01, -6.4244e+01, -1.7798e-01],\n",
       "        [-1.6989e+00, -5.8483e+00, -1.6199e+01, -6.8163e+01, -2.0552e-01],\n",
       "        ...,\n",
       "        [-3.1502e+00, -1.2478e+01, -2.4051e+01, -6.2364e+01, -4.3791e-02],\n",
       "        [-1.7367e+00, -1.5492e+01, -2.7248e+01, -6.4086e+01, -1.9370e-01],\n",
       "        [-2.0000e+03, -2.0000e+03, -2.0000e+03, -2.0000e+03,  0.0000e+00]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LogSoftmax(dim=1)(bonds_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1000.0000, -1000.0000, -1000.0000, -1000.0000,  1000.0000],\n",
       "        [    2.6185,    -2.0562,   -12.1131,   -59.8020,     4.2635],\n",
       "        [    2.9847,    -1.1648,   -11.5157,   -63.4792,     4.4780],\n",
       "        ...,\n",
       "        [    3.8900,    -5.4378,   -17.0104,   -55.3233,     6.9964],\n",
       "        [    5.5758,    -8.1793,   -19.9355,   -56.7733,     7.1188],\n",
       "        [-1000.0000, -1000.0000, -1000.0000, -1000.0000,  1000.0000]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonds_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "M, pred_bonds_nll, target_bonds_rescaled = fgw_loss(*pred_pack, tau = 1)\n",
    "num_atoms = M.shape[0]\n",
    "alpha = 0.55\n",
    "device = pred_bonds_nll.device\n",
    "\n",
    "M=M\n",
    "C1= target_bonds_rescaled\n",
    "C2= -1 * pred_bonds_nll\n",
    "p1=np.ones([num_atoms]) / float(num_atoms)\n",
    "p2=np.ones([num_atoms]) / float(num_atoms)\n",
    "dist_type='dot'\n",
    "nce_reg = True\n",
    "alpha=alpha\n",
    "device=device\n",
    "\n",
    "C1_detach = C1.detach().cpu().numpy()\n",
    "C2_detach = C2.detach().cpu().numpy()\n",
    "C1_m = max(1, C1_detach.max())\n",
    "C2_m = max(1, C2_detach.max())\n",
    "C1_detach /= C1_m\n",
    "C2_detach /= C2_m\n",
    "M_detach = M.detach().cpu().numpy()\n",
    "\n",
    "from otgnn.models import np_fused_gw\n",
    "\n",
    "ot_mat = np_fused_gw(M=M_detach, C1 = C1_detach, C2 = C2_detach,\n",
    "                     p1 = p1, p2 = p2, dist_type=dist_type, alpha=alpha)\n",
    "print (ot_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1007, 150]) torch.Size([1007, 150])\n"
     ]
    }
   ],
   "source": [
    "yhat_embedding = molopt.GCN(Y)[0]\n",
    "print (x_embedding.shape, yhat_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05882353, 0.05882353, 0.05882353, 0.05882353, 0.05882353,\n",
       "       0.05882353, 0.05882353, 0.05882353, 0.05882353, 0.05882353,\n",
       "       0.05882353, 0.05882353, 0.05882353, 0.05882353, 0.05882353,\n",
       "       0.05882353, 0.05882353])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_mat.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05882353, 0.05882353, 0.05882353, 0.05882353, 0.05882353,\n",
       "       0.05882353, 0.05882353, 0.05882353, 0.05882353, 0.05882353,\n",
       "       0.05882353, 0.05882353, 0.05882353, 0.05882353, 0.05882353,\n",
       "       0.05882353, 0.05882353])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_mat.sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot_mat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058823529411764705"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.8011, 0.7918, 0.7918, 1.1442, 1.1484, 1.1484, 0.7918, 0.7918, 0.7918,\n",
      "        0.8984, 1.1419, 0.8984, 0.7918, 1.1498, 0.8984, 0.8984, 2.1213],\n",
      "       grad_fn=<SumBackward1>)\n",
      "1 23\n",
      "torch.Size([23, 23])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1522, 1.1522, 1.1522, 1.6522, 1.1522, 0.7522, 0.7522, 0.7522, 0.7522,\n",
      "        1.1522, 1.1522, 1.1522, 1.1522, 0.9855, 1.6522, 0.7522, 0.7522, 0.7522,\n",
      "        0.7522, 0.7522, 0.7522, 0.9855, 0.9855], grad_fn=<SumBackward1>)\n",
      "2 28\n",
      "torch.Size([28, 28])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.7982, 1.0484, 0.7982, 0.7982, 1.5484, 1.5484, 1.0484, 0.8820, 0.8820,\n",
      "        3.1978, 0.7978, 0.7978, 0.8816, 1.0477, 0.7984, 0.7978, 0.7150, 0.7150,\n",
      "        0.7150, 0.7150, 0.7150, 0.7150, 1.0484, 1.0484, 1.0484, 1.0484, 1.0477,\n",
      "        0.7982], grad_fn=<SumBackward1>)\n",
      "3 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0251, 1.6918, 1.0251, 1.0261, 1.8889, 0.9418, 0.9542, 0.9418, 1.6918,\n",
      "        0.8925, 0.8029, 0.8029, 0.8029, 1.0252, 0.8925, 0.9418, 0.8029, 0.8029,\n",
      "        0.8925, 0.8925, 0.8029, 0.8029, 1.0251, 1.0252, 0.8029, 0.8029],\n",
      "       grad_fn=<SumBackward1>)\n",
      "4 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.2805, 0.7959, 0.7959, 0.7959, 1.2805, 1.0293, 0.7959, 1.0293, 0.7959,\n",
      "        0.7959, 1.0293, 1.6959, 1.6959, 0.7959, 0.7959, 0.7959, 0.7959],\n",
      "       grad_fn=<SumBackward1>)\n",
      "5 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1676, 0.7439, 1.1519, 1.6484, 0.7439, 0.7480, 1.1519, 0.7439, 0.7439,\n",
      "        2.1582, 0.7439, 0.7459, 0.7439, 0.7439, 1.1571, 0.8196, 0.8196, 0.8196,\n",
      "        0.8196, 0.8196, 0.8196, 1.1529, 1.6529, 1.6529, 0.7439, 0.7439],\n",
      "       grad_fn=<SumBackward1>)\n",
      "6 15\n",
      "torch.Size([15, 15])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0332, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 0.7000, 1.5333, 1.0347,\n",
      "        1.0321, 1.0321, 1.0347, 1.5333, 1.0332, 1.5333],\n",
      "       grad_fn=<SumBackward1>)\n",
      "7 11\n",
      "torch.Size([11, 11])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9486, 0.9486, 1.1929, 0.9486, 0.9486, 1.0557, 0.9486, 0.9486, 0.9486,\n",
      "        1.0557, 1.0557], grad_fn=<SumBackward1>)\n",
      "8 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0294, 0.7294, 1.0294, 0.7294, 1.6755, 0.9289, 0.7294, 1.0474, 1.5294,\n",
      "        1.0294, 1.0294, 1.0294, 0.9289, 1.0294, 0.7294, 1.0663, 0.7294],\n",
      "       grad_fn=<SumBackward1>)\n",
      "9 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.5046, 0.3710, 1.1709, 4.4524, 1.1703, 0.3715, 0.3710, 0.3710, 1.1709,\n",
      "        1.1709, 0.5046, 0.3710], grad_fn=<SumBackward1>)\n",
      "10 18\n",
      "torch.Size([18, 18])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0292, 0.8685, 0.8685, 1.2753, 0.8685, 1.0284, 1.2771, 1.0292, 1.7778,\n",
      "        0.8685, 0.8685, 0.8685, 0.8685, 1.0292, 0.8685, 0.8685, 0.8686, 0.8685],\n",
      "       grad_fn=<SumBackward1>)\n",
      "11 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0200, 1.2615, 0.8523, 0.8523, 1.0125, 0.8523, 0.8546, 0.8523, 0.8523,\n",
      "        1.0122, 1.0329, 0.8523, 1.0281, 1.0125, 0.8523, 1.0080, 1.2615, 0.8523,\n",
      "        0.8523, 0.8523, 1.9731], grad_fn=<SumBackward1>)\n",
      "12 40\n",
      "torch.Size([40, 40])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.4127, 1.7000, 1.1129, 1.0813, 0.7909, 1.1373, 1.0807, 0.7909, 1.0502,\n",
      "        0.7909, 0.9491, 0.7909, 0.7909, 0.9500, 0.8667, 0.9500, 0.8667, 0.8667,\n",
      "        0.9495, 0.7909, 0.9500, 0.8667, 0.9500, 0.8667, 0.8667, 0.7909, 1.5684,\n",
      "        1.1301, 1.5827, 0.9491, 1.1185, 1.1159, 0.7909, 1.1272, 1.1222, 0.7909,\n",
      "        0.7909, 0.9491, 1.1633, 0.7909], grad_fn=<SumBackward1>)\n",
      "13 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9414, 0.9414, 0.9414, 0.9414, 0.9414, 0.9414, 0.9414, 1.1636, 1.1819,\n",
      "        1.1819, 0.9414, 0.9414], grad_fn=<SumBackward1>)\n",
      "14 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.7134, 0.7134, 0.7134, 1.1468, 0.7134, 0.7134, 0.7134, 0.7134, 0.7134,\n",
      "        2.2917, 1.1468, 0.7134, 0.8967, 1.2558, 0.8967, 0.7134, 0.7134, 1.6475,\n",
      "        1.6465, 0.7134, 0.8967, 0.8967, 2.5766, 0.7134, 0.7134, 0.7134],\n",
      "       grad_fn=<SumBackward1>)\n",
      "15 24\n",
      "torch.Size([24, 24])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1191, 1.4933, 1.4629, 1.4933, 1.6550, 0.6187, 0.6452, 0.6187, 1.4933,\n",
      "        1.4933, 0.6187, 0.6187, 0.6187, 1.4933, 1.4933, 1.8675, 0.6187, 0.6187,\n",
      "        0.6599, 0.6599, 0.6599, 0.6599, 0.6599, 0.6599],\n",
      "       grad_fn=<SumBackward1>)\n",
      "16 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.7346, 0.7335, 0.7335, 0.7335, 0.7507, 0.7336, 1.2840, 1.2383, 0.8093,\n",
      "        0.8093, 1.2383, 1.2840, 0.7335, 0.7336, 0.7335, 0.8093, 0.8093, 2.2744,\n",
      "        1.5115, 1.3124], grad_fn=<SumBackward1>)\n",
      "17 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.2907, 0.8740, 0.6955, 0.6955, 0.6955, 0.6955, 0.6955, 0.6955, 2.6125,\n",
      "        0.6955, 0.6955, 0.8740, 2.7882, 0.8741, 0.8741, 0.8741, 1.6240, 0.8740,\n",
      "        1.2907, 0.6955, 1.1240, 0.6955, 0.6955, 1.1240, 0.6955, 0.8740, 1.2907,\n",
      "        0.6955, 0.6955], grad_fn=<SumBackward1>)\n",
      "18 14\n",
      "torch.Size([14, 14])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.8639, 1.6350, 0.8639, 1.6386, 0.7858, 1.6350, 0.7858, 0.8917, 0.7858,\n",
      "        0.7858, 0.8146, 0.8639, 0.8639, 0.7858], grad_fn=<SumBackward1>)\n",
      "19 22\n",
      "torch.Size([22, 22])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.8005, 0.8006, 0.6336, 0.6674, 0.6336, 0.6675, 1.4670, 1.5373, 0.9862,\n",
      "        1.2284, 2.2050, 0.9453, 0.6675, 0.8007, 1.4669, 0.6336, 0.6336, 1.4670,\n",
      "        0.9902, 1.4670, 0.6336, 0.6675], grad_fn=<SumBackward1>)\n",
      "20 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.8500, 0.8501, 1.7388, 0.7639, 0.8500, 0.7639, 0.7639, 0.8500, 0.7639,\n",
      "        0.7639, 0.8500, 0.7639, 0.9833, 0.9833, 0.9833, 0.7639, 0.7639, 1.1435,\n",
      "        2.6635, 1.1435], grad_fn=<SumBackward1>)\n",
      "21 7\n",
      "torch.Size([7, 7])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.7143, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810],\n",
      "       grad_fn=<SumBackward1>)\n",
      "22 17\n",
      "torch.Size([17, 17])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.8692, 0.7549, 0.7549, 0.7549, 0.7549, 1.0883, 0.8692, 1.5883, 1.0523,\n",
      "        0.9216, 0.9216, 0.9216, 0.7549, 0.8692, 2.2811, 1.0883, 0.7549],\n",
      "       grad_fn=<SumBackward1>)\n",
      "23 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0333, 1.7000, 1.0333, 0.8667, 0.8667, 0.8667, 0.8667, 1.0333, 0.8667,\n",
      "        0.8667, 1.0333, 1.7000, 1.0333, 0.8667, 0.8667, 0.8667, 0.8667, 1.0333,\n",
      "        0.8667, 0.8667], grad_fn=<SumBackward1>)\n",
      "24 20\n",
      "torch.Size([20, 20])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0888, 1.0888, 1.1117, 1.6000, 0.7428, 0.7428, 0.7428, 0.7428, 0.8426,\n",
      "        0.7428, 0.7428, 1.6000, 0.8397, 1.1109, 0.7428, 1.6383, 1.0999, 0.8399,\n",
      "        0.8397, 1.0999], grad_fn=<SumBackward1>)\n",
      "25 30\n",
      "torch.Size([30, 30])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0291, 1.0290, 1.0290, 1.0290, 1.0290, 1.0424, 1.0290, 1.0290, 1.1957,\n",
      "        1.1450, 1.1957, 0.8207, 0.8208, 0.8207, 0.9457, 0.8207, 0.9457, 0.8956,\n",
      "        0.8956, 1.2768, 0.8956, 0.8956, 2.1145, 0.8956, 0.8207, 0.8207, 0.8207,\n",
      "        0.9457, 0.8207, 0.9457], grad_fn=<SumBackward1>)\n",
      "26 14\n",
      "torch.Size([14, 14])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([2.8312, 0.8333, 0.6668, 0.8333, 0.6668, 0.6668, 0.6668, 0.8333, 1.5001,\n",
      "        0.8340, 0.6668, 1.5001, 0.6668, 0.8340], grad_fn=<SumBackward1>)\n",
      "27 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1601, 0.8772, 0.8739, 0.8721, 0.8721, 0.8721, 0.8721, 0.8721, 0.8721,\n",
      "        0.8721, 1.8281, 0.8721, 0.8721, 0.8721, 1.1601, 1.3272, 1.3270, 1.8435,\n",
      "        0.8721, 0.8721, 0.8721, 0.8721, 0.8721, 0.8721, 0.8721, 0.8721, 1.1601,\n",
      "        0.8721, 0.8721], grad_fn=<SumBackward1>)\n",
      "28 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0420, 1.0420, 0.9483, 1.0949, 1.5897, 1.0897, 1.5897, 1.0897, 0.9483,\n",
      "        1.9778, 0.7579, 0.7673, 0.7579, 0.7595, 0.7618, 0.7595, 1.5897, 1.5897,\n",
      "        0.8298, 0.8317, 0.8332, 0.8298, 0.9680, 0.7579, 0.7595, 0.7579, 0.7595,\n",
      "        0.7579, 0.7595], grad_fn=<SumBackward1>)\n",
      "29 8\n",
      "torch.Size([8, 8])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.5854, 1.2520, 0.5854, 0.5854, 1.2520, 2.5692, 0.5854, 0.5854],\n",
      "       grad_fn=<SumBackward1>)\n",
      "30 7\n",
      "torch.Size([7, 7])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.1108, 0.9400, 0.9402, 1.0230, 1.0230, 0.9399, 1.0230],\n",
      "       grad_fn=<SumBackward1>)\n",
      "31 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.8914, 1.1557, 0.8914, 1.1557, 0.8914, 1.1371, 0.8914, 0.8914, 1.1557,\n",
      "        0.8914, 1.1557, 0.8914], grad_fn=<SumBackward1>)\n",
      "32 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9643, 0.9643, 0.8958, 0.8972, 0.8958, 0.8994, 0.8994, 1.0384, 1.0480,\n",
      "        0.8994, 1.0364, 0.8994, 0.9643, 0.9643, 0.9067, 0.8991, 1.0384, 1.0482,\n",
      "        2.0460, 0.8958, 0.8994], grad_fn=<SumBackward1>)\n",
      "33 7\n",
      "torch.Size([7, 7])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.7714, 0.7717, 0.7714, 0.7714, 1.5686, 1.5742, 0.7714],\n",
      "       grad_fn=<SumBackward1>)\n",
      "34 19\n",
      "torch.Size([19, 19])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.5609, 1.5689, 0.9133, 1.6762, 0.8717, 0.9198, 0.7821, 0.7821, 0.9133,\n",
      "        0.7842, 0.7217, 1.5788, 1.5968, 0.7217, 0.7217, 0.7217, 0.7217, 0.7217,\n",
      "        0.7217], grad_fn=<SumBackward1>)\n",
      "35 22\n",
      "torch.Size([22, 22])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.8362, 0.9697, 1.1381, 0.9697, 0.8362, 1.6339, 0.8362, 0.7612, 0.7612,\n",
      "        0.7612, 0.7612, 0.7612, 0.7612, 1.6375, 0.8362, 0.7612, 1.1378, 0.9697,\n",
      "        1.6364, 0.7612, 1.6364, 0.8362], grad_fn=<SumBackward1>)\n",
      "36 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.1670, 0.8337, 1.1670, 1.0004, 0.8337, 1.0004, 0.9170, 0.9170, 0.8337,\n",
      "        1.0004, 0.8337, 0.8337, 0.9170, 0.9170, 0.8671, 0.8671, 1.8590, 1.6670,\n",
      "        0.8337, 0.8671, 0.8671], grad_fn=<SumBackward1>)\n",
      "37 5\n",
      "torch.Size([5, 5])\n",
      "tensor([1., 1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "tensor([1.6000, 0.8500, 0.8500, 0.8500, 0.8500], grad_fn=<SumBackward1>)\n",
      "38 42\n",
      "torch.Size([42, 42])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.7737, 1.1448, 0.8947, 0.6973, 4.6067, 1.1447, 0.8113, 0.8113, 0.8947,\n",
      "        0.8446, 2.6446, 0.8113, 0.8947, 1.6447, 0.8113, 0.6973, 0.6973, 0.6973,\n",
      "        0.6973, 0.6973, 0.6973, 1.1447, 0.8446, 0.6973, 0.6973, 0.6973, 0.6973,\n",
      "        0.6973, 0.6973, 0.6973, 0.6973, 0.6973, 0.6973, 1.6447, 1.1447, 0.8446,\n",
      "        0.8446, 0.8113, 0.6973, 0.6973, 0.8446, 0.8947],\n",
      "       grad_fn=<SumBackward1>)\n",
      "39 9\n",
      "torch.Size([9, 9])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.9007, 1.7944, 0.9007, 0.9007, 0.9007, 0.9007, 0.9007, 0.9007, 0.9007],\n",
      "       grad_fn=<SumBackward1>)\n",
      "40 28\n",
      "torch.Size([28, 28])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.9926, 0.9450, 0.7621, 0.7621, 0.7621, 0.7621, 0.9907, 1.1728, 1.1728,\n",
      "        0.8394, 0.8394, 1.1728, 0.8394, 0.7621, 0.7621, 0.7621, 1.7828, 0.7621,\n",
      "        0.7621, 0.7621, 0.7621, 1.6728, 1.1728, 0.8853, 1.6753, 1.6728, 0.9511,\n",
      "        0.8394], grad_fn=<SumBackward1>)\n",
      "41 21\n",
      "torch.Size([21, 21])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0578, 0.8912, 0.8758, 0.8912, 1.5853, 0.8913, 0.8912, 0.8912, 0.8078,\n",
      "        0.8912, 0.8078, 0.8078, 1.5578, 0.8758, 1.5764, 1.1759, 0.8078, 0.8758,\n",
      "        0.8912, 0.8912, 1.0588], grad_fn=<SumBackward1>)\n",
      "42 24\n",
      "torch.Size([24, 24])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.9167, 0.9219, 0.6916, 0.6916, 0.9219, 0.6916, 0.6930, 0.8499, 0.8076,\n",
      "        2.1159, 0.6918, 1.8458, 0.6954, 2.0509, 0.8499, 1.5833, 0.9167, 1.0719,\n",
      "        0.6916, 1.0719, 0.6916, 0.9289, 0.9167, 0.6916],\n",
      "       grad_fn=<SumBackward1>)\n",
      "43 24\n",
      "torch.Size([24, 24])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([1.0001, 0.9167, 0.7578, 0.7578, 0.7578, 0.9167, 1.0001, 0.7578, 0.7578,\n",
      "        0.8369, 0.8667, 0.7578, 1.6833, 0.8839, 0.8667, 3.5306, 0.8667, 0.8688,\n",
      "        0.8667, 1.0001, 0.9167, 0.7578, 0.9167, 0.7578],\n",
      "       grad_fn=<SumBackward1>)\n",
      "44 26\n",
      "torch.Size([26, 26])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.7537, 0.7537, 0.7537, 0.7537, 1.6923, 0.7537, 1.0256, 1.1921, 1.1923,\n",
      "        0.7537, 0.7537, 0.7537, 0.7537, 0.7537, 0.7537, 0.7537, 0.7537, 1.1923,\n",
      "        1.1922, 1.0256, 2.6923, 0.7537, 1.2321, 1.2321, 1.0256, 0.7540],\n",
      "       grad_fn=<SumBackward1>)\n",
      "45 29\n",
      "torch.Size([29, 29])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([0.7599, 0.7599, 0.7004, 0.7004, 2.7241, 0.7599, 0.7599, 1.1998, 0.7599,\n",
      "        0.7599, 0.7004, 0.7004, 1.1170, 0.7004, 0.7004, 1.6170, 0.9504, 0.9504,\n",
      "        0.9504, 1.1170, 1.1998, 0.7599, 0.7004, 0.7004, 0.7004, 1.6170, 1.6170,\n",
      "        0.7004, 1.6170], grad_fn=<SumBackward1>)\n",
      "46 23\n",
      "torch.Size([23, 23])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.6951, 0.7864, 0.7860, 0.7860, 0.7860, 1.1947, 0.7860, 0.7860, 1.0284,\n",
      "        0.7860, 0.7860, 0.7992, 1.0284, 1.1951, 1.6958, 0.7860, 1.0284, 1.1947,\n",
      "        0.7860, 1.0284, 1.0284, 1.1951, 1.0284], grad_fn=<SumBackward1>)\n",
      "47 18\n",
      "torch.Size([18, 18])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.8056, 0.8888, 0.8888, 1.0395, 1.5559, 1.0395, 0.8056, 1.5554, 1.5876,\n",
      "        0.7556, 0.7556, 0.7556, 0.7556, 0.7556, 0.8056, 0.8056, 1.5556, 0.8889],\n",
      "       grad_fn=<SumBackward1>)\n",
      "48 12\n",
      "torch.Size([12, 12])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0191, 1.4742, 1.1667, 0.8767, 1.1667, 0.9167, 0.9167, 0.9167, 0.9167,\n",
      "        0.8767, 0.8767, 0.8767], grad_fn=<SumBackward1>)\n",
      "49 25\n",
      "torch.Size([25, 25])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([0.9964, 1.6003, 0.6652, 0.6652, 0.6652, 0.6652, 0.6652, 0.6652, 0.6652,\n",
      "        0.6652, 0.6652, 0.6652, 0.6652, 0.6652, 0.6652, 0.6652, 0.6667, 3.5919,\n",
      "        0.9330, 1.6003, 1.2312, 1.6003, 0.9330, 0.9330, 1.6006],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "common_dim = 200\n",
    "eps = 1e-7\n",
    "k = torch.autograd.Variable(torch.randn(args.pc_hidden, common_dim))\n",
    "q = torch.autograd.Variable(torch.randn(args.pc_hidden, common_dim))\n",
    "\n",
    "for idx, (stx, lex) in enumerate(X.scope):\n",
    "    yhat = yhat_embedding[stx:stx+lex]\n",
    "    x = x_embedding[stx:stx+lex]\n",
    "    M = 1/np.sqrt(common_dim) * torch.matmul(torch.matmul(x, k), torch.matmul(q.T, yhat.T))\n",
    "    attn = torch.softmax(M, dim = 1) + eps\n",
    "    W = (attn / attn.sum(axis = 0))\n",
    "   \n",
    "    print (idx, lex)\n",
    "    print (W.shape)\n",
    "    print (W.sum(axis = 0))\n",
    "    print (W.sum(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 3.6910e-01,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 2.6929e-02, 4.0008e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e+00, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 5.1433e-08, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 1.7823e-03, 4.0000e-02, 6.4547e-02, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 9.9593e-01, 4.0000e-02, 4.0000e-02, 1.0000e+00, 4.0000e-02,\n",
       "         4.0000e-02, 9.9593e-01, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 2.3240e-08, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-01, 4.0000e-02, 6.4895e-09, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0009e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4895e-09, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e+00],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-01,\n",
       "         1.0000e-07, 3.3265e-08, 4.0000e-02, 6.4905e-09, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0060e-07, 4.0007e-02, 6.3090e-08,\n",
       "         1.0000e+00, 3.3265e-08, 4.0000e-02, 6.4895e-09, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-01, 4.0000e-02, 6.4895e-09, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0008e-07, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 3.3265e-01, 4.0000e-02, 1.5515e-08, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07],\n",
       "        [4.0000e-02, 4.0000e-02, 4.0000e-02, 1.0000e-07, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 4.0000e-02, 1.0012e-07, 4.0000e-02,\n",
       "         4.0000e-02, 1.6957e-04, 4.0000e-02, 1.0000e+00, 4.0000e-02, 6.3090e-08,\n",
       "         1.0000e-07, 2.7322e-04, 4.0000e-02, 6.4895e-09, 4.0000e-02, 4.0000e-02,\n",
       "         1.0000e-07]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 25])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8806e+01,  1.2745e+02,  8.5013e+01,  1.6420e+02,  1.8269e+01,\n",
       "         -1.2526e+02, -6.7990e+01,  2.9985e+01, -6.0364e+01, -6.3572e+01,\n",
       "          2.8890e+01, -6.3572e+01, -6.0364e+01,  2.9985e+01, -5.5506e+01,\n",
       "         -1.0067e+02,  5.0763e+01,  2.1775e+02,  9.6130e+01,  1.8065e+02,\n",
       "         -3.5103e+01,  2.1741e+02,  1.9373e+02,  1.2703e+02,  5.9381e+01],\n",
       "        [-1.8349e+01,  9.2621e+01,  1.3784e+02,  1.6916e+02,  8.9967e+00,\n",
       "         -1.7360e+02, -1.5138e+02, -4.8960e+01, -1.5916e+02, -1.6577e+02,\n",
       "         -4.5353e+01, -1.6577e+02, -1.5916e+02, -4.8960e+01, -1.4277e+02,\n",
       "         -1.3320e+02,  5.1016e+01,  9.9278e+01,  8.4654e+01,  1.2031e+02,\n",
       "         -9.5534e+01,  1.5498e+02,  1.2172e+02,  5.0620e+01,  4.9736e+01],\n",
       "        [ 1.3419e+01,  1.7614e+02,  2.3679e+02,  3.0860e+02,  2.7714e+01,\n",
       "         -1.3887e+02, -7.2370e+01, -6.2119e+01, -8.8330e+01, -9.7444e+01,\n",
       "         -6.0173e+01, -9.7444e+01, -8.8330e+01, -6.2119e+01, -6.4899e+01,\n",
       "         -8.9064e+01,  7.9825e+01,  2.6198e+02,  1.9640e+02,  1.9484e+02,\n",
       "         -2.9178e+01,  3.4556e+02,  1.9628e+02,  1.3766e+02,  1.3186e+02],\n",
       "        [-3.4180e+01,  1.0178e+02,  9.5928e+01,  1.2640e+02, -2.8854e+01,\n",
       "         -1.4133e+02, -1.0965e+02, -8.2269e+01, -1.2018e+02, -1.2538e+02,\n",
       "         -8.0476e+01, -1.2538e+02, -1.2018e+02, -8.2269e+01, -9.9499e+01,\n",
       "         -1.0409e+02,  1.2272e-01,  9.2307e+01,  1.0439e+02,  1.5120e+02,\n",
       "         -4.2957e+01,  2.5857e+02,  1.2685e+02,  4.1371e+01,  6.3052e+01],\n",
       "        [-8.5577e+01,  7.7856e+01,  7.7830e+01,  9.6812e+01,  1.1632e+01,\n",
       "         -1.3842e+02, -7.1884e+01,  4.3793e+01, -6.8222e+01, -7.0802e+01,\n",
       "          3.6130e+01, -7.0802e+01, -6.8222e+01,  4.3793e+01, -5.6561e+01,\n",
       "         -1.1638e+02,  3.1914e+01,  9.5220e+01,  9.6312e+01,  1.5614e+02,\n",
       "          1.2577e+01,  2.0649e+02,  1.5214e+02,  1.2910e+02,  7.2711e+01],\n",
       "        [-1.0361e+02,  4.0324e+00, -5.5896e+01, -3.1929e+01, -1.6995e+02,\n",
       "         -3.7697e+02, -2.4763e+02, -1.1928e+02, -2.2508e+02, -2.2647e+02,\n",
       "         -1.3082e+02, -2.2647e+02, -2.2508e+02, -1.1928e+02, -2.2862e+02,\n",
       "         -3.3967e+02, -1.1422e+02,  6.9952e+01, -5.5981e+01, -9.1695e+01,\n",
       "          7.8900e+00,  2.4858e+02,  3.1941e+01,  1.8945e+01,  1.6882e+02],\n",
       "        [-1.4226e+02, -5.4908e+01, -6.8499e+01, -6.4735e+01, -1.6340e+02,\n",
       "         -4.4183e+02, -2.9454e+02, -6.9716e+01, -2.6782e+02, -2.6787e+02,\n",
       "         -8.3955e+01, -2.6787e+02, -2.6782e+02, -6.9716e+01, -2.7137e+02,\n",
       "         -3.9315e+02, -9.5103e+01,  7.7355e+01, -7.1096e+01, -8.9529e+01,\n",
       "          2.4529e+01,  2.5405e+02,  4.4291e+01,  1.7562e+01,  1.7040e+02],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-1.4175e+02,  6.9503e+01,  1.0256e+02,  7.8622e+01,  3.3251e+01,\n",
       "         -1.3056e+02, -1.0908e+02,  3.3809e+01, -8.5626e+01, -8.7258e+01,\n",
       "          3.8418e+01, -8.7258e+01, -8.5626e+01,  3.3809e+01, -8.8714e+01,\n",
       "         -9.8440e+01,  4.1398e+01,  2.8889e+01,  5.9545e+01,  1.1578e+02,\n",
       "          8.7794e+01,  2.0508e+02,  6.8253e+01,  7.9645e+01,  8.6628e+01],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [-1.3260e+02, -2.8387e+01, -6.5230e+01, -5.2705e+01, -1.5164e+02,\n",
       "         -4.3932e+02, -2.9490e+02, -5.9763e+01, -2.7242e+02, -2.7222e+02,\n",
       "         -7.2692e+01, -2.7222e+02, -2.7242e+02, -5.9763e+01, -2.7225e+02,\n",
       "         -3.9949e+02, -8.4544e+01,  9.3551e+01, -6.2804e+01, -9.5592e+01,\n",
       "          1.9358e+01,  2.4522e+02,  5.0873e+01,  2.9236e+01,  1.6399e+02],\n",
       "        [-1.1108e+02,  3.0390e+01, -5.2469e+01, -2.3003e+01, -1.5536e+02,\n",
       "         -4.1227e+02, -2.7429e+02, -8.6056e+01, -2.5178e+02, -2.5279e+02,\n",
       "         -9.6545e+01, -2.5279e+02, -2.5178e+02, -8.6056e+01, -2.5256e+02,\n",
       "         -3.7861e+02, -9.3677e+01,  9.3129e+01, -4.9324e+01, -9.2061e+01,\n",
       "         -8.4151e+00,  2.6010e+02,  5.2161e+01,  3.9355e+01,  1.6669e+02],\n",
       "        [-1.0237e+02,  4.4220e+01,  8.6363e+01,  1.0266e+02,  1.9387e+01,\n",
       "         -1.3108e+02, -7.1542e+01,  5.0727e+01, -6.4031e+01, -6.5911e+01,\n",
       "          4.5624e+01, -6.5911e+01, -6.4031e+01,  5.0727e+01, -6.0926e+01,\n",
       "         -1.0589e+02,  4.6251e+01,  1.0855e+02,  1.2764e+02,  2.0013e+02,\n",
       "          2.7195e+01,  2.0535e+02,  1.6045e+02,  1.2593e+02,  5.8524e+01],\n",
       "        [-1.9427e+02, -9.3319e+01, -8.6999e+01, -7.4099e+01,  1.4269e+01,\n",
       "         -2.6058e+02, -2.3335e+02,  1.5223e+02, -2.2765e+02, -2.2457e+02,\n",
       "          1.5967e+02, -2.2457e+02, -2.2765e+02,  1.5223e+02, -2.1992e+02,\n",
       "         -2.5309e+02,  3.1494e+01, -7.3894e+01,  5.6645e+01,  1.1840e+02,\n",
       "         -4.9226e+00,  1.4450e+02,  3.5715e+01, -1.8686e+01, -6.3116e+01],\n",
       "        [-1.1923e+02, -5.9629e+01, -3.5477e+01, -6.2287e+01, -6.7956e+01,\n",
       "         -1.3300e+02, -5.6052e+01, -1.0629e+01, -5.7595e+01, -5.8856e+01,\n",
       "         -2.3312e+01, -5.8856e+01, -5.7595e+01, -1.0629e+01, -4.9471e+01,\n",
       "         -9.8253e+01, -2.9414e+01,  5.3016e+01,  1.4275e+02,  2.0140e+02,\n",
       "          2.5368e+00,  1.6847e+02,  1.6342e+02,  1.0452e+02,  2.9112e+01],\n",
       "        [-5.0592e+01, -1.1114e+02, -2.4645e+01, -2.0936e+02, -1.4528e+02,\n",
       "         -1.5217e+01, -6.7821e+01, -2.8649e+02, -3.2025e+01, -3.9599e+01,\n",
       "         -2.8217e+02, -3.9599e+01, -3.2025e+01, -2.8649e+02, -6.1862e+01,\n",
       "          5.8680e+01, -1.2127e+02, -8.9990e+01, -4.7383e+01,  5.6195e+01,\n",
       "         -1.9670e+01,  5.3916e+01, -2.1905e+01, -2.3979e+01,  8.4365e+01],\n",
       "        [-8.9948e+01,  7.5621e+00,  6.8850e+00,  1.6208e+00, -7.2264e+01,\n",
       "          3.4406e+01,  5.9855e+01, -1.1907e+02,  1.0299e+02,  9.9488e+01,\n",
       "         -1.1880e+02,  9.9488e+01,  1.0299e+02, -1.1907e+02,  6.8117e+01,\n",
       "          1.0220e+02, -2.6015e+01,  1.5597e+02,  2.9095e+01,  1.2512e+02,\n",
       "         -2.9149e+01,  1.3111e+02,  8.7560e+01, -1.8449e+00,  1.6903e+01],\n",
       "        [-5.4560e+01,  1.0016e+02,  1.0596e+02, -2.3179e+01,  1.0314e+02,\n",
       "          1.1376e+02,  4.2291e+01,  1.1896e+02,  5.5046e+01,  5.0743e+01,\n",
       "          1.2211e+02,  5.0743e+01,  5.5046e+01,  1.1896e+02,  3.9664e+01,\n",
       "          1.5812e+02,  1.5471e+02, -8.9072e+00,  1.7950e+02,  1.2768e+02,\n",
       "          2.7970e+00,  7.1505e+01,  1.0331e+02,  7.6419e+01,  4.5112e+01],\n",
       "        [-7.8885e+01,  7.2556e+01,  1.0373e+02,  1.1950e+02,  4.8719e+01,\n",
       "         -1.8229e+02, -1.6753e+02,  3.0221e+01, -1.5645e+02, -1.5841e+02,\n",
       "          3.8944e+01, -1.5841e+02, -1.5645e+02,  3.0221e+01, -1.6239e+02,\n",
       "         -1.4762e+02,  7.8007e+01,  1.0311e+02,  1.3401e+02,  2.9438e+02,\n",
       "          1.1596e+00,  2.4554e+02,  1.0706e+02,  4.1670e+01,  5.8804e+01],\n",
       "        [-9.0737e+01, -8.2141e+00,  1.8435e+01,  4.8170e+01, -4.1254e+01,\n",
       "         -2.2802e+02, -1.9034e+02, -2.5503e+01, -1.9098e+02, -1.9185e+02,\n",
       "         -2.4767e+01, -1.9185e+02, -1.9098e+02, -2.5503e+01, -1.8670e+02,\n",
       "         -2.0945e+02,  4.1963e+00,  5.1351e+01,  7.6705e+01,  1.5329e+02,\n",
       "         -1.5772e+01,  1.3750e+02,  1.0138e+02,  5.1821e+01,  5.6784e+01],\n",
       "        [ 6.9156e+01, -7.7571e+00,  2.0306e+02,  3.8969e+01,  6.6164e+01,\n",
       "          1.7069e+02,  5.3064e+01, -4.5214e+01,  9.8600e+01,  9.0422e+01,\n",
       "         -4.2173e+01,  9.0422e+01,  9.8600e+01, -4.5214e+01,  4.0607e+01,\n",
       "          2.4738e+02,  1.2399e+02,  4.4344e+01,  1.7271e+02,  2.4028e+02,\n",
       "          5.4295e+01,  1.0368e+02,  6.2485e+01,  3.5069e+01,  9.9739e+01]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdet_orig = M.detach().cpu().numpy().copy()\n",
    "Mdet = M.detach().cpu().numpy().copy()\n",
    "np.random.shuffle(Mdet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36550903e+02,  6.81647415e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319481e+01, -1.35173340e+02,\n",
       "        -1.08069221e+02,  3.83839455e+01, -8.44185638e+01,\n",
       "        -8.56652298e+01,  4.37059669e+01, -8.56652298e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548050e+01,  4.25657501e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223709e+01,\n",
       "         2.01263702e+02,  6.49279480e+01,  7.15621567e+01,\n",
       "         8.77687454e+01],\n",
       "       [-1.41745499e+02,  6.95025024e+01,  1.02559906e+02,\n",
       "         7.86224289e+01,  3.32511063e+01, -1.30562500e+02,\n",
       "        -1.09084831e+02,  3.38087959e+01, -8.56264267e+01,\n",
       "        -8.72580566e+01,  3.84175034e+01, -8.72580566e+01,\n",
       "        -8.56264267e+01,  3.38088036e+01, -8.87138443e+01,\n",
       "        -9.84396439e+01,  4.13976135e+01,  2.88886242e+01,\n",
       "         5.95451431e+01,  1.15779877e+02,  8.77940063e+01,\n",
       "         2.05081360e+02,  6.82530594e+01,  7.96451645e+01,\n",
       "         8.66283646e+01],\n",
       "       [-1.83492146e+01,  9.26209259e+01,  1.37842575e+02,\n",
       "         1.69162537e+02,  8.99667835e+00, -1.73602600e+02,\n",
       "        -1.51378342e+02, -4.89596748e+01, -1.59155289e+02,\n",
       "        -1.65768341e+02, -4.53528862e+01, -1.65768341e+02,\n",
       "        -1.59155289e+02, -4.89596748e+01, -1.42774399e+02,\n",
       "        -1.33195892e+02,  5.10164108e+01,  9.92778549e+01,\n",
       "         8.46540451e+01,  1.20313560e+02, -9.55340500e+01,\n",
       "         1.54979660e+02,  1.21715820e+02,  5.06204796e+01,\n",
       "         4.97362747e+01],\n",
       "       [-1.02365128e+02,  4.42197723e+01,  8.63626709e+01,\n",
       "         1.02662292e+02,  1.93874683e+01, -1.31079193e+02,\n",
       "        -7.15418625e+01,  5.07268791e+01, -6.40310364e+01,\n",
       "        -6.59105530e+01,  4.56244392e+01, -6.59105530e+01,\n",
       "        -6.40310364e+01,  5.07268791e+01, -6.09264412e+01,\n",
       "        -1.05887657e+02,  4.62507591e+01,  1.08548080e+02,\n",
       "         1.27635468e+02,  2.00126785e+02,  2.71951561e+01,\n",
       "         2.05350586e+02,  1.60445786e+02,  1.25930275e+02,\n",
       "         5.85239143e+01],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-1.11082222e+02,  3.03898048e+01, -5.24693451e+01,\n",
       "        -2.30031281e+01, -1.55363968e+02, -4.12267548e+02,\n",
       "        -2.74289490e+02, -8.60564117e+01, -2.51776825e+02,\n",
       "        -2.52794312e+02, -9.65450439e+01, -2.52794312e+02,\n",
       "        -2.51776825e+02, -8.60564117e+01, -2.52561707e+02,\n",
       "        -3.78611755e+02, -9.36768112e+01,  9.31287613e+01,\n",
       "        -4.93243065e+01, -9.20607681e+01, -8.41514111e+00,\n",
       "         2.60104584e+02,  5.21609955e+01,  3.93547935e+01,\n",
       "         1.66690750e+02],\n",
       "       [-1.36550873e+02,  6.81647491e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319443e+01, -1.35173370e+02,\n",
       "        -1.08069221e+02,  3.83839607e+01, -8.44185638e+01,\n",
       "        -8.56652756e+01,  4.37059593e+01, -8.56652756e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548431e+01,  4.25657425e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223557e+01,\n",
       "         2.01263657e+02,  6.49279404e+01,  7.15621414e+01,\n",
       "         8.77687378e+01],\n",
       "       [ 1.34186239e+01,  1.76136963e+02,  2.36792114e+02,\n",
       "         3.08596344e+02,  2.77139816e+01, -1.38867889e+02,\n",
       "        -7.23698807e+01, -6.21188812e+01, -8.83300476e+01,\n",
       "        -9.74438477e+01, -6.01728668e+01, -9.74438477e+01,\n",
       "        -8.83300476e+01, -6.21188812e+01, -6.48987961e+01,\n",
       "        -8.90636063e+01,  7.98253708e+01,  2.61980255e+02,\n",
       "         1.96402252e+02,  1.94839828e+02, -2.91775169e+01,\n",
       "         3.45563812e+02,  1.96279922e+02,  1.37662170e+02,\n",
       "         1.31858047e+02],\n",
       "       [-1.01353043e+02, -1.62935600e+01, -4.81409302e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-9.07371368e+01, -8.21410179e+00,  1.84349041e+01,\n",
       "         4.81701889e+01, -4.12543602e+01, -2.28016327e+02,\n",
       "        -1.90343597e+02, -2.55028915e+01, -1.90976151e+02,\n",
       "        -1.91850769e+02, -2.47672958e+01, -1.91850769e+02,\n",
       "        -1.90976151e+02, -2.55028915e+01, -1.86695374e+02,\n",
       "        -2.09454132e+02,  4.19630194e+00,  5.13508949e+01,\n",
       "         7.67049484e+01,  1.53291550e+02, -1.57724085e+01,\n",
       "         1.37503357e+02,  1.01375107e+02,  5.18212547e+01,\n",
       "         5.67843666e+01],\n",
       "       [-7.88852692e+01,  7.25557861e+01,  1.03729790e+02,\n",
       "         1.19504967e+02,  4.87192879e+01, -1.82292557e+02,\n",
       "        -1.67526459e+02,  3.02212849e+01, -1.56447525e+02,\n",
       "        -1.58408875e+02,  3.89437447e+01, -1.58408875e+02,\n",
       "        -1.56447525e+02,  3.02212849e+01, -1.62388000e+02,\n",
       "        -1.47620087e+02,  7.80071945e+01,  1.03107742e+02,\n",
       "         1.34013702e+02,  2.94375854e+02,  1.15958142e+00,\n",
       "         2.45539108e+02,  1.07058586e+02,  4.16696701e+01,\n",
       "         5.88036499e+01],\n",
       "       [-1.94267349e+02, -9.33194885e+01, -8.69994965e+01,\n",
       "        -7.40991135e+01,  1.42685404e+01, -2.60582245e+02,\n",
       "        -2.33354507e+02,  1.52231323e+02, -2.27652618e+02,\n",
       "        -2.24569138e+02,  1.59670258e+02, -2.24569138e+02,\n",
       "        -2.27652618e+02,  1.52231323e+02, -2.19920303e+02,\n",
       "        -2.53092010e+02,  3.14940853e+01, -7.38941040e+01,\n",
       "         5.66454620e+01,  1.18396759e+02, -4.92256498e+00,\n",
       "         1.44501602e+02,  3.57148056e+01, -1.86855354e+01,\n",
       "        -6.31158371e+01],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-4.88056641e+01,  1.27446671e+02,  8.50131836e+01,\n",
       "         1.64195267e+02,  1.82686081e+01, -1.25264709e+02,\n",
       "        -6.79895096e+01,  2.99845352e+01, -6.03640709e+01,\n",
       "        -6.35715599e+01,  2.88896904e+01, -6.35715599e+01,\n",
       "        -6.03640709e+01,  2.99845352e+01, -5.55064354e+01,\n",
       "        -1.00666046e+02,  5.07632561e+01,  2.17748779e+02,\n",
       "         9.61298676e+01,  1.80651260e+02, -3.51030121e+01,\n",
       "         2.17405273e+02,  1.93726181e+02,  1.27026718e+02,\n",
       "         5.93812599e+01],\n",
       "       [-5.45599861e+01,  1.00158745e+02,  1.05964836e+02,\n",
       "        -2.31788368e+01,  1.03137474e+02,  1.13762985e+02,\n",
       "         4.22908745e+01,  1.18958099e+02,  5.50460625e+01,\n",
       "         5.07430649e+01,  1.22109154e+02,  5.07430649e+01,\n",
       "         5.50460625e+01,  1.18958084e+02,  3.96638756e+01,\n",
       "         1.58115173e+02,  1.54708847e+02, -8.90717983e+00,\n",
       "         1.79497879e+02,  1.27680420e+02,  2.79696488e+00,\n",
       "         7.15046005e+01,  1.03312851e+02,  7.64186859e+01,\n",
       "         4.51117783e+01],\n",
       "       [-3.41802597e+01,  1.01781570e+02,  9.59276352e+01,\n",
       "         1.26400780e+02, -2.88540478e+01, -1.41332748e+02,\n",
       "        -1.09651588e+02, -8.22688065e+01, -1.20184616e+02,\n",
       "        -1.25382523e+02, -8.04758759e+01, -1.25382523e+02,\n",
       "        -1.20184616e+02, -8.22688065e+01, -9.94991913e+01,\n",
       "        -1.04089645e+02,  1.22722663e-01,  9.23067322e+01,\n",
       "         1.04388435e+02,  1.51203842e+02, -4.29573746e+01,\n",
       "         2.58570312e+02,  1.26849747e+02,  4.13706169e+01,\n",
       "         6.30515633e+01],\n",
       "       [-5.05915604e+01, -1.11137825e+02, -2.46446323e+01,\n",
       "        -2.09355728e+02, -1.45283829e+02, -1.52174692e+01,\n",
       "        -6.78208542e+01, -2.86494415e+02, -3.20254326e+01,\n",
       "        -3.95985756e+01, -2.82174957e+02, -3.95985756e+01,\n",
       "        -3.20254326e+01, -2.86494415e+02, -6.18615494e+01,\n",
       "         5.86800423e+01, -1.21269150e+02, -8.99904022e+01,\n",
       "        -4.73829536e+01,  5.61949043e+01, -1.96696320e+01,\n",
       "         5.39164009e+01, -2.19052486e+01, -2.39790688e+01,\n",
       "         8.43652802e+01],\n",
       "       [ 6.91557465e+01, -7.75707722e+00,  2.03064453e+02,\n",
       "         3.89688568e+01,  6.61638870e+01,  1.70689346e+02,\n",
       "         5.30642090e+01, -4.52142029e+01,  9.85995789e+01,\n",
       "         9.04224091e+01, -4.21729965e+01,  9.04224091e+01,\n",
       "         9.85995789e+01, -4.52142105e+01,  4.06072273e+01,\n",
       "         2.47382370e+02,  1.23985901e+02,  4.43443184e+01,\n",
       "         1.72711823e+02,  2.40278519e+02,  5.42948418e+01,\n",
       "         1.03681747e+02,  6.24854622e+01,  3.50694237e+01,\n",
       "         9.97391357e+01],\n",
       "       [-8.55771942e+01,  7.78556366e+01,  7.78295135e+01,\n",
       "         9.68123550e+01,  1.16317530e+01, -1.38424561e+02,\n",
       "        -7.18837509e+01,  4.37928772e+01, -6.82218170e+01,\n",
       "        -7.08022308e+01,  3.61296844e+01, -7.08022308e+01,\n",
       "        -6.82218170e+01,  4.37928772e+01, -5.65611610e+01,\n",
       "        -1.16380333e+02,  3.19141293e+01,  9.52203903e+01,\n",
       "         9.63119049e+01,  1.56136108e+02,  1.25771351e+01,\n",
       "         2.06493317e+02,  1.52142303e+02,  1.29101456e+02,\n",
       "         7.27111893e+01],\n",
       "       [-1.32601089e+02, -2.83870506e+01, -6.52298203e+01,\n",
       "        -5.27048187e+01, -1.51636551e+02, -4.39321747e+02,\n",
       "        -2.94904388e+02, -5.97630577e+01, -2.72415894e+02,\n",
       "        -2.72224030e+02, -7.26923523e+01, -2.72224030e+02,\n",
       "        -2.72415894e+02, -5.97630692e+01, -2.72250702e+02,\n",
       "        -3.99491547e+02, -8.45443573e+01,  9.35509109e+01,\n",
       "        -6.28044281e+01, -9.55923538e+01,  1.93577957e+01,\n",
       "         2.45220795e+02,  5.08734131e+01,  2.92363091e+01,\n",
       "         1.63989105e+02],\n",
       "       [-1.01353043e+02, -1.62935486e+01, -4.81409454e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-8.99477539e+01,  7.56210232e+00,  6.88499069e+00,\n",
       "         1.62078476e+00, -7.22636414e+01,  3.44055786e+01,\n",
       "         5.98550415e+01, -1.19069115e+02,  1.02992706e+02,\n",
       "         9.94882050e+01, -1.18800636e+02,  9.94882050e+01,\n",
       "         1.02992706e+02, -1.19069099e+02,  6.81170349e+01,\n",
       "         1.02202347e+02, -2.60145473e+01,  1.55966446e+02,\n",
       "         2.90947914e+01,  1.25119064e+02, -2.91494045e+01,\n",
       "         1.31105179e+02,  8.75604782e+01, -1.84493661e+00,\n",
       "         1.69025841e+01],\n",
       "       [-1.19229172e+02, -5.96294746e+01, -3.54770164e+01,\n",
       "        -6.22872696e+01, -6.79555588e+01, -1.33002975e+02,\n",
       "        -5.60519295e+01, -1.06289597e+01, -5.75945892e+01,\n",
       "        -5.88556023e+01, -2.33123817e+01, -5.88556023e+01,\n",
       "        -5.75945892e+01, -1.06289587e+01, -4.94709129e+01,\n",
       "        -9.82530899e+01, -2.94137039e+01,  5.30157661e+01,\n",
       "         1.42747665e+02,  2.01400970e+02,  2.53682733e+00,\n",
       "         1.68473206e+02,  1.63419891e+02,  1.04522156e+02,\n",
       "         2.91124153e+01],\n",
       "       [-1.42264709e+02, -5.49079819e+01, -6.84985352e+01,\n",
       "        -6.47350235e+01, -1.63396500e+02, -4.41831390e+02,\n",
       "        -2.94542755e+02, -6.97163086e+01, -2.67818451e+02,\n",
       "        -2.67872864e+02, -8.39545441e+01, -2.67872864e+02,\n",
       "        -2.67818451e+02, -6.97163010e+01, -2.71367615e+02,\n",
       "        -3.93151459e+02, -9.51026230e+01,  7.73551102e+01,\n",
       "        -7.10961914e+01, -8.95292664e+01,  2.45286694e+01,\n",
       "         2.54052979e+02,  4.42912254e+01,  1.75615902e+01,\n",
       "         1.70402695e+02],\n",
       "       [-1.03609627e+02,  4.03235579e+00, -5.58961792e+01,\n",
       "        -3.19293747e+01, -1.69948975e+02, -3.76969299e+02,\n",
       "        -2.47625702e+02, -1.19275635e+02, -2.25075485e+02,\n",
       "        -2.26471771e+02, -1.30822815e+02, -2.26471771e+02,\n",
       "        -2.25075485e+02, -1.19275635e+02, -2.28617111e+02,\n",
       "        -3.39665985e+02, -1.14217369e+02,  6.99518433e+01,\n",
       "        -5.59809036e+01, -9.16953354e+01,  7.88998842e+00,\n",
       "         2.48581375e+02,  3.19408703e+01,  1.89452496e+01,\n",
       "         1.68819168e+02]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36550903e+02,  6.81647415e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319481e+01, -1.35173340e+02,\n",
       "        -1.08069221e+02,  3.83839455e+01, -8.44185638e+01,\n",
       "        -8.56652298e+01,  4.37059669e+01, -8.56652298e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548050e+01,  4.25657501e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223709e+01,\n",
       "         2.01263702e+02,  6.49279480e+01,  7.15621567e+01,\n",
       "         8.77687454e+01],\n",
       "       [-5.45599861e+01,  1.00158745e+02,  1.05964836e+02,\n",
       "        -2.31788368e+01,  1.03137474e+02,  1.13762985e+02,\n",
       "         4.22908745e+01,  1.18958099e+02,  5.50460625e+01,\n",
       "         5.07430649e+01,  1.22109154e+02,  5.07430649e+01,\n",
       "         5.50460625e+01,  1.18958084e+02,  3.96638756e+01,\n",
       "         1.58115173e+02,  1.54708847e+02, -8.90717983e+00,\n",
       "         1.79497879e+02,  1.27680420e+02,  2.79696488e+00,\n",
       "         7.15046005e+01,  1.03312851e+02,  7.64186859e+01,\n",
       "         4.51117783e+01],\n",
       "       [-1.41745499e+02,  6.95025024e+01,  1.02559906e+02,\n",
       "         7.86224289e+01,  3.32511063e+01, -1.30562500e+02,\n",
       "        -1.09084831e+02,  3.38087959e+01, -8.56264267e+01,\n",
       "        -8.72580566e+01,  3.84175034e+01, -8.72580566e+01,\n",
       "        -8.56264267e+01,  3.38088036e+01, -8.87138443e+01,\n",
       "        -9.84396439e+01,  4.13976135e+01,  2.88886242e+01,\n",
       "         5.95451431e+01,  1.15779877e+02,  8.77940063e+01,\n",
       "         2.05081360e+02,  6.82530594e+01,  7.96451645e+01,\n",
       "         8.66283646e+01],\n",
       "       [-1.36550873e+02,  6.81647491e+01,  1.03288399e+02,\n",
       "         7.67897720e+01,  3.60319443e+01, -1.35173370e+02,\n",
       "        -1.08069221e+02,  3.83839607e+01, -8.44185638e+01,\n",
       "        -8.56652756e+01,  4.37059593e+01, -8.56652756e+01,\n",
       "        -8.44185638e+01,  3.83839607e+01, -8.79000778e+01,\n",
       "        -9.98548431e+01,  4.25657425e+01,  2.22053623e+01,\n",
       "         5.34014587e+01,  1.11797241e+02,  8.24223557e+01,\n",
       "         2.01263657e+02,  6.49279404e+01,  7.15621414e+01,\n",
       "         8.77687378e+01],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-8.55771942e+01,  7.78556366e+01,  7.78295135e+01,\n",
       "         9.68123550e+01,  1.16317530e+01, -1.38424561e+02,\n",
       "        -7.18837509e+01,  4.37928772e+01, -6.82218170e+01,\n",
       "        -7.08022308e+01,  3.61296844e+01, -7.08022308e+01,\n",
       "        -6.82218170e+01,  4.37928772e+01, -5.65611610e+01,\n",
       "        -1.16380333e+02,  3.19141293e+01,  9.52203903e+01,\n",
       "         9.63119049e+01,  1.56136108e+02,  1.25771351e+01,\n",
       "         2.06493317e+02,  1.52142303e+02,  1.29101456e+02,\n",
       "         7.27111893e+01],\n",
       "       [-5.05915604e+01, -1.11137825e+02, -2.46446323e+01,\n",
       "        -2.09355728e+02, -1.45283829e+02, -1.52174692e+01,\n",
       "        -6.78208542e+01, -2.86494415e+02, -3.20254326e+01,\n",
       "        -3.95985756e+01, -2.82174957e+02, -3.95985756e+01,\n",
       "        -3.20254326e+01, -2.86494415e+02, -6.18615494e+01,\n",
       "         5.86800423e+01, -1.21269150e+02, -8.99904022e+01,\n",
       "        -4.73829536e+01,  5.61949043e+01, -1.96696320e+01,\n",
       "         5.39164009e+01, -2.19052486e+01, -2.39790688e+01,\n",
       "         8.43652802e+01],\n",
       "       [-1.03609627e+02,  4.03235579e+00, -5.58961792e+01,\n",
       "        -3.19293747e+01, -1.69948975e+02, -3.76969299e+02,\n",
       "        -2.47625702e+02, -1.19275635e+02, -2.25075485e+02,\n",
       "        -2.26471771e+02, -1.30822815e+02, -2.26471771e+02,\n",
       "        -2.25075485e+02, -1.19275635e+02, -2.28617111e+02,\n",
       "        -3.39665985e+02, -1.14217369e+02,  6.99518433e+01,\n",
       "        -5.59809036e+01, -9.16953354e+01,  7.88998842e+00,\n",
       "         2.48581375e+02,  3.19408703e+01,  1.89452496e+01,\n",
       "         1.68819168e+02],\n",
       "       [-1.01175285e+02, -1.54687977e+01, -5.31892624e+01,\n",
       "        -4.89507370e+01, -1.46639160e+02, -3.80385101e+02,\n",
       "        -2.61636536e+02, -8.35660477e+01, -2.38411499e+02,\n",
       "        -2.38277679e+02, -9.44022064e+01, -2.38277679e+02,\n",
       "        -2.38411499e+02, -8.35660477e+01, -2.42703979e+02,\n",
       "        -3.45879364e+02, -8.86485825e+01,  7.14123306e+01,\n",
       "        -6.50000610e+01, -1.11270020e+02,  1.50974340e+01,\n",
       "         2.06003464e+02,  1.33229513e+01,  1.38495922e+01,\n",
       "         1.65312592e+02],\n",
       "       [-1.01353043e+02, -1.62935600e+01, -4.81409302e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-1.01353043e+02, -1.62935486e+01, -4.81409454e+01,\n",
       "        -4.86631126e+01, -1.42555603e+02, -3.73634674e+02,\n",
       "        -2.58322998e+02, -8.10957870e+01, -2.34032761e+02,\n",
       "        -2.33913986e+02, -9.18214951e+01, -2.33913986e+02,\n",
       "        -2.34032761e+02, -8.10957718e+01, -2.39484283e+02,\n",
       "        -3.37393280e+02, -8.47273331e+01,  7.17759399e+01,\n",
       "        -6.25860825e+01, -1.03286964e+02,  1.71766415e+01,\n",
       "         2.05227554e+02,  1.53499012e+01,  1.21512804e+01,\n",
       "         1.64193314e+02],\n",
       "       [-7.88852692e+01,  7.25557861e+01,  1.03729790e+02,\n",
       "         1.19504967e+02,  4.87192879e+01, -1.82292557e+02,\n",
       "        -1.67526459e+02,  3.02212849e+01, -1.56447525e+02,\n",
       "        -1.58408875e+02,  3.89437447e+01, -1.58408875e+02,\n",
       "        -1.56447525e+02,  3.02212849e+01, -1.62388000e+02,\n",
       "        -1.47620087e+02,  7.80071945e+01,  1.03107742e+02,\n",
       "         1.34013702e+02,  2.94375854e+02,  1.15958142e+00,\n",
       "         2.45539108e+02,  1.07058586e+02,  4.16696701e+01,\n",
       "         5.88036499e+01],\n",
       "       [-1.02365128e+02,  4.42197723e+01,  8.63626709e+01,\n",
       "         1.02662292e+02,  1.93874683e+01, -1.31079193e+02,\n",
       "        -7.15418625e+01,  5.07268791e+01, -6.40310364e+01,\n",
       "        -6.59105530e+01,  4.56244392e+01, -6.59105530e+01,\n",
       "        -6.40310364e+01,  5.07268791e+01, -6.09264412e+01,\n",
       "        -1.05887657e+02,  4.62507591e+01,  1.08548080e+02,\n",
       "         1.27635468e+02,  2.00126785e+02,  2.71951561e+01,\n",
       "         2.05350586e+02,  1.60445786e+02,  1.25930275e+02,\n",
       "         5.85239143e+01],\n",
       "       [-1.19229172e+02, -5.96294746e+01, -3.54770164e+01,\n",
       "        -6.22872696e+01, -6.79555588e+01, -1.33002975e+02,\n",
       "        -5.60519295e+01, -1.06289597e+01, -5.75945892e+01,\n",
       "        -5.88556023e+01, -2.33123817e+01, -5.88556023e+01,\n",
       "        -5.75945892e+01, -1.06289587e+01, -4.94709129e+01,\n",
       "        -9.82530899e+01, -2.94137039e+01,  5.30157661e+01,\n",
       "         1.42747665e+02,  2.01400970e+02,  2.53682733e+00,\n",
       "         1.68473206e+02,  1.63419891e+02,  1.04522156e+02,\n",
       "         2.91124153e+01],\n",
       "       [-8.99477539e+01,  7.56210232e+00,  6.88499069e+00,\n",
       "         1.62078476e+00, -7.22636414e+01,  3.44055786e+01,\n",
       "         5.98550415e+01, -1.19069115e+02,  1.02992706e+02,\n",
       "         9.94882050e+01, -1.18800636e+02,  9.94882050e+01,\n",
       "         1.02992706e+02, -1.19069099e+02,  6.81170349e+01,\n",
       "         1.02202347e+02, -2.60145473e+01,  1.55966446e+02,\n",
       "         2.90947914e+01,  1.25119064e+02, -2.91494045e+01,\n",
       "         1.31105179e+02,  8.75604782e+01, -1.84493661e+00,\n",
       "         1.69025841e+01],\n",
       "       [-1.42264709e+02, -5.49079819e+01, -6.84985352e+01,\n",
       "        -6.47350235e+01, -1.63396500e+02, -4.41831390e+02,\n",
       "        -2.94542755e+02, -6.97163086e+01, -2.67818451e+02,\n",
       "        -2.67872864e+02, -8.39545441e+01, -2.67872864e+02,\n",
       "        -2.67818451e+02, -6.97163010e+01, -2.71367615e+02,\n",
       "        -3.93151459e+02, -9.51026230e+01,  7.73551102e+01,\n",
       "        -7.10961914e+01, -8.95292664e+01,  2.45286694e+01,\n",
       "         2.54052979e+02,  4.42912254e+01,  1.75615902e+01,\n",
       "         1.70402695e+02],\n",
       "       [-9.07371368e+01, -8.21410179e+00,  1.84349041e+01,\n",
       "         4.81701889e+01, -4.12543602e+01, -2.28016327e+02,\n",
       "        -1.90343597e+02, -2.55028915e+01, -1.90976151e+02,\n",
       "        -1.91850769e+02, -2.47672958e+01, -1.91850769e+02,\n",
       "        -1.90976151e+02, -2.55028915e+01, -1.86695374e+02,\n",
       "        -2.09454132e+02,  4.19630194e+00,  5.13508949e+01,\n",
       "         7.67049484e+01,  1.53291550e+02, -1.57724085e+01,\n",
       "         1.37503357e+02,  1.01375107e+02,  5.18212547e+01,\n",
       "         5.67843666e+01],\n",
       "       [-3.41802597e+01,  1.01781570e+02,  9.59276352e+01,\n",
       "         1.26400780e+02, -2.88540478e+01, -1.41332748e+02,\n",
       "        -1.09651588e+02, -8.22688065e+01, -1.20184616e+02,\n",
       "        -1.25382523e+02, -8.04758759e+01, -1.25382523e+02,\n",
       "        -1.20184616e+02, -8.22688065e+01, -9.94991913e+01,\n",
       "        -1.04089645e+02,  1.22722663e-01,  9.23067322e+01,\n",
       "         1.04388435e+02,  1.51203842e+02, -4.29573746e+01,\n",
       "         2.58570312e+02,  1.26849747e+02,  4.13706169e+01,\n",
       "         6.30515633e+01],\n",
       "       [-1.11082222e+02,  3.03898048e+01, -5.24693451e+01,\n",
       "        -2.30031281e+01, -1.55363968e+02, -4.12267548e+02,\n",
       "        -2.74289490e+02, -8.60564117e+01, -2.51776825e+02,\n",
       "        -2.52794312e+02, -9.65450439e+01, -2.52794312e+02,\n",
       "        -2.51776825e+02, -8.60564117e+01, -2.52561707e+02,\n",
       "        -3.78611755e+02, -9.36768112e+01,  9.31287613e+01,\n",
       "        -4.93243065e+01, -9.20607681e+01, -8.41514111e+00,\n",
       "         2.60104584e+02,  5.21609955e+01,  3.93547935e+01,\n",
       "         1.66690750e+02],\n",
       "       [ 1.34186239e+01,  1.76136963e+02,  2.36792114e+02,\n",
       "         3.08596344e+02,  2.77139816e+01, -1.38867889e+02,\n",
       "        -7.23698807e+01, -6.21188812e+01, -8.83300476e+01,\n",
       "        -9.74438477e+01, -6.01728668e+01, -9.74438477e+01,\n",
       "        -8.83300476e+01, -6.21188812e+01, -6.48987961e+01,\n",
       "        -8.90636063e+01,  7.98253708e+01,  2.61980255e+02,\n",
       "         1.96402252e+02,  1.94839828e+02, -2.91775169e+01,\n",
       "         3.45563812e+02,  1.96279922e+02,  1.37662170e+02,\n",
       "         1.31858047e+02],\n",
       "       [-1.83492146e+01,  9.26209259e+01,  1.37842575e+02,\n",
       "         1.69162537e+02,  8.99667835e+00, -1.73602600e+02,\n",
       "        -1.51378342e+02, -4.89596748e+01, -1.59155289e+02,\n",
       "        -1.65768341e+02, -4.53528862e+01, -1.65768341e+02,\n",
       "        -1.59155289e+02, -4.89596748e+01, -1.42774399e+02,\n",
       "        -1.33195892e+02,  5.10164108e+01,  9.92778549e+01,\n",
       "         8.46540451e+01,  1.20313560e+02, -9.55340500e+01,\n",
       "         1.54979660e+02,  1.21715820e+02,  5.06204796e+01,\n",
       "         4.97362747e+01],\n",
       "       [-1.32601089e+02, -2.83870506e+01, -6.52298203e+01,\n",
       "        -5.27048187e+01, -1.51636551e+02, -4.39321747e+02,\n",
       "        -2.94904388e+02, -5.97630577e+01, -2.72415894e+02,\n",
       "        -2.72224030e+02, -7.26923523e+01, -2.72224030e+02,\n",
       "        -2.72415894e+02, -5.97630692e+01, -2.72250702e+02,\n",
       "        -3.99491547e+02, -8.45443573e+01,  9.35509109e+01,\n",
       "        -6.28044281e+01, -9.55923538e+01,  1.93577957e+01,\n",
       "         2.45220795e+02,  5.08734131e+01,  2.92363091e+01,\n",
       "         1.63989105e+02],\n",
       "       [ 6.91557465e+01, -7.75707722e+00,  2.03064453e+02,\n",
       "         3.89688568e+01,  6.61638870e+01,  1.70689346e+02,\n",
       "         5.30642090e+01, -4.52142029e+01,  9.85995789e+01,\n",
       "         9.04224091e+01, -4.21729965e+01,  9.04224091e+01,\n",
       "         9.85995789e+01, -4.52142105e+01,  4.06072273e+01,\n",
       "         2.47382370e+02,  1.23985901e+02,  4.43443184e+01,\n",
       "         1.72711823e+02,  2.40278519e+02,  5.42948418e+01,\n",
       "         1.03681747e+02,  6.24854622e+01,  3.50694237e+01,\n",
       "         9.97391357e+01],\n",
       "       [-1.94267349e+02, -9.33194885e+01, -8.69994965e+01,\n",
       "        -7.40991135e+01,  1.42685404e+01, -2.60582245e+02,\n",
       "        -2.33354507e+02,  1.52231323e+02, -2.27652618e+02,\n",
       "        -2.24569138e+02,  1.59670258e+02, -2.24569138e+02,\n",
       "        -2.27652618e+02,  1.52231323e+02, -2.19920303e+02,\n",
       "        -2.53092010e+02,  3.14940853e+01, -7.38941040e+01,\n",
       "         5.66454620e+01,  1.18396759e+02, -4.92256498e+00,\n",
       "         1.44501602e+02,  3.57148056e+01, -1.86855354e+01,\n",
       "        -6.31158371e+01],\n",
       "       [-4.88056641e+01,  1.27446671e+02,  8.50131836e+01,\n",
       "         1.64195267e+02,  1.82686081e+01, -1.25264709e+02,\n",
       "        -6.79895096e+01,  2.99845352e+01, -6.03640709e+01,\n",
       "        -6.35715599e+01,  2.88896904e+01, -6.35715599e+01,\n",
       "        -6.03640709e+01,  2.99845352e+01, -5.55064354e+01,\n",
       "        -1.00666046e+02,  5.07632561e+01,  2.17748779e+02,\n",
       "         9.61298676e+01,  1.80651260e+02, -3.51030121e+01,\n",
       "         2.17405273e+02,  1.93726181e+02,  1.27026718e+02,\n",
       "         5.93812599e+01]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mdet_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-5.4560e+01,  1.0016e+02,  1.0596e+02, -2.3179e+01,  1.0314e+02,\n",
       "          1.1376e+02,  4.2291e+01,  1.1896e+02,  5.5046e+01,  5.0743e+01,\n",
       "          1.2211e+02,  5.0743e+01,  5.5046e+01,  1.1896e+02,  3.9664e+01,\n",
       "          1.5812e+02,  1.5471e+02, -8.9072e+00,  1.7950e+02,  1.2768e+02,\n",
       "          2.7970e+00,  7.1505e+01,  1.0331e+02,  7.6419e+01,  4.5112e+01],\n",
       "        [-1.4175e+02,  6.9503e+01,  1.0256e+02,  7.8622e+01,  3.3251e+01,\n",
       "         -1.3056e+02, -1.0908e+02,  3.3809e+01, -8.5626e+01, -8.7258e+01,\n",
       "          3.8418e+01, -8.7258e+01, -8.5626e+01,  3.3809e+01, -8.8714e+01,\n",
       "         -9.8440e+01,  4.1398e+01,  2.8889e+01,  5.9545e+01,  1.1578e+02,\n",
       "          8.7794e+01,  2.0508e+02,  6.8253e+01,  7.9645e+01,  8.6628e+01],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [-1.8349e+01,  9.2621e+01,  1.3784e+02,  1.6916e+02,  8.9967e+00,\n",
       "         -1.7360e+02, -1.5138e+02, -4.8960e+01, -1.5916e+02, -1.6577e+02,\n",
       "         -4.5353e+01, -1.6577e+02, -1.5916e+02, -4.8960e+01, -1.4277e+02,\n",
       "         -1.3320e+02,  5.1016e+01,  9.9278e+01,  8.4654e+01,  1.2031e+02,\n",
       "         -9.5534e+01,  1.5498e+02,  1.2172e+02,  5.0620e+01,  4.9736e+01],\n",
       "        [-5.0592e+01, -1.1114e+02, -2.4645e+01, -2.0936e+02, -1.4528e+02,\n",
       "         -1.5217e+01, -6.7821e+01, -2.8649e+02, -3.2025e+01, -3.9599e+01,\n",
       "         -2.8217e+02, -3.9599e+01, -3.2025e+01, -2.8649e+02, -6.1862e+01,\n",
       "          5.8680e+01, -1.2127e+02, -8.9990e+01, -4.7383e+01,  5.6195e+01,\n",
       "         -1.9670e+01,  5.3916e+01, -2.1905e+01, -2.3979e+01,  8.4365e+01],\n",
       "        [-9.0737e+01, -8.2141e+00,  1.8435e+01,  4.8170e+01, -4.1254e+01,\n",
       "         -2.2802e+02, -1.9034e+02, -2.5503e+01, -1.9098e+02, -1.9185e+02,\n",
       "         -2.4767e+01, -1.9185e+02, -1.9098e+02, -2.5503e+01, -1.8670e+02,\n",
       "         -2.0945e+02,  4.1963e+00,  5.1351e+01,  7.6705e+01,  1.5329e+02,\n",
       "         -1.5772e+01,  1.3750e+02,  1.0138e+02,  5.1821e+01,  5.6784e+01],\n",
       "        [-1.9427e+02, -9.3319e+01, -8.6999e+01, -7.4099e+01,  1.4269e+01,\n",
       "         -2.6058e+02, -2.3335e+02,  1.5223e+02, -2.2765e+02, -2.2457e+02,\n",
       "          1.5967e+02, -2.2457e+02, -2.2765e+02,  1.5223e+02, -2.1992e+02,\n",
       "         -2.5309e+02,  3.1494e+01, -7.3894e+01,  5.6645e+01,  1.1840e+02,\n",
       "         -4.9226e+00,  1.4450e+02,  3.5715e+01, -1.8686e+01, -6.3116e+01],\n",
       "        [-1.0118e+02, -1.5469e+01, -5.3189e+01, -4.8951e+01, -1.4664e+02,\n",
       "         -3.8039e+02, -2.6164e+02, -8.3566e+01, -2.3841e+02, -2.3828e+02,\n",
       "         -9.4402e+01, -2.3828e+02, -2.3841e+02, -8.3566e+01, -2.4270e+02,\n",
       "         -3.4588e+02, -8.8649e+01,  7.1412e+01, -6.5000e+01, -1.1127e+02,\n",
       "          1.5097e+01,  2.0600e+02,  1.3323e+01,  1.3850e+01,  1.6531e+02],\n",
       "        [-3.4180e+01,  1.0178e+02,  9.5928e+01,  1.2640e+02, -2.8854e+01,\n",
       "         -1.4133e+02, -1.0965e+02, -8.2269e+01, -1.2018e+02, -1.2538e+02,\n",
       "         -8.0476e+01, -1.2538e+02, -1.2018e+02, -8.2269e+01, -9.9499e+01,\n",
       "         -1.0409e+02,  1.2272e-01,  9.2307e+01,  1.0439e+02,  1.5120e+02,\n",
       "         -4.2957e+01,  2.5857e+02,  1.2685e+02,  4.1371e+01,  6.3052e+01],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-8.9948e+01,  7.5621e+00,  6.8850e+00,  1.6208e+00, -7.2264e+01,\n",
       "          3.4406e+01,  5.9855e+01, -1.1907e+02,  1.0299e+02,  9.9488e+01,\n",
       "         -1.1880e+02,  9.9488e+01,  1.0299e+02, -1.1907e+02,  6.8117e+01,\n",
       "          1.0220e+02, -2.6015e+01,  1.5597e+02,  2.9095e+01,  1.2512e+02,\n",
       "         -2.9149e+01,  1.3111e+02,  8.7560e+01, -1.8449e+00,  1.6903e+01],\n",
       "        [-1.1923e+02, -5.9629e+01, -3.5477e+01, -6.2287e+01, -6.7956e+01,\n",
       "         -1.3300e+02, -5.6052e+01, -1.0629e+01, -5.7595e+01, -5.8856e+01,\n",
       "         -2.3312e+01, -5.8856e+01, -5.7595e+01, -1.0629e+01, -4.9471e+01,\n",
       "         -9.8253e+01, -2.9414e+01,  5.3016e+01,  1.4275e+02,  2.0140e+02,\n",
       "          2.5368e+00,  1.6847e+02,  1.6342e+02,  1.0452e+02,  2.9112e+01],\n",
       "        [-1.0361e+02,  4.0324e+00, -5.5896e+01, -3.1929e+01, -1.6995e+02,\n",
       "         -3.7697e+02, -2.4763e+02, -1.1928e+02, -2.2508e+02, -2.2647e+02,\n",
       "         -1.3082e+02, -2.2647e+02, -2.2508e+02, -1.1928e+02, -2.2862e+02,\n",
       "         -3.3967e+02, -1.1422e+02,  6.9952e+01, -5.5981e+01, -9.1695e+01,\n",
       "          7.8900e+00,  2.4858e+02,  3.1941e+01,  1.8945e+01,  1.6882e+02],\n",
       "        [-1.4226e+02, -5.4908e+01, -6.8499e+01, -6.4735e+01, -1.6340e+02,\n",
       "         -4.4183e+02, -2.9454e+02, -6.9716e+01, -2.6782e+02, -2.6787e+02,\n",
       "         -8.3955e+01, -2.6787e+02, -2.6782e+02, -6.9716e+01, -2.7137e+02,\n",
       "         -3.9315e+02, -9.5103e+01,  7.7355e+01, -7.1096e+01, -8.9529e+01,\n",
       "          2.4529e+01,  2.5405e+02,  4.4291e+01,  1.7562e+01,  1.7040e+02],\n",
       "        [-1.1108e+02,  3.0390e+01, -5.2469e+01, -2.3003e+01, -1.5536e+02,\n",
       "         -4.1227e+02, -2.7429e+02, -8.6056e+01, -2.5178e+02, -2.5279e+02,\n",
       "         -9.6545e+01, -2.5279e+02, -2.5178e+02, -8.6056e+01, -2.5256e+02,\n",
       "         -3.7861e+02, -9.3677e+01,  9.3129e+01, -4.9324e+01, -9.2061e+01,\n",
       "         -8.4151e+00,  2.6010e+02,  5.2161e+01,  3.9355e+01,  1.6669e+02],\n",
       "        [-7.8885e+01,  7.2556e+01,  1.0373e+02,  1.1950e+02,  4.8719e+01,\n",
       "         -1.8229e+02, -1.6753e+02,  3.0221e+01, -1.5645e+02, -1.5841e+02,\n",
       "          3.8944e+01, -1.5841e+02, -1.5645e+02,  3.0221e+01, -1.6239e+02,\n",
       "         -1.4762e+02,  7.8007e+01,  1.0311e+02,  1.3401e+02,  2.9438e+02,\n",
       "          1.1596e+00,  2.4554e+02,  1.0706e+02,  4.1670e+01,  5.8804e+01],\n",
       "        [-8.5577e+01,  7.7856e+01,  7.7830e+01,  9.6812e+01,  1.1632e+01,\n",
       "         -1.3842e+02, -7.1884e+01,  4.3793e+01, -6.8222e+01, -7.0802e+01,\n",
       "          3.6130e+01, -7.0802e+01, -6.8222e+01,  4.3793e+01, -5.6561e+01,\n",
       "         -1.1638e+02,  3.1914e+01,  9.5220e+01,  9.6312e+01,  1.5614e+02,\n",
       "          1.2577e+01,  2.0649e+02,  1.5214e+02,  1.2910e+02,  7.2711e+01],\n",
       "        [-1.0135e+02, -1.6294e+01, -4.8141e+01, -4.8663e+01, -1.4256e+02,\n",
       "         -3.7363e+02, -2.5832e+02, -8.1096e+01, -2.3403e+02, -2.3391e+02,\n",
       "         -9.1821e+01, -2.3391e+02, -2.3403e+02, -8.1096e+01, -2.3948e+02,\n",
       "         -3.3739e+02, -8.4727e+01,  7.1776e+01, -6.2586e+01, -1.0329e+02,\n",
       "          1.7177e+01,  2.0523e+02,  1.5350e+01,  1.2151e+01,  1.6419e+02],\n",
       "        [-1.3260e+02, -2.8387e+01, -6.5230e+01, -5.2705e+01, -1.5164e+02,\n",
       "         -4.3932e+02, -2.9490e+02, -5.9763e+01, -2.7242e+02, -2.7222e+02,\n",
       "         -7.2692e+01, -2.7222e+02, -2.7242e+02, -5.9763e+01, -2.7225e+02,\n",
       "         -3.9949e+02, -8.4544e+01,  9.3551e+01, -6.2804e+01, -9.5592e+01,\n",
       "          1.9358e+01,  2.4522e+02,  5.0873e+01,  2.9236e+01,  1.6399e+02],\n",
       "        [-1.0237e+02,  4.4220e+01,  8.6363e+01,  1.0266e+02,  1.9387e+01,\n",
       "         -1.3108e+02, -7.1542e+01,  5.0727e+01, -6.4031e+01, -6.5911e+01,\n",
       "          4.5624e+01, -6.5911e+01, -6.4031e+01,  5.0727e+01, -6.0926e+01,\n",
       "         -1.0589e+02,  4.6251e+01,  1.0855e+02,  1.2764e+02,  2.0013e+02,\n",
       "          2.7195e+01,  2.0535e+02,  1.6045e+02,  1.2593e+02,  5.8524e+01],\n",
       "        [-1.3655e+02,  6.8165e+01,  1.0329e+02,  7.6790e+01,  3.6032e+01,\n",
       "         -1.3517e+02, -1.0807e+02,  3.8384e+01, -8.4419e+01, -8.5665e+01,\n",
       "          4.3706e+01, -8.5665e+01, -8.4419e+01,  3.8384e+01, -8.7900e+01,\n",
       "         -9.9855e+01,  4.2566e+01,  2.2205e+01,  5.3401e+01,  1.1180e+02,\n",
       "          8.2422e+01,  2.0126e+02,  6.4928e+01,  7.1562e+01,  8.7769e+01],\n",
       "        [ 6.9156e+01, -7.7571e+00,  2.0306e+02,  3.8969e+01,  6.6164e+01,\n",
       "          1.7069e+02,  5.3064e+01, -4.5214e+01,  9.8600e+01,  9.0422e+01,\n",
       "         -4.2173e+01,  9.0422e+01,  9.8600e+01, -4.5214e+01,  4.0607e+01,\n",
       "          2.4738e+02,  1.2399e+02,  4.4344e+01,  1.7271e+02,  2.4028e+02,\n",
       "          5.4295e+01,  1.0368e+02,  6.2485e+01,  3.5069e+01,  9.9739e+01],\n",
       "        [-4.8806e+01,  1.2745e+02,  8.5013e+01,  1.6420e+02,  1.8269e+01,\n",
       "         -1.2526e+02, -6.7990e+01,  2.9985e+01, -6.0364e+01, -6.3572e+01,\n",
       "          2.8890e+01, -6.3572e+01, -6.0364e+01,  2.9985e+01, -5.5506e+01,\n",
       "         -1.0067e+02,  5.0763e+01,  2.1775e+02,  9.6130e+01,  1.8065e+02,\n",
       "         -3.5103e+01,  2.1741e+02,  1.9373e+02,  1.2703e+02,  5.9381e+01],\n",
       "        [ 1.3419e+01,  1.7614e+02,  2.3679e+02,  3.0860e+02,  2.7714e+01,\n",
       "         -1.3887e+02, -7.2370e+01, -6.2119e+01, -8.8330e+01, -9.7444e+01,\n",
       "         -6.0173e+01, -9.7444e+01, -8.8330e+01, -6.2119e+01, -6.4899e+01,\n",
       "         -8.9064e+01,  7.9825e+01,  2.6198e+02,  1.9640e+02,  1.9484e+02,\n",
       "         -2.9178e+01,  3.4556e+02,  1.9628e+02,  1.3766e+02,  1.3186e+02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[torch.randperm(M.size()[0])].detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 1.0542e-06, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 1.5957e+05, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 4.0323e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 6.0959e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 2.1699e+05, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 6.0959e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5044e+00, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.4005e+03, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1949e-01],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.3267e-03, 3.9987e-02, 1.7760e+05, 3.9973e+05, 3.3471e+03,\n",
       "         4.0000e+05, 3.9179e-02, 4.0000e+05, 4.0000e+05, 1.8434e-07, 4.0000e+05,\n",
       "         4.0000e+05, 3.9179e-02, 4.0000e+05, 1.0009e+00, 4.0000e-02, 9.9163e-01,\n",
       "         4.0000e+05, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e+05, 2.5068e-07, 3.9987e-02, 1.6759e+00, 2.7162e+02, 3.9665e+05,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0405e-07, 1.2991e+02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-01, 4.0000e-02, 5.2211e-02, 1.7043e+01,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 3.5173e-08, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8538e-02, 2.5068e-07, 3.9646e+05, 5.2613e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-02, 2.4148e-08, 4.0000e-02, 2.9952e-01, 1.7043e-06,\n",
       "         2.1951e-08],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 4.0000e-02, 4.0000e-02, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 4.0000e-02, 1.8434e-07, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e-02, 4.0000e-02, 1.0009e-07, 4.0000e-02, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 2.3442e+04, 3.5173e-08, 1.7043e-06,\n",
       "         1.4761e-05],\n",
       "        [1.8529e-02, 2.5068e-07, 3.9987e-02, 2.2240e+05, 9.4280e-01, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e+05, 4.0000e-02, 4.0000e-02, 1.8434e+00, 4.0000e-02,\n",
       "         4.0000e-02, 3.9179e+05, 4.0000e-02, 1.0009e-07, 3.9987e+05, 9.9163e-08,\n",
       "         4.0000e-02, 9.5670e-09, 2.4148e-08, 4.0000e-02, 5.9244e-08, 1.7043e-06,\n",
       "         2.1951e-08]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.T / attn.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-16-bfc19aa26183>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-bfc19aa26183>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (attn / attn.sum(axis = 0)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "(attn / attn.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3970e-06, 3.9892e-01, 2.5008e-06, 2.5000e-06, 2.5000e-06, 2.5000e-06,\n",
       "        2.5000e-06, 2.5524e-06, 2.5000e-06, 2.5000e-06, 5.4248e-01, 2.5000e-06,\n",
       "        2.5000e-06, 2.5524e-06, 2.5000e-06, 9.9907e-01, 2.5000e-06, 1.0084e+00,\n",
       "        2.5000e-06, 1.0453e+01, 4.1411e+00, 2.5000e-06, 2.8431e+00, 5.8674e-02,\n",
       "        4.5557e+00], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): None\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.ModuleList([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
