{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from otgnn.models import GCN\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, get_latest_model\n",
    "from mol_opt.ot_utils import compute_barycenter\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/octav/gitrepos/tum-thesis'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"val\", 48, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "1121\n",
      "26779\n",
      "1022\n",
      "22052\n"
     ]
    }
   ],
   "source": [
    "for i in data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break\n",
    "    \n",
    "print(len(X.mols))\n",
    "print(sum([y for (_, y) in X.scope]))\n",
    "print(sum([y**2 for (_, y) in X.scope]))\n",
    "print(sum([y for (_, y) in Y.scope]))\n",
    "print(sum([y**2 for (_, y) in Y.scope]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\", \"-cuda\", \"-pred_hidden\", \"150\"]\n",
    "args = get_args()\n",
    "args.output_dir = \"mol_opt/output/\"\n",
    "# args.device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(args).to(args.device)\n",
    "opt = torch.nn.Linear(50, 50).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (W_message_i): Linear(in_features=100, out_features=50, bias=False)\n",
       "  (W_message_h): Linear(in_features=50, out_features=50, bias=False)\n",
       "  (W_message_o): Linear(in_features=143, out_features=50, bias=True)\n",
       "  (W_mol_h): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
       "  (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (W_message_i): Linear(in_features=100, out_features=50, bias=False)\n",
       "  (W_message_h): Linear(in_features=50, out_features=50, bias=False)\n",
       "  (W_message_o): Linear(in_features=143, out_features=50, bias=True)\n",
       "  (W_mol_h): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
       "  (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0079,  0.0743, -0.1079,  ...,  0.1204,  0.2161,  0.1556],\n",
       "        [ 0.0249,  0.0846, -0.0451,  ...,  0.0463,  0.1724,  0.2085],\n",
       "        [-0.0030,  0.1260,  0.0180,  ...,  0.1078,  0.1869,  0.1830],\n",
       "        ...,\n",
       "        [ 0.0186,  0.0592, -0.0904,  ...,  0.1361,  0.2348,  0.1759],\n",
       "        [ 0.0481,  0.1973, -0.1271,  ...,  0.0720,  0.2060,  0.1390],\n",
       "        [ 0.0014,  0.1280, -0.1103,  ...,  0.0922,  0.2469,  0.1206]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt(gcn.forward(Y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedding = gcn.forward(X)[0]\n",
    "stx, lex = X.scope[0]\n",
    "x1 = x_embedding.narrow(0, stx, lex).view(lex, 1, -1).repeat(1, lex, 1)\n",
    "x2 = x_embedding.narrow(0, stx, lex).view(1, lex, -1).repeat(lex, 1, 1)\n",
    "_bonds = torch.cat((x1, x2), dim = 2)\n",
    "# bonds_logits = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctions.cat>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  18   42   61   87  106  130  150  167  187  212  237  262  286  308\n",
      "  331  353  375  394  418  437  457  477  500  526  552  575  598  622\n",
      "  643  663  688  711  735  757  778  799  816  842  862  884  905  929\n",
      "  950  969  993 1017 1039 1061]\n"
     ]
    }
   ],
   "source": [
    "print (np.cumsum(([len(x.atoms) for x in X.mols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.mols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.atoms[0].symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-49b019ba4585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbonds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbond_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.bonds[0].bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.pred_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolOpt(\n",
       "  (GCN): GCN(\n",
       "    (W_message_i): Linear(in_features=100, out_features=50, bias=False)\n",
       "    (W_message_h): Linear(in_features=50, out_features=50, bias=False)\n",
       "    (W_message_o): Linear(in_features=143, out_features=50, bias=True)\n",
       "    (W_mol_h): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
       "    (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (opt0): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (opt1): Linear(in_features=50, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mol_opt import mol_opt\n",
    "molopt = mol_opt.MolOpt(args).to(device = args.device)\n",
    "molopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# molopt.align(molopt.encode(X), X, molopt.encode(Y), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1920, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding = molopt.encode(X)\n",
    "x_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5640e-01,  2.1761e-01,  1.8304e-01, -1.6272e-01,  3.1493e-02,\n",
       "          1.1379e-01,  2.1669e-02,  1.8854e-01, -2.9571e-01,  1.8985e-02,\n",
       "         -1.4275e-01,  1.9132e-01,  2.1506e-02,  6.2977e-02, -5.7108e-02,\n",
       "          4.4616e-02,  1.1306e-01, -2.1863e-01, -1.5550e-02, -4.0034e-01,\n",
       "          1.6929e-01,  1.9568e-01, -1.9850e-01, -2.8040e-02,  5.4685e-02,\n",
       "         -1.1141e-01, -2.1223e-01, -1.0030e-01, -1.0619e-01, -1.0559e-01,\n",
       "         -1.7550e-01, -1.1165e-01,  1.1228e-01, -1.1534e-02,  3.5927e-01,\n",
       "         -7.8190e-02, -2.3244e-01, -1.4523e-01,  1.9819e-01,  1.3657e-01,\n",
       "         -3.0067e-01,  7.3870e-03, -8.7360e-02,  2.0422e-01, -2.5709e-01,\n",
       "         -9.0651e-02,  9.8129e-03,  1.8269e-01, -2.4321e-01,  6.7296e-02],\n",
       "        [-1.0911e-01, -6.2154e-02, -1.5407e-02,  3.6712e-02,  7.0942e-03,\n",
       "          3.2297e-01, -1.5229e-01, -3.8390e-02, -1.7681e-01,  7.7100e-03,\n",
       "         -1.1580e-01, -2.4396e-02,  1.2572e-01,  2.1479e-01, -1.9864e-01,\n",
       "         -1.0103e-02, -5.2607e-02,  9.6390e-03,  6.6661e-02, -4.7251e-02,\n",
       "         -1.5850e-01, -2.7588e-01,  1.3299e-01,  2.1025e-03,  2.0830e-01,\n",
       "          6.0250e-03,  1.6008e-01,  5.2883e-02,  1.4305e-01,  8.6633e-02,\n",
       "          2.5166e-01,  1.9571e-02,  1.9573e-02,  4.1518e-02,  2.3609e-02,\n",
       "         -1.7345e-01, -4.8554e-03,  2.0607e-01,  6.0206e-02,  2.1392e-01,\n",
       "          5.9915e-02,  9.4265e-03,  1.0843e-02,  1.7436e-01, -1.2111e-01,\n",
       "          2.2889e-01,  7.6562e-02,  2.7534e-01,  1.4971e-01,  1.8806e-01],\n",
       "        [-1.0831e-02, -4.3316e-02, -1.6870e-01, -2.2552e-02,  1.8214e-01,\n",
       "          6.0647e-02, -8.6588e-03, -7.6079e-02, -7.5269e-02,  1.3990e-01,\n",
       "          3.8334e-02,  1.1631e-01,  4.8579e-02, -1.2553e-01, -2.8256e-03,\n",
       "          6.5367e-03, -1.6423e-01,  3.5573e-02, -1.5745e-01,  8.2272e-02,\n",
       "         -9.6397e-02,  1.5564e-01, -6.6697e-02,  1.0046e-01, -2.8013e-01,\n",
       "          1.2895e-01,  4.1876e-02, -1.0374e-01,  1.1683e-01, -2.9021e-03,\n",
       "          1.0981e-01, -4.5815e-02, -1.3971e-01, -1.7487e-01, -2.4298e-01,\n",
       "          2.6542e-01,  1.6492e-01, -1.0545e-01, -5.9401e-02, -1.2720e-01,\n",
       "          3.7333e-02, -3.3622e-02,  2.0657e-01,  2.9031e-01, -1.3922e-01,\n",
       "          8.0986e-02, -2.0904e-01, -1.8174e-03,  2.6203e-01, -3.9934e-02],\n",
       "        [ 5.5969e-02, -1.7304e-02,  2.8701e-01,  6.5290e-02, -1.2983e-01,\n",
       "         -5.8773e-02,  2.7019e-01, -6.9833e-02,  2.1756e-01, -1.1078e-01,\n",
       "         -9.2979e-02,  4.1456e-01,  4.8478e-02, -2.7874e-01, -8.7170e-02,\n",
       "         -6.7306e-03,  1.2271e-01, -3.8919e-01, -8.1506e-02, -2.2377e-02,\n",
       "         -5.1644e-02,  2.6297e-02,  4.1636e-01, -8.1455e-02, -3.7363e-02,\n",
       "          2.1667e-01, -1.9554e-02, -1.1175e-01,  1.9383e-01, -1.3175e-01,\n",
       "         -4.0334e-02, -1.7711e-01,  2.5084e-01,  5.1068e-02,  8.2362e-02,\n",
       "         -9.5328e-02,  2.0026e-01, -5.2717e-02,  1.3635e-01, -1.7000e-01,\n",
       "          1.7796e-01, -1.4802e-01, -1.8900e-02,  1.5135e-01, -1.7312e-02,\n",
       "          1.2624e-01, -1.0343e-01,  9.7722e-03,  1.1169e-01,  1.0208e-01],\n",
       "        [ 2.7095e-02, -2.0494e-01, -2.6822e-02,  9.9499e-02, -6.4899e-03,\n",
       "         -2.9761e-01,  2.1911e-01,  7.2222e-03,  1.6273e-01,  5.7817e-02,\n",
       "          1.9617e-01,  1.9332e-01,  9.6891e-02, -1.6897e-01, -2.1162e-01,\n",
       "         -1.7789e-03, -1.8713e-01,  3.8100e-02,  1.4493e-01,  8.2834e-02,\n",
       "         -1.1563e-01,  9.0357e-02, -5.6276e-02, -1.0765e-01,  1.3725e-01,\n",
       "          6.2723e-02,  1.4987e-01,  3.3882e-02, -2.2855e-01,  1.1819e-02,\n",
       "         -1.1915e-02, -2.2448e-01,  1.2198e-01,  1.9771e-01,  4.1608e-02,\n",
       "          7.7108e-02,  5.8588e-02, -1.4516e-01,  1.1226e-01,  6.5119e-02,\n",
       "          1.4086e-01, -1.8801e-01, -5.6396e-01, -1.1023e-01,  6.3878e-02,\n",
       "         -1.2816e-01,  9.1863e-02, -1.6933e-01, -7.4478e-02,  5.4711e-03],\n",
       "        [-1.1131e-01, -3.4225e-02, -2.0276e-01, -1.6488e-01,  1.6596e-01,\n",
       "         -2.7691e-02, -5.0394e-02, -1.8704e-01, -1.6478e-01, -2.6920e-02,\n",
       "          4.3695e-01, -4.1490e-02,  3.8289e-04,  1.0524e-01,  3.0229e-01,\n",
       "          1.0304e-01,  1.2153e-01,  1.7544e-01,  2.9635e-01, -1.3980e-01,\n",
       "         -1.3036e-01, -1.0548e-01, -1.0495e-02, -7.3493e-02, -3.5838e-02,\n",
       "         -2.8186e-01,  1.5751e-01,  1.2217e-01,  1.2944e-01,  1.3715e-01,\n",
       "          2.2362e-01, -6.3197e-02, -4.8308e-02,  1.9093e-02,  1.7409e-01,\n",
       "         -8.8596e-03,  1.9141e-01,  3.6549e-02, -3.4685e-02, -2.0662e-01,\n",
       "         -1.6170e-01,  2.2200e-01,  1.1554e-01,  1.4432e-01,  1.5372e-01,\n",
       "          1.4130e-01,  5.8230e-02,  1.4596e-01,  1.9265e-01, -8.3019e-04],\n",
       "        [ 1.2629e-01, -4.0466e-02, -3.2189e-01,  1.9926e-01,  1.5344e-01,\n",
       "         -4.5582e-02, -2.0496e-02, -1.4376e-01,  5.3197e-02, -7.5516e-02,\n",
       "         -2.9681e-01, -3.5868e-02, -6.7162e-02,  8.7244e-02, -1.5461e-01,\n",
       "         -2.4936e-02, -4.1681e-01,  1.0744e-01,  1.8119e-01, -8.2335e-02,\n",
       "         -9.3758e-02,  2.3992e-01, -2.2354e-02, -2.9209e-01, -1.0802e-02,\n",
       "          1.7148e-01, -2.1541e-01, -9.4338e-02,  1.4589e-02, -5.5751e-04,\n",
       "         -1.5281e-01, -2.2458e-02, -1.8543e-01, -2.9435e-01, -7.9481e-02,\n",
       "          1.4583e-01, -3.6081e-02,  2.5768e-01,  1.9958e-01,  8.1467e-02,\n",
       "          3.3483e-02, -1.4871e-01, -4.7844e-02, -3.0078e-01,  2.5541e-01,\n",
       "         -9.1983e-03,  2.3358e-01,  3.0581e-01, -1.1958e-01,  2.5542e-01],\n",
       "        [-1.9054e-01, -1.3069e-01,  2.1198e-01, -4.1632e-02, -2.2249e-01,\n",
       "          1.5208e-01,  4.6670e-02, -1.4426e-02, -5.6422e-02,  5.2943e-02,\n",
       "          4.2615e-02,  1.7730e-01, -4.3367e-01, -6.3512e-02,  4.1718e-03,\n",
       "         -4.9344e-03, -6.5851e-02,  9.2521e-02, -8.0425e-02,  2.8063e-01,\n",
       "          1.2798e-01,  1.3305e-01,  7.6906e-02,  2.3257e-02,  2.1618e-02,\n",
       "         -2.5362e-01, -6.4445e-02,  1.3156e-01,  5.7836e-02,  2.0347e-01,\n",
       "         -1.0741e-02,  2.3972e-01,  1.3796e-01, -6.4547e-02, -2.6716e-01,\n",
       "         -7.9854e-02, -4.7124e-02, -2.9456e-01,  4.9940e-02,  8.2509e-03,\n",
       "         -1.6878e-01, -1.6583e-01, -6.4125e-02,  2.8822e-01, -1.6078e-01,\n",
       "         -9.2027e-02, -3.8322e-01,  1.1113e-01, -2.6801e-01, -6.3078e-02],\n",
       "        [ 1.9198e-02, -1.8056e-01, -2.1236e-02, -3.8057e-01, -1.6054e-01,\n",
       "         -1.3682e-01, -1.1786e-01,  1.1262e-02, -3.0660e-01, -1.9652e-02,\n",
       "         -7.3865e-02, -6.5801e-02, -4.6750e-02,  9.4870e-02, -5.5525e-02,\n",
       "          4.4838e-01,  1.0265e-02, -2.2685e-01,  3.1261e-02,  2.2903e-01,\n",
       "         -1.5888e-01, -1.4524e-02,  1.0003e-01,  1.1670e-02, -7.1395e-02,\n",
       "          1.0085e-01,  2.0613e-01,  4.1360e-02,  9.0561e-02,  4.8348e-02,\n",
       "          1.4735e-01,  1.1534e-01,  2.3905e-01, -8.4306e-02, -1.3574e-01,\n",
       "          3.7581e-02, -3.7085e-03, -1.7195e-01, -1.6020e-01,  3.4014e-02,\n",
       "          5.9953e-02, -8.0021e-02,  3.2001e-01,  4.1931e-02,  2.8655e-01,\n",
       "          2.7431e-02,  1.9025e-01,  2.2938e-01,  6.3074e-02,  7.8517e-03],\n",
       "        [-1.0429e-01,  5.7616e-02,  1.1904e-01,  3.2784e-03, -2.0349e-02,\n",
       "          7.9756e-03,  3.4478e-02,  7.0878e-02, -4.4271e-02,  3.4805e-01,\n",
       "         -3.3105e-02,  5.1863e-02, -4.4768e-02, -1.6952e-02,  1.9409e-02,\n",
       "         -3.4282e-01, -1.4394e-02,  1.4290e-01,  2.7273e-01,  2.0197e-01,\n",
       "         -3.1680e-01,  1.4087e-02, -3.0632e-02, -6.9473e-02,  1.3967e-01,\n",
       "          7.7001e-02, -9.2618e-02, -1.5170e-02, -5.1995e-02, -4.2858e-02,\n",
       "         -1.2209e-01,  1.1089e-01, -2.5535e-01, -1.8599e-01,  7.6844e-02,\n",
       "         -3.6345e-01,  1.8477e-01,  5.1028e-02, -1.3162e-01, -1.6439e-01,\n",
       "         -2.8466e-01, -5.5827e-02,  2.6038e-01,  1.6533e-02, -3.1360e-01,\n",
       "         -3.5772e-01, -3.3793e-02,  1.8213e-02, -7.0903e-02,  1.3018e-01],\n",
       "        [-9.0699e-02,  4.9925e-02,  1.1208e-01,  1.5734e-01,  1.5499e-02,\n",
       "         -2.3354e-01,  8.9323e-02,  2.9953e-02, -2.2027e-01, -6.9525e-02,\n",
       "         -5.7843e-02,  1.1929e-01, -2.0928e-02, -5.2179e-02,  1.9214e-01,\n",
       "          2.5933e-01, -7.9483e-02, -4.3948e-01, -2.4754e-01,  3.2698e-01,\n",
       "          2.6275e-01,  1.0404e-01, -2.5350e-01,  8.2421e-02, -1.3745e-01,\n",
       "         -3.3463e-01,  1.3150e-01, -6.6915e-02,  6.6520e-02, -7.4491e-02,\n",
       "          1.7482e-01, -1.2589e-03,  5.0497e-02,  1.4489e-01,  1.0999e-01,\n",
       "         -1.7332e-01,  1.4629e-01,  2.5950e-01,  1.5900e-01,  1.5187e-02,\n",
       "          2.0764e-01, -8.1328e-02,  1.3571e-01, -3.5422e-01,  2.8886e-01,\n",
       "          5.0163e-02, -1.7518e-01,  2.3363e-01,  8.8050e-02,  7.1257e-02],\n",
       "        [-9.0195e-02, -3.4483e-02,  3.6204e-02, -1.8957e-01, -3.3531e-02,\n",
       "          1.7922e-01,  9.6204e-03,  4.1557e-01,  8.4483e-02, -1.5896e-01,\n",
       "         -1.3663e-01, -1.7291e-02,  5.9737e-02,  9.4934e-02,  1.4360e-01,\n",
       "          2.2707e-01, -2.2012e-01, -4.0591e-02, -1.3409e-01,  5.8159e-02,\n",
       "          7.7868e-02, -2.3451e-01,  6.5063e-02,  9.3077e-02,  2.2310e-02,\n",
       "         -6.5024e-02, -8.7740e-02,  2.3246e-01,  4.7609e-02, -1.6249e-01,\n",
       "          7.9175e-02,  6.5378e-02, -3.6271e-02,  5.0306e-02, -7.6449e-02,\n",
       "         -1.9526e-01, -2.5360e-01, -1.5033e-01,  4.7147e-02, -4.4017e-02,\n",
       "          1.2865e-01, -7.2954e-02,  3.4789e-01,  8.1615e-02,  6.5311e-02,\n",
       "         -4.9613e-02,  3.1302e-01, -1.1711e-01, -1.5658e-01,  1.5902e-01],\n",
       "        [ 1.1048e-01, -5.7045e-02,  1.1458e-01,  6.8174e-02,  2.2355e-01,\n",
       "         -6.3964e-03,  2.2334e-02, -1.5002e-02, -4.4406e-02,  2.5146e-01,\n",
       "          1.7842e-02, -2.3721e-01, -4.4251e-03,  1.1768e-01, -1.6548e-01,\n",
       "          2.6737e-01, -2.0054e-01, -1.7840e-01, -7.1140e-02, -9.7280e-03,\n",
       "          5.5886e-02,  3.9719e-02, -5.7197e-02,  2.7892e-02, -1.8139e-01,\n",
       "         -8.1075e-02, -7.8157e-02,  1.6264e-02,  8.9523e-02,  3.9845e-01,\n",
       "          2.7991e-02,  1.9459e-01,  1.5299e-01,  1.6824e-01, -1.0373e-02,\n",
       "          4.4800e-02, -1.8026e-01,  1.0142e-01,  1.2402e-01, -3.0477e-02,\n",
       "         -2.5182e-03, -2.7186e-01, -1.0950e-01,  7.4643e-02, -3.8427e-01,\n",
       "          6.6424e-02,  7.8525e-02, -4.1974e-02, -2.4458e-01,  8.5675e-02],\n",
       "        [ 2.0078e-02,  6.0726e-02, -2.7170e-01, -3.1097e-02, -1.7568e-02,\n",
       "          5.8600e-03,  1.9978e-01, -3.5327e-01, -8.8409e-02,  2.4081e-02,\n",
       "          4.3991e-01,  1.4889e-02,  1.3062e-01,  8.1750e-02, -3.4180e-02,\n",
       "          6.3893e-02,  2.1645e-01, -9.9467e-02, -2.8710e-01,  2.5546e-02,\n",
       "          1.9555e-01,  9.6160e-02, -2.7896e-02,  3.5089e-02,  2.9856e-01,\n",
       "          5.7615e-02,  3.2264e-02,  3.7868e-02, -9.3606e-02,  4.4866e-02,\n",
       "         -1.1977e-01,  2.2386e-01, -1.4473e-02, -9.4657e-02,  2.0404e-01,\n",
       "          8.2078e-02,  1.1286e-01, -7.3118e-02,  1.8860e-01, -3.7399e-01,\n",
       "          1.7072e-01,  1.8265e-01,  1.6649e-02, -2.9710e-01,  2.8844e-01,\n",
       "          5.4426e-02, -8.4817e-02, -2.4757e-02,  1.5363e-01,  1.3487e-01],\n",
       "        [ 1.0766e-01, -1.8940e-01,  2.2178e-01,  2.1235e-01,  6.4311e-02,\n",
       "         -1.3090e-01, -2.3082e-01, -1.7450e-01,  6.9012e-02,  3.9501e-01,\n",
       "         -3.0601e-02,  3.4329e-01, -9.4984e-02, -2.0436e-02, -4.9618e-02,\n",
       "          7.7084e-02, -4.7247e-02, -1.2733e-01,  5.7002e-02,  1.8293e-01,\n",
       "         -1.1204e-01,  2.7652e-01,  9.7843e-02, -1.4599e-01, -1.2737e-01,\n",
       "         -1.5247e-01, -1.8713e-01, -5.8871e-02, -1.6024e-01,  1.2247e-01,\n",
       "          6.0169e-03, -3.5551e-01, -1.0420e-01, -9.1446e-02, -2.0315e-01,\n",
       "          2.4187e-01, -3.2548e-01,  8.6980e-02, -1.4149e-01, -1.0485e-01,\n",
       "          6.9278e-02,  1.8087e-01,  9.0135e-02,  6.5691e-02, -3.6296e-02,\n",
       "         -5.7098e-02, -2.5319e-02, -2.4640e-01, -1.8713e-01,  1.8514e-01],\n",
       "        [-1.1799e-02, -2.7331e-02,  1.7170e-01,  1.6363e-01, -3.0370e-01,\n",
       "          4.0460e-02, -1.8243e-01, -8.3257e-03, -1.9030e-01, -3.9450e-02,\n",
       "         -1.9801e-01,  1.0731e-01, -1.0456e-02,  9.2944e-02,  6.2580e-03,\n",
       "          2.1944e-03,  1.8540e-03, -6.7067e-02, -1.0172e-01, -1.9056e-01,\n",
       "          2.0643e-02, -2.7641e-01,  7.7665e-02, -2.4776e-01,  1.4495e-01,\n",
       "          2.8197e-01,  8.4384e-02, -9.7529e-02,  7.4707e-02,  3.6470e-02,\n",
       "          1.0396e-01,  5.6787e-02, -9.8402e-02,  1.1298e-02, -9.9045e-02,\n",
       "         -4.1016e-02,  6.5595e-02, -8.3593e-02,  1.3898e-01,  2.2821e-01,\n",
       "         -1.1492e-01, -2.8532e-01,  9.2317e-02, -1.6652e-02,  8.8019e-02,\n",
       "         -5.1491e-02,  1.4951e-02,  9.2574e-02, -1.4206e-01, -3.6619e-02],\n",
       "        [-9.7017e-02,  3.3757e-01,  1.5908e-01,  1.7843e-01,  2.4904e-02,\n",
       "          2.0603e-01, -3.2154e-01, -3.7857e-01,  3.1388e-02, -3.2093e-01,\n",
       "         -5.3272e-02, -3.7811e-01, -1.3541e-01,  3.7372e-02,  1.8258e-01,\n",
       "         -2.5816e-01, -1.4551e-02, -1.1638e-01,  1.5556e-01,  7.8847e-02,\n",
       "          4.1561e-03, -2.0657e-02, -1.1900e-01,  2.0637e-01, -3.6894e-02,\n",
       "          2.0613e-01, -1.9677e-02, -2.0981e-01, -2.8522e-02, -4.4358e-02,\n",
       "          1.9613e-02,  2.5892e-01,  1.8591e-01,  1.8430e-01,  1.9851e-01,\n",
       "         -6.9715e-02, -2.3228e-03, -1.7427e-01, -4.5907e-02, -2.7960e-01,\n",
       "          3.7244e-02,  8.6961e-03,  3.9513e-02,  3.0391e-02,  3.3537e-01,\n",
       "         -8.4482e-02,  4.9536e-02, -2.7162e-01, -7.8700e-03,  9.8835e-02],\n",
       "        [-8.7844e-02, -7.1917e-02, -1.4108e-01,  3.6692e-02, -6.6867e-02,\n",
       "         -1.0407e-01, -5.5402e-02, -2.0596e-01, -9.5471e-02,  1.5420e-01,\n",
       "         -3.0493e-01, -4.3120e-02, -1.5620e-01,  1.2651e-01, -4.0480e-02,\n",
       "         -6.8612e-02,  3.0193e-02, -2.1032e-01,  9.5811e-02, -1.1343e-01,\n",
       "         -1.7283e-01, -2.4365e-01, -3.7248e-02, -1.3440e-01, -4.6826e-02,\n",
       "          8.0616e-02, -1.3150e-01,  6.1084e-02, -1.5005e-01,  1.8258e-02,\n",
       "         -6.1471e-02,  1.0757e-02,  8.2986e-02, -3.1237e-02,  1.2553e-01,\n",
       "          3.8797e-02,  1.6607e-02,  1.4912e-01,  2.4644e-01, -4.7148e-03,\n",
       "          3.3307e-01, -1.9206e-01,  1.3927e-01, -2.9169e-01, -2.3673e-02,\n",
       "         -2.5201e-01, -2.2559e-01, -1.6343e-02, -5.5461e-02,  2.3971e-01],\n",
       "        [-3.5099e-01, -1.9557e-02,  8.3110e-02,  1.4398e-01, -1.9319e-01,\n",
       "          2.1028e-01, -2.2583e-02,  4.6814e-02, -4.8843e-02,  6.7906e-04,\n",
       "         -1.1462e-01, -2.0513e-01, -1.8698e-01, -9.1411e-02,  2.7471e-01,\n",
       "         -2.1816e-02,  5.0158e-02, -1.0106e-01, -2.1911e-01, -3.7270e-02,\n",
       "          3.4099e-01,  4.6468e-02,  1.8288e-01, -1.2008e-01, -1.6333e-01,\n",
       "          7.5326e-02,  2.5381e-02,  1.3945e-01, -9.1095e-02, -8.5468e-02,\n",
       "         -1.1101e-01, -6.8078e-02,  2.0190e-01, -2.6754e-01,  1.0430e-01,\n",
       "         -1.6844e-01,  3.8783e-02, -1.3465e-01, -1.1647e-01,  7.5628e-02,\n",
       "          2.3367e-03,  1.5204e-01,  3.3400e-02,  4.3799e-02,  7.1250e-02,\n",
       "          1.7895e-01,  1.4355e-01,  6.4037e-02,  1.8570e-01, -8.7529e-03],\n",
       "        [-2.5471e-01, -2.1930e-01, -2.3837e-02, -3.4714e-01,  2.6849e-01,\n",
       "         -5.3797e-02, -2.0430e-01, -1.6616e-01,  2.1518e-02,  2.6881e-01,\n",
       "          1.9603e-01, -1.4100e-01,  1.2853e-01, -6.1967e-02,  6.3137e-02,\n",
       "         -1.6024e-01, -3.2593e-02,  8.6308e-02, -6.5492e-03, -1.1180e-01,\n",
       "         -1.5157e-01, -1.8908e-01, -1.6353e-02,  7.1155e-02, -7.1490e-02,\n",
       "         -1.4398e-01, -4.1508e-01, -2.6080e-02, -1.2737e-01, -1.9621e-01,\n",
       "          2.1750e-01,  2.0578e-01, -7.5281e-02,  2.2800e-01,  1.6345e-01,\n",
       "         -1.5670e-01,  1.2478e-01, -1.9851e-01,  2.6503e-01, -2.3284e-01,\n",
       "         -1.6702e-01, -1.3505e-01, -9.8019e-02,  5.3381e-02, -1.2267e-01,\n",
       "         -1.8758e-02, -3.9942e-02, -1.4486e-01,  3.1044e-02,  6.1762e-02]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mol_opt.ot_utils import compute_barycenter\n",
    "compute_barycenter(x_embedding.narrow(0,0,20), 20, num_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35099155 -0.25470862 -0.19054031 -0.11130951 -0.10911432 -0.10428502\n",
      " -0.09701747 -0.09069885 -0.0901949  -0.08784354 -0.01179874 -0.01083078\n",
      "  0.01919781  0.02007846  0.02709519  0.05596866  0.1076645   0.11048253\n",
      "  0.12628663  0.15640064]\n",
      "[-0.35099155 -0.25470862 -0.19054031 -0.11130951 -0.10911432 -0.10428501\n",
      " -0.09701747 -0.09069885 -0.0901949  -0.08784354 -0.01179874 -0.01083078\n",
      "  0.01919781  0.02007846  0.02709519  0.05596866  0.1076645   0.11048252\n",
      "  0.12628663  0.15640062]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8273868e-08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these numbers should all be very small\n",
    "# that means that the computation converged\n",
    "xhat = np.sort(compute_barycenter(x_embedding.narrow(0,0,20), 20, num_iters=50)[:,0].cpu().detach().numpy())\n",
    "xreal = np.sort(x_embedding.narrow(0,0,20)[:,0].cpu().detach().numpy())\n",
    "print (xhat)\n",
    "print (xreal)\n",
    "np.linalg.norm(xhat - xreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolOptDecoder(\n",
       "  (fc1_SYMBOLS): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc2_SYMBOLS): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (fc1_CHARGES): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc2_CHARGES): Linear(in_features=100, out_features=5, bias=True)\n",
       "  (fc1_BONDS): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2_BONDS): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mol_opt.decoder_mol_opt import MolOptDecoder\n",
    "molopt_decoder = MolOptDecoder(args).to(device = args.device)\n",
    "molopt_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = molopt_decoder.forward(x_embedding, Y)\n",
    "res_discrete = molopt_decoder.discretize(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([54, 29, 54,  ..., 19, 29, 29], device='cuda:0',\n",
       "        grad_fn=<NotImplemented>),\n",
       " tensor([4, 4, 4,  ..., 4, 4, 4], device='cuda:0', grad_fn=<NotImplemented>),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0', grad_fn=<NotImplemented>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mol_opt.ot_utils import encode_target\n",
    "encode_target(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: mol_opt/output//model_test\n"
     ]
    }
   ],
   "source": [
    "save_model(molopt, args, args.output_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mol_opt/output/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(args.n_epochs):\n",
    "#     start = time.time()\n",
    "#     for idx, i in enumerate(data_loader):\n",
    "#         X = (MolGraph(i[0]))\n",
    "#         Y = (MolGraph(i[1]))\n",
    "# \n",
    "#         # create your optimizer\n",
    "#         optimizer = torch.optim.SGD(molopt.parameters(), lr=0.01)\n",
    "# \n",
    "#         # in your training loop:\n",
    "#         optimizer.zero_grad()   # zero the gradient buffers\n",
    "#         loss = molopt.forward_train(X, Y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()    # Does the update\n",
    "# \n",
    "#         print (\"Iter: {}, loss: {}\".format(idx, loss.item()))\n",
    "#     end = time.time()\n",
    "#     print(\"Time for epoch {}: {}\", epoch, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 18),\n",
       " (18, 24),\n",
       " (42, 19),\n",
       " (61, 26),\n",
       " (87, 19),\n",
       " (106, 24),\n",
       " (130, 20),\n",
       " (150, 17),\n",
       " (167, 20),\n",
       " (187, 25),\n",
       " (212, 25),\n",
       " (237, 25),\n",
       " (262, 24),\n",
       " (286, 22),\n",
       " (308, 23),\n",
       " (331, 22),\n",
       " (353, 22),\n",
       " (375, 19),\n",
       " (394, 24),\n",
       " (418, 19),\n",
       " (437, 20),\n",
       " (457, 20),\n",
       " (477, 23),\n",
       " (500, 26),\n",
       " (526, 26),\n",
       " (552, 23),\n",
       " (575, 23),\n",
       " (598, 24),\n",
       " (622, 21),\n",
       " (643, 20),\n",
       " (663, 25),\n",
       " (688, 23),\n",
       " (711, 24),\n",
       " (735, 22),\n",
       " (757, 21),\n",
       " (778, 21),\n",
       " (799, 17),\n",
       " (816, 26),\n",
       " (842, 20),\n",
       " (862, 22),\n",
       " (884, 21),\n",
       " (905, 24),\n",
       " (929, 21),\n",
       " (950, 19),\n",
       " (969, 24),\n",
       " (993, 24),\n",
       " (1017, 22),\n",
       " (1039, 22)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0455,  0.0447,  0.0261,  ..., -0.0160,  0.0526,  0.0204],\n",
       "        [-0.0465,  0.0597,  0.0177,  ..., -0.1785, -0.0618,  0.0922],\n",
       "        [ 0.0161,  0.0673, -0.1091,  ...,  0.0081, -0.0677,  0.1738],\n",
       "        ...,\n",
       "        [ 0.0850, -0.0669, -0.0290,  ..., -0.0392, -0.0300,  0.0311],\n",
       "        [ 0.1073, -0.0826, -0.0462,  ..., -0.0227, -0.0654,  0.0300],\n",
       "        [ 0.0796,  0.0683,  0.0362,  ..., -0.0448, -0.0863,  0.0600]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.narrow(0, 0, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 50])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding[0:22,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.2475e-02,  4.4592e-02,  4.1157e-02, -6.2958e-02, -2.6449e-02,\n",
       "          5.1672e-03, -4.6384e-02, -5.3797e-02, -7.3464e-02, -7.3005e-02,\n",
       "         -1.7704e-02,  8.3490e-02, -1.3573e-01,  8.2092e-03, -5.4852e-02,\n",
       "         -1.0005e-01,  1.0265e-01,  8.8467e-02,  1.8191e-02,  8.6351e-02,\n",
       "          1.7423e-01,  2.4751e-02,  6.3913e-03,  3.5624e-03,  8.4073e-03,\n",
       "         -2.3538e-02,  1.3579e-01,  4.8769e-02,  1.5200e-01, -2.5218e-02,\n",
       "          2.4999e-01, -7.4404e-03,  6.2257e-02, -1.2847e-01, -1.4130e-01,\n",
       "          1.4734e-01, -2.1842e-03,  8.3792e-02, -8.7801e-02,  4.2352e-02,\n",
       "          2.5093e-01, -3.2312e-02,  7.7363e-02,  6.2747e-02,  1.1126e-01,\n",
       "          6.4715e-02, -3.6868e-02,  1.1756e-03,  7.7242e-03,  7.6595e-03],\n",
       "        [ 2.0119e-03, -1.1420e-01, -6.6094e-03, -6.3875e-02,  8.7873e-02,\n",
       "          1.7288e-02,  9.8871e-02, -1.4052e-01, -5.1341e-02, -1.6861e-01,\n",
       "         -7.1023e-02,  3.3994e-02,  2.1864e-02, -9.5770e-03,  4.5321e-02,\n",
       "          1.1468e-01,  1.7144e-01,  1.0275e-01,  6.4650e-02,  6.7548e-02,\n",
       "          1.1096e-01, -1.7862e-01, -1.1572e-01,  3.9683e-03,  2.1316e-02,\n",
       "          5.1599e-02,  1.9089e-02, -9.7457e-02, -5.7705e-02, -3.2013e-02,\n",
       "          1.1510e-01, -1.3428e-01,  7.6023e-02,  1.1371e-01, -1.2995e-01,\n",
       "          1.5539e-01,  6.3551e-02,  6.3039e-02, -3.3870e-02,  2.1248e-01,\n",
       "         -5.7164e-03,  5.5832e-02, -1.1985e-01,  3.5071e-02, -5.7318e-02,\n",
       "         -6.9915e-02, -1.2773e-02,  2.2984e-02, -1.9392e-01,  5.6128e-02],\n",
       "        [-7.4831e-02,  1.9202e-02,  2.6232e-02, -4.9086e-02,  1.6536e-01,\n",
       "          1.1132e-02,  2.0409e-02, -1.3349e-01,  1.0190e-02, -1.5394e-01,\n",
       "         -6.3496e-02, -6.5835e-02,  1.8784e-02,  1.0282e-02,  1.2250e-01,\n",
       "          3.5327e-02,  9.5941e-02,  9.9225e-02,  1.0245e-01,  1.0312e-01,\n",
       "          1.3071e-01, -3.9658e-02, -1.2481e-01,  2.3864e-02,  4.8434e-02,\n",
       "          2.9407e-02, -7.0972e-02, -9.2338e-02, -2.1639e-02,  1.9514e-02,\n",
       "          9.3547e-02, -9.2258e-02,  1.4259e-01,  1.0263e-01, -1.0799e-01,\n",
       "          3.9730e-02, -4.9214e-03,  8.1520e-03,  5.2861e-02,  1.0459e-01,\n",
       "          3.7120e-02,  5.9990e-02, -7.3661e-02,  4.6982e-02,  1.8996e-02,\n",
       "         -1.5189e-02,  5.7292e-02, -1.1482e-01, -1.5137e-01,  4.1276e-02],\n",
       "        [ 1.1107e-01, -1.1086e-01, -6.8608e-02, -7.9348e-02, -9.8589e-03,\n",
       "         -3.3475e-02,  2.5361e-02, -1.0676e-01, -3.0541e-02, -1.3399e-01,\n",
       "          7.1472e-02,  1.2067e-02, -1.1203e-01, -6.5732e-02,  3.8560e-02,\n",
       "         -3.7062e-02,  5.2307e-03, -7.6133e-04,  1.2335e-01,  1.3654e-01,\n",
       "          5.2324e-02,  1.1503e-02, -3.3225e-02,  4.9500e-02, -3.9982e-03,\n",
       "         -1.1418e-01,  9.5772e-02, -2.7959e-02,  5.9731e-02, -7.4483e-02,\n",
       "          1.1130e-01, -5.3144e-02,  4.5784e-02,  7.8103e-02, -9.3262e-02,\n",
       "          1.4370e-01,  3.0391e-02,  1.0941e-02, -6.8041e-02,  1.2573e-01,\n",
       "          8.3403e-02, -1.9750e-02,  4.3076e-02,  5.5770e-02, -1.0587e-04,\n",
       "          1.9467e-02, -4.1530e-02, -5.3311e-02, -6.1343e-02,  5.2183e-02],\n",
       "        [ 1.4965e-01, -4.3767e-02, -1.6036e-02, -4.3057e-02, -1.3387e-02,\n",
       "         -4.2743e-02,  3.6037e-02, -1.3668e-01,  7.7198e-03, -1.7244e-01,\n",
       "          4.1195e-02,  7.0311e-02, -1.4857e-01, -1.4191e-01,  5.1213e-02,\n",
       "         -7.0471e-02,  7.4260e-02,  2.3955e-02,  4.7956e-02,  1.9671e-01,\n",
       "         -2.9506e-02, -7.5589e-02, -4.6484e-02, -9.1569e-02,  1.0470e-01,\n",
       "          6.0248e-03,  4.1826e-02,  5.8838e-02,  6.5742e-03,  8.4379e-02,\n",
       "         -4.3867e-02, -1.1369e-02,  1.2448e-01, -2.8557e-02,  5.5058e-02,\n",
       "          1.8164e-01,  6.6553e-03,  9.0238e-02, -2.0040e-01,  1.6113e-01,\n",
       "          1.0416e-01,  9.9796e-02, -4.6932e-02, -2.1982e-02, -1.3103e-01,\n",
       "          5.8650e-02,  1.5278e-02,  8.2953e-02, -1.0486e-01,  1.0686e-01],\n",
       "        [-1.3811e-01, -1.0962e-02,  1.5299e-01, -1.5090e-01,  4.2050e-02,\n",
       "         -7.9550e-02,  1.4646e-01, -3.8062e-02,  1.0760e-02, -9.9155e-02,\n",
       "         -1.3323e-01,  1.3856e-01, -6.6188e-02, -3.5772e-02,  1.2616e-03,\n",
       "         -5.8006e-02,  5.4338e-02,  3.4116e-02,  3.9887e-02, -2.6394e-02,\n",
       "         -3.1722e-02, -7.0152e-02, -1.0378e-01, -6.5871e-02, -2.9889e-02,\n",
       "         -4.4786e-02, -3.9086e-02,  1.8439e-02,  1.9467e-01,  1.3721e-01,\n",
       "          8.1558e-04, -2.5913e-02,  3.7295e-03, -1.0363e-01, -1.8557e-01,\n",
       "          9.6840e-02, -7.1866e-02,  1.1633e-01,  3.3533e-02, -8.6680e-02,\n",
       "          9.4380e-02,  3.4461e-02, -5.2381e-02,  7.9040e-02,  3.4064e-02,\n",
       "          1.6273e-01,  1.3577e-02, -1.4633e-01, -8.3325e-02,  1.2317e-01],\n",
       "        [ 1.3637e-01, -4.4353e-02, -4.4834e-02, -3.8192e-02, -1.4762e-02,\n",
       "         -6.8501e-02,  5.0284e-02, -1.4969e-01, -3.9461e-03, -1.5554e-01,\n",
       "          2.2196e-02,  9.1206e-02, -2.2257e-01, -9.7455e-02,  3.4719e-02,\n",
       "          5.4771e-03,  6.0597e-02,  4.3464e-02,  8.3396e-02,  1.6212e-01,\n",
       "          5.4218e-02, -9.5843e-02, -8.6093e-02, -6.3744e-02,  9.9415e-02,\n",
       "          2.2308e-02,  1.7616e-02,  2.0128e-02,  3.0082e-02,  8.9772e-02,\n",
       "         -1.0687e-02, -8.5193e-02,  1.4852e-01, -1.3911e-02,  7.9518e-02,\n",
       "          2.1588e-01,  2.2159e-02,  5.5309e-02, -2.2926e-01,  1.1593e-01,\n",
       "          1.5672e-01,  7.2799e-02, -5.9888e-04, -4.4272e-02, -7.3670e-02,\n",
       "          1.2101e-01,  6.7118e-03,  4.4005e-02, -7.9488e-02,  1.4179e-01],\n",
       "        [ 5.0304e-04, -4.7265e-02, -6.8680e-02, -1.8989e-02, -4.3069e-02,\n",
       "          1.2028e-02,  3.0058e-02, -1.1381e-01, -4.9087e-03, -9.1327e-02,\n",
       "          4.2059e-02,  3.9389e-02, -1.3250e-01, -4.4926e-02,  2.9262e-02,\n",
       "          9.3829e-03,  6.7096e-02, -1.2767e-02,  1.2730e-01,  1.1479e-01,\n",
       "         -1.2171e-03, -7.9559e-02,  1.3363e-02, -3.9249e-02,  1.0448e-01,\n",
       "         -4.9952e-02,  5.7367e-02,  7.9590e-03,  7.2742e-02,  1.9224e-02,\n",
       "         -5.6658e-02, -7.9287e-02,  3.9887e-02,  6.7840e-02,  1.2043e-01,\n",
       "          2.2017e-01, -2.5548e-02,  6.9413e-02, -1.2256e-01,  1.0479e-01,\n",
       "          8.6722e-02,  1.2362e-01, -3.2506e-02,  1.9682e-02, -4.7247e-02,\n",
       "          1.0296e-01, -2.9497e-02, -6.7464e-02, -5.0787e-02,  2.1128e-01],\n",
       "        [-8.4101e-02, -1.2952e-01,  4.6561e-03,  2.5336e-02,  8.9385e-02,\n",
       "         -3.3152e-02, -6.2429e-02, -1.1558e-01,  3.9478e-02,  7.0717e-04,\n",
       "          1.9344e-03, -1.9591e-03, -4.0175e-02, -1.8285e-01, -2.4802e-02,\n",
       "         -1.2054e-01,  4.9930e-02,  2.6806e-02,  1.5114e-02,  3.2357e-02,\n",
       "          3.1959e-02,  3.0837e-02, -1.8034e-01, -4.4719e-02, -1.4276e-02,\n",
       "         -4.3431e-03, -1.8570e-02,  1.0516e-01,  1.9579e-02,  8.9768e-02,\n",
       "          2.8135e-02, -3.8529e-02,  3.8870e-02, -6.8335e-02, -1.2181e-01,\n",
       "          2.4701e-01, -5.1530e-02,  1.2441e-01, -5.6590e-02,  1.2005e-01,\n",
       "          1.3201e-01, -2.4858e-02,  8.6666e-02, -4.5921e-02,  9.3157e-02,\n",
       "          6.3326e-02,  3.9900e-02, -1.4168e-02, -2.9439e-02,  8.9053e-02],\n",
       "        [-1.1275e-01,  1.2943e-03, -5.4671e-02, -6.5457e-02, -7.1936e-02,\n",
       "         -1.3738e-02, -3.0450e-02,  1.2147e-01,  9.9804e-02, -1.1622e-01,\n",
       "          1.0904e-01,  9.0601e-02, -8.1999e-02, -3.5589e-02,  2.1940e-01,\n",
       "          1.2496e-02, -5.0089e-02, -8.2836e-02,  3.4453e-02, -6.3917e-03,\n",
       "          9.5113e-02,  4.1443e-02,  8.1753e-02,  3.9420e-02, -5.5499e-02,\n",
       "         -8.2504e-02,  7.4723e-02, -1.4665e-01,  7.0595e-02, -3.6533e-02,\n",
       "          8.3312e-02, -8.9807e-02, -3.5077e-02,  1.9412e-01,  1.8954e-02,\n",
       "          2.2515e-01,  3.8089e-02, -5.1842e-02,  8.1517e-02, -4.1861e-03,\n",
       "          2.3012e-02,  1.4055e-02,  3.7473e-02, -3.2812e-02, -1.2586e-02,\n",
       "         -4.8062e-02, -4.3280e-02, -2.8999e-02, -2.0492e-01,  2.0290e-01],\n",
       "        [-3.6591e-02,  4.6016e-03, -7.6796e-02, -1.8898e-02, -4.2509e-02,\n",
       "          5.2543e-02, -9.9672e-03, -1.1597e-01,  1.5406e-02, -3.6737e-02,\n",
       "          6.9244e-02,  1.5420e-02, -1.1354e-01, -5.1621e-02,  5.0807e-02,\n",
       "          2.1520e-02,  5.6531e-02,  2.4925e-02,  1.6732e-01,  9.6959e-02,\n",
       "          7.0073e-03, -7.5256e-02, -4.8453e-02, -2.2980e-02,  9.7129e-02,\n",
       "          6.9751e-02,  6.9503e-02,  1.0228e-02,  1.1353e-01,  3.1293e-02,\n",
       "         -2.1551e-03, -9.0327e-02,  8.6456e-02,  7.5242e-02,  6.5324e-02,\n",
       "          2.2482e-01, -4.8340e-02,  7.8806e-02, -8.1247e-02,  1.1624e-01,\n",
       "          1.5895e-01,  9.4216e-02, -4.1416e-02,  4.3831e-02, -7.5481e-02,\n",
       "          1.1918e-01, -6.2028e-02, -4.3639e-02, -4.4378e-02,  1.7389e-01],\n",
       "        [-5.7643e-02,  9.0985e-03, -2.9833e-02,  4.5143e-03, -9.8575e-03,\n",
       "         -5.3548e-02,  1.5851e-02, -1.0652e-01,  6.3350e-03, -2.0842e-03,\n",
       "          5.1616e-02,  4.2332e-02,  2.1081e-03, -1.9878e-01,  8.5597e-02,\n",
       "         -1.6425e-01, -5.8760e-03,  3.3283e-02, -1.0720e-01,  1.4510e-01,\n",
       "          2.2784e-02,  4.8351e-02, -1.7794e-01,  1.0362e-02, -6.6807e-02,\n",
       "          2.6328e-02,  4.2177e-02,  4.3030e-02,  4.8680e-02,  1.0780e-01,\n",
       "          1.0842e-01, -6.3398e-02,  1.0684e-02,  3.4621e-02, -3.8505e-02,\n",
       "          9.0589e-02,  3.8153e-02,  1.3906e-01, -1.6519e-02,  4.2114e-02,\n",
       "          1.2325e-01, -7.1997e-02, -3.0775e-02,  6.2293e-02, -3.6598e-02,\n",
       "         -6.2821e-02,  8.2474e-03, -8.8951e-02,  5.3630e-02, -1.4264e-02],\n",
       "        [-7.8254e-02, -8.2792e-02,  1.8675e-02, -3.5932e-02,  5.6793e-02,\n",
       "          5.2942e-02,  7.4303e-02, -3.8158e-02, -8.5450e-02, -1.1032e-01,\n",
       "         -4.6928e-02, -3.1212e-03,  8.4089e-02,  4.6139e-02,  5.1325e-02,\n",
       "          1.7325e-01,  1.2102e-01,  7.5074e-02,  1.6370e-01, -4.7505e-02,\n",
       "          1.2629e-01, -2.2183e-01, -8.4482e-02,  6.4749e-02, -9.5201e-03,\n",
       "         -1.6193e-02,  1.7835e-02, -1.0828e-01,  5.5775e-02, -1.0897e-01,\n",
       "          5.6066e-03, -1.4808e-01, -3.7711e-02,  2.1916e-01, -1.1704e-01,\n",
       "          1.4177e-01,  3.2967e-02,  9.5712e-02, -3.4131e-03,  2.3827e-01,\n",
       "         -1.3770e-02,  3.3080e-02, -1.6552e-01,  9.0251e-02,  1.5492e-02,\n",
       "         -2.8265e-02, -4.8025e-02, -1.1888e-01, -1.7046e-01,  1.3865e-01],\n",
       "        [ 3.4114e-02,  1.0204e-01, -9.0270e-02,  2.8761e-02, -3.7776e-02,\n",
       "         -1.2258e-02, -1.4382e-01,  4.7977e-02,  4.9830e-02,  1.5700e-02,\n",
       "          1.3497e-01,  6.7086e-02, -1.2683e-01, -4.5996e-02,  1.0811e-01,\n",
       "          1.4485e-02,  1.6109e-02,  4.6190e-02,  5.7579e-02,  7.8621e-02,\n",
       "          1.5290e-01, -7.5824e-03,  3.9437e-03, -1.0607e-02,  2.2816e-02,\n",
       "         -8.0109e-02,  7.4569e-02, -3.1358e-02,  9.5366e-02,  3.2356e-03,\n",
       "         -4.7866e-02,  8.0441e-02,  1.0015e-01,  2.1060e-02,  5.2461e-02,\n",
       "          6.3485e-02,  1.0180e-03, -5.4314e-02, -3.3123e-03,  3.4116e-02,\n",
       "          7.1588e-02,  1.3165e-01,  1.0242e-02,  1.3733e-02, -2.7791e-02,\n",
       "         -9.8141e-03, -5.0253e-02,  1.8194e-02, -9.1925e-02,  1.7552e-01],\n",
       "        [ 3.7890e-02,  7.0168e-02, -9.0855e-02,  6.6424e-02, -4.5429e-02,\n",
       "         -5.5615e-02, -1.0286e-01,  9.2074e-03, -1.1636e-02, -2.2935e-02,\n",
       "          8.6468e-02,  2.9843e-02, -1.0275e-01, -3.1200e-02,  5.9485e-02,\n",
       "          8.5958e-03, -1.5521e-02,  1.9868e-02,  8.7264e-02,  8.1197e-02,\n",
       "          1.2720e-01, -2.3281e-02, -1.1109e-02, -2.8612e-05,  8.5473e-03,\n",
       "         -9.9978e-02,  8.3859e-02, -4.0947e-03,  8.3056e-02, -1.4108e-02,\n",
       "         -9.8817e-02,  1.2138e-01,  7.1917e-02, -3.6474e-03,  3.2560e-02,\n",
       "          3.9896e-02,  5.0349e-04, -3.1494e-02, -4.4667e-02,  5.3413e-02,\n",
       "          3.8768e-02,  1.0952e-01,  2.6022e-02, -1.3302e-02, -3.4250e-02,\n",
       "         -1.2320e-02, -2.2463e-02, -1.0446e-03, -5.0203e-02,  2.0068e-01],\n",
       "        [ 3.0044e-03,  9.2889e-02,  4.0899e-02,  6.2183e-02,  8.6703e-02,\n",
       "         -1.2006e-02,  5.7864e-03,  1.6809e-02,  1.0045e-01, -8.5322e-03,\n",
       "          9.9359e-02, -3.2882e-02, -1.6531e-02, -2.0355e-01,  1.4233e-01,\n",
       "         -4.0833e-02, -6.8080e-02,  2.4784e-02,  5.1234e-02,  6.8301e-02,\n",
       "         -6.0353e-02, -5.3563e-02, -7.3836e-02,  4.4007e-02,  6.5564e-02,\n",
       "         -6.5315e-02,  2.8460e-02, -2.5883e-02,  1.4184e-02,  8.0203e-02,\n",
       "         -7.9824e-02, -9.4156e-02,  5.4985e-02,  7.5851e-02, -3.3991e-02,\n",
       "          2.1319e-02, -3.2957e-02,  1.0702e-01, -2.6242e-03,  1.0723e-01,\n",
       "          3.0318e-02,  4.1110e-03, -9.3678e-02, -2.2851e-02, -2.4640e-02,\n",
       "         -7.2871e-02,  7.6433e-02, -1.9022e-01, -3.6434e-02,  1.3717e-01],\n",
       "        [ 3.7890e-02,  7.0168e-02, -9.0855e-02,  6.6424e-02, -4.5429e-02,\n",
       "         -5.5615e-02, -1.0286e-01,  9.2074e-03, -1.1636e-02, -2.2935e-02,\n",
       "          8.6468e-02,  2.9843e-02, -1.0275e-01, -3.1200e-02,  5.9485e-02,\n",
       "          8.5958e-03, -1.5521e-02,  1.9868e-02,  8.7264e-02,  8.1197e-02,\n",
       "          1.2720e-01, -2.3281e-02, -1.1109e-02, -2.8612e-05,  8.5473e-03,\n",
       "         -9.9978e-02,  8.3859e-02, -4.0947e-03,  8.3056e-02, -1.4108e-02,\n",
       "         -9.8817e-02,  1.2138e-01,  7.1917e-02, -3.6474e-03,  3.2560e-02,\n",
       "          3.9896e-02,  5.0349e-04, -3.1494e-02, -4.4667e-02,  5.3413e-02,\n",
       "          3.8768e-02,  1.0952e-01,  2.6022e-02, -1.3302e-02, -3.4250e-02,\n",
       "         -1.2320e-02, -2.2463e-02, -1.0446e-03, -5.0203e-02,  2.0068e-01],\n",
       "        [ 3.4114e-02,  1.0204e-01, -9.0270e-02,  2.8761e-02, -3.7776e-02,\n",
       "         -1.2258e-02, -1.4382e-01,  4.7977e-02,  4.9830e-02,  1.5700e-02,\n",
       "          1.3497e-01,  6.7086e-02, -1.2683e-01, -4.5996e-02,  1.0811e-01,\n",
       "          1.4485e-02,  1.6109e-02,  4.6190e-02,  5.7579e-02,  7.8621e-02,\n",
       "          1.5290e-01, -7.5824e-03,  3.9437e-03, -1.0607e-02,  2.2816e-02,\n",
       "         -8.0109e-02,  7.4569e-02, -3.1358e-02,  9.5366e-02,  3.2356e-03,\n",
       "         -4.7866e-02,  8.0441e-02,  1.0015e-01,  2.1060e-02,  5.2461e-02,\n",
       "          6.3485e-02,  1.0180e-03, -5.4314e-02, -3.3123e-03,  3.4116e-02,\n",
       "          7.1588e-02,  1.3165e-01,  1.0242e-02,  1.3733e-02, -2.7791e-02,\n",
       "         -9.8141e-03, -5.0253e-02,  1.8194e-02, -9.1925e-02,  1.7552e-01]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.narrow(0, 22, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# for idx, i in enumerate(data_loader):\n",
    "#     X = (MolGraph(i[0]))\n",
    "#     Y = (MolGraph(i[1]))\n",
    "#     \n",
    "#     # create your optimizer\n",
    "#     optimizer = torch.optim.SGD(molopt.parameters(), lr=0.01)\n",
    "# \n",
    "#     # in your training loop:\n",
    "#     optimizer.zero_grad()   # zero the gradient buffers\n",
    "#     loss = molopt.forward_train(X, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()    # Does the update\n",
    "# \n",
    "#     print (idx, loss)\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the implemented function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(N_transformer=6, agg_func='sum', batch_norm=False, cuda=True, device='cuda:0', dim_tangent_space=40, dropout_ffn=0.0, dropout_gcn=0.0, dropout_transformer=0.1, ffn_activation='LeakyReLU', init_decoder_model='transformer1_decode', init_model='transformer1', linear_out=False, n_epochs=40, n_ffn_hidden=100, n_ffn_transformer=100, n_heads_transformer=10, n_hidden=50, n_labels=1, n_layers=5, ot_solver='emd', output_dir='mol_opt/output', pc_hidden=50, pred_hidden=150, sinkhorn_entropy=0.1, sinkhorn_max_it=10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv = [\"\", \"-cuda\", \"-pred_hidden\", \"150\"]\n",
    "args = get_args()\n",
    "args.n_epochs = 40 \n",
    "args.output_dir = \"mol_opt/output\"\n",
    "args.init_model = \"transformer1\"\n",
    "args.init_decoder_model = \"{}_decode\".format(args.init_model)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train\", 96, False)\n",
    "val_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"val\", 96, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model gcn3_decode found in mol_opt/output! Starting from scratch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latest_model(\"gcn3_decode\", args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model transformer1 found in mol_opt/output! Starting from scratch.\n",
      "No model transformer1_decode found in mol_opt/output! Starting from scratch.\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis/otgnn/models/gromov_modules.py:394: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_mse: 51.106947\n",
      " val_mse: 39.266362\n",
      "Epoch duration: 1527.9214224815369\n",
      "Model saved to: mol_opt/output/model_transformer1_1\n",
      "Model saved to: mol_opt/output/model_transformer1_decode_1\n",
      "Epoch: 2\n",
      " train_mse: 39.063239\n",
      " val_mse: 38.922148\n",
      "Epoch duration: 1613.0044691562653\n",
      "Model saved to: mol_opt/output/model_transformer1_2\n",
      "Model saved to: mol_opt/output/model_transformer1_decode_2\n",
      "Epoch: 3\n",
      " train_mse: 38.706692\n",
      " val_mse: 38.638293\n",
      "Epoch duration: 1651.5140421390533\n",
      "Model saved to: mol_opt/output/model_transformer1_3\n",
      "Model saved to: mol_opt/output/model_transformer1_decode_3\n",
      "Epoch: 4\n",
      " train_mse: 38.733420\n",
      " val_mse: 38.737589\n",
      "Epoch duration: 1577.0327999591827\n",
      "Model saved to: mol_opt/output/model_transformer1_4\n",
      "Model saved to: mol_opt/output/model_transformer1_decode_4\n",
      "Epoch: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b45cff8cb532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmolopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# run the training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolopt_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# compute the validation loss as well, at the end of the epoch?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mrun_func\u001b[0;34m(mol_opt, mol_opt_decoder, optim, data_loader, data_type, args)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0myhat_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol_opt_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0myhat_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol_opt_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscretize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0myhat_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgw_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# add stat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/ot_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prediction, target_batch)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mnce_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             )\n\u001b[1;32m     90\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0matom_gw_dist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbond_gw_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mfused_gw_torch\u001b[0;34m(M, C1, C2, p1, p2, dist_type, alpha, nce_reg, device)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     ot_mat = np_fused_gw(M=M_detach, C1 = C1_detach, C2 = C2_detach,\n\u001b[0;32m--> 361\u001b[0;31m                          p1 = p1, p2 = p2, dist_type=dist_type, alpha=alpha)\n\u001b[0m\u001b[1;32m    362\u001b[0m     \u001b[0mot_mat_attached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mnp_fused_gw\u001b[0;34m(M, C1, C2, p1, p2, dist_type, alpha)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mG0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mot_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0msanity_check_ot_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mot_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/otgnn/models/gromov_modules.py\u001b[0m in \u001b[0;36mmy_cg\u001b[0;34m(a, b, M, reg, f, df, G0, numItermax, stopThr, stopThr2, verbose, log, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# solve linear program\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mGc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mdeltaG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/ot/lp/__init__.py\u001b[0m in \u001b[0;36memd\u001b[0;34m(a, b, M, numItermax, log, center_dual)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mbsel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memd_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumItermax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcenter_dual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "molopt = main(args, train_data_loader = train_data_loader, val_data_loader = val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      " train_mse: 40.374824\n",
      " val_mse: 38.866998\n",
      "Epoch duration: 1921.0867624282837\n",
      "Model saved to: mol_opt/output/model_transformer0_2\n",
      "Model saved to: mol_opt/output/model_transformer0_decode_2\n",
      "         888227500 function calls (886352703 primitive calls) in 1921.114 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   408871    0.314    0.000    4.459    0.000 <__array_function__ internals>:2(amax)\n",
      "  7655076    3.786    0.000   34.072    0.000 <__array_function__ internals>:2(any)\n",
      "  2888831    1.585    0.000    8.998    0.000 <__array_function__ internals>:2(atleast_1d)\n",
      "  4499472    1.707    0.000    9.646    0.000 <__array_function__ internals>:2(concatenate)\n",
      "  1998380    1.117    0.000    4.955    0.000 <__array_function__ internals>:2(copyto)\n",
      "  2914091    1.306    0.000    4.903    0.000 <__array_function__ internals>:2(dot)\n",
      "   441530    0.400    0.000    0.787    0.000 <__array_function__ internals>:2(empty_like)\n",
      "  1854419    0.970    0.000   14.591    0.000 <__array_function__ internals>:2(norm)\n",
      "     1842    0.003    0.000    6.476    0.004 <__array_function__ internals>:2(stack)\n",
      " 15863952    7.991    0.000   94.499    0.000 <__array_function__ internals>:2(sum)\n",
      " 21792078    9.330    0.000   41.705    0.000 <__array_function__ internals>:2(transpose)\n",
      "       36    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(parent)\n",
      "       36    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
      "        1    0.000    0.000 1921.114 1921.114 <string>:1(<module>)\n",
      "      921    0.001    0.000    0.002    0.000 <string>:12(__new__)\n",
      "   414397    0.192    0.000    0.279    0.000 _VF.py:11(__getattr__)\n",
      "       48    0.000    0.000    0.000    0.000 __future__.py:18(get_overwrite_module_params_on_conversion)\n",
      "       48    0.000    0.000    0.000    0.000 __init__.py:124(_lazy_init)\n",
      "  3297702   29.984    0.000  274.071    0.000 __init__.py:175(emd)\n",
      "      712    0.000    0.000    0.000    0.000 __init__.py:176(is_storage)\n",
      "  1315877    0.134    0.000    0.134    0.000 __init__.py:1917(is_scripting)\n",
      "       24    0.000    0.000    0.000    0.000 __init__.py:200(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 __init__.py:204(__enter__)\n",
      "      828    0.005    0.000    0.028    0.000 __init__.py:21(_make_grads)\n",
      "       24    0.000    0.000    0.000    0.000 __init__.py:212(__exit__)\n",
      "  3297702   15.843    0.000   41.610    0.000 __init__.py:28(center_ot_dual)\n",
      "       24    0.000    0.000    0.000    0.000 __init__.py:320(device_count)\n",
      "       48    0.000    0.000    0.000    0.000 __init__.py:33(is_available)\n",
      "       24    0.000    0.000    0.000    0.000 __init__.py:428(_lazy_new)\n",
      "      828    0.005    0.000   69.815    0.084 __init__.py:45(backward)\n",
      "       48    0.000    0.000    0.000    0.000 __init__.py:92(is_initialized)\n",
      " 12012443    2.595    0.000   11.286    0.000 _asarray.py:16(asarray)\n",
      "  9478699    1.465    0.000    3.264    0.000 _asarray.py:88(asanyarray)\n",
      "   706448    0.180    0.000    2.762    0.000 _methods.py:28(_amax)\n",
      "  2888831    0.838    0.000   11.927    0.000 _methods.py:32(_amin)\n",
      "  6595404    1.521    0.000   16.827    0.000 _methods.py:36(_sum)\n",
      "       24    0.000    0.000    0.000    0.000 _namedtensor_internals.py:11(check_serializing_named_tensor)\n",
      "   539046    0.234    0.000    1.169    0.000 _overrides.py:745(has_torch_function)\n",
      "  1617138    0.299    0.000    0.660    0.000 _overrides.py:758(<genexpr>)\n",
      "       24    0.000    0.000    0.001    0.000 _utils.py:128(_rebuild_tensor)\n",
      "       24    0.000    0.000    0.001    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
      "       48    0.000    0.000    0.000    0.000 _utils.py:5(_get_device_index)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
      "    91069    0.179    0.000    2.360    0.000 activation.py:1104(__init__)\n",
      "    91069    0.088    0.000    2.351    0.000 activation.py:1113(forward)\n",
      "     1842    0.004    0.000    0.049    0.000 activation.py:576(__init__)\n",
      "     1842    0.002    0.000    0.035    0.000 activation.py:581(forward)\n",
      "     4605    0.007    0.000    0.111    0.000 activation.py:89(__init__)\n",
      "     4605    0.004    0.000    0.074    0.000 activation.py:93(forward)\n",
      "        1    0.000    0.000    0.000    0.000 adam.py:30(__init__)\n",
      "      828    0.141    0.000    0.572    0.001 adam.py:51(step)\n",
      "    88306    0.303    0.000   41.693    0.000 bregman.py:23(sinkhorn)\n",
      "    88306   10.652    0.000   41.356    0.000 bregman.py:565(sinkhorn_stabilized)\n",
      "   618142   12.014    0.000   12.529    0.000 bregman.py:689(get_K)\n",
      "   176612    4.385    0.000    4.616    0.000 bregman.py:694(get_Gamma)\n",
      "        8    0.000    0.000    0.000    0.000 connection.py:117(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
      "     2763    0.001    0.000    0.001    0.000 connection.py:134(_check_closed)\n",
      "     1842    0.001    0.000    0.001    0.000 connection.py:138(_check_readable)\n",
      "      921    0.001    0.000    0.001    0.000 connection.py:168(fileno)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:173(close)\n",
      "      921    0.002    0.000    0.538    0.001 connection.py:208(recv_bytes)\n",
      "      921    0.003    0.000    0.052    0.000 connection.py:253(poll)\n",
      "        6    0.000    0.000    0.000    0.000 connection.py:360(_close)\n",
      "     1842    0.005    0.000    0.530    0.000 connection.py:374(_recv)\n",
      "      921    0.004    0.000    0.536    0.001 connection.py:406(_recv_bytes)\n",
      "      921    0.003    0.000    0.048    0.000 connection.py:413(_poll)\n",
      "        4    0.000    0.000    0.000    0.000 connection.py:501(Pipe)\n",
      "      921    0.007    0.000    0.046    0.000 connection.py:897(wait)\n",
      "      921    0.001    0.000    0.001    0.000 connection.py:913(<listcomp>)\n",
      "       24    0.000    0.000    0.000    0.000 context.py:186(get_context)\n",
      "       22    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
      "        2    0.000    0.000    0.026    0.013 context.py:221(_Popen)\n",
      "        8    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
      "        2    0.000    0.000    0.026    0.013 context.py:274(_Popen)\n",
      "       10    0.000    0.000    0.001    0.000 context.py:64(Lock)\n",
      "        2    0.000    0.000    0.000    0.000 context.py:74(Condition)\n",
      "        8    0.000    0.000    0.000    0.000 context.py:79(Semaphore)\n",
      "        4    0.000    0.000    0.000    0.000 context.py:84(BoundedSemaphore)\n",
      "        2    0.000    0.000    0.001    0.000 context.py:89(Event)\n",
      "        4    0.000    0.000    0.001    0.000 context.py:99(Queue)\n",
      "        2    0.000    0.000    0.000    0.000 data_mol_opt.py:28(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 data_utils.py:212(__init__)\n",
      "      921    0.003    0.000    0.003    0.000 data_utils.py:216(add_stat)\n",
      "        2    0.000    0.000    0.000    0.000 data_utils.py:220(get_stats)\n",
      "        2    0.000    0.000    0.000    0.000 data_utils.py:221(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 data_utils.py:227(print_stats)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:236(multiprocessing_context)\n",
      "        2    0.000    0.000    0.034    0.017 dataloader.py:275(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 dataloader.py:281(_auto_collation)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:285(_index_sampler)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:320(__init__)\n",
      "      925    0.001    0.000    0.036    0.000 dataloader.py:338(_next_index)\n",
      "      923    0.002    0.000    0.739    0.001 dataloader.py:344(__next__)\n",
      "        2    0.000    0.000    0.034    0.017 dataloader.py:672(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 dataloader.py:740(<genexpr>)\n",
      "      921    0.003    0.000    0.631    0.001 dataloader.py:748(_try_get_data)\n",
      "      921    0.002    0.000    0.633    0.001 dataloader.py:779(_get_data)\n",
      "      923    0.007    0.000    0.737    0.001 dataloader.py:812(_next_data)\n",
      "      925    0.006    0.000    0.066    0.000 dataloader.py:858(_try_put_index)\n",
      "      921    0.001    0.000    0.062    0.000 dataloader.py:877(_process_data)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:884(_shutdown_worker)\n",
      "        4    0.000    0.000    0.035    0.009 dataloader.py:907(_shutdown_workers)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:961(__del__)\n",
      "        1    0.000    0.000    0.002    0.002 decoder_mol_opt.py:16(__init__)\n",
      "      921    2.920    0.003  209.759    0.228 decoder_mol_opt.py:38(forward)\n",
      "      921    0.001    0.000    0.037    0.000 decoder_mol_opt.py:67(discretize)\n",
      "     5526    0.005    0.000    0.035    0.000 dropout.py:53(forward)\n",
      "        2    0.000    0.000    0.000    0.000 dropout.py:8(__init__)\n",
      " 15863952    1.707    0.000    1.707    0.000 fromnumeric.py:2087(_sum_dispatcher)\n",
      " 15863952   15.345    0.000   78.720    0.000 fromnumeric.py:2092(sum)\n",
      "  7655076    0.801    0.000    0.801    0.000 fromnumeric.py:2232(_any_dispatcher)\n",
      "  7655076    4.533    0.000   26.539    0.000 fromnumeric.py:2236(any)\n",
      "   408871    0.059    0.000    0.059    0.000 fromnumeric.py:2546(_amax_dispatcher)\n",
      "   408871    0.469    0.000    3.874    0.000 fromnumeric.py:2551(amax)\n",
      " 21792078    7.673    0.000   16.994    0.000 fromnumeric.py:55(_wrapfunc)\n",
      " 21792078    2.075    0.000    2.075    0.000 fromnumeric.py:600(_transpose_dispatcher)\n",
      " 21792078    6.756    0.000   23.750    0.000 fromnumeric.py:604(transpose)\n",
      " 23927899   23.513    0.000   85.854    0.000 fromnumeric.py:73(_wrapreduction)\n",
      " 23927899    8.060    0.000    8.060    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "   269523    0.279    0.000    3.442    0.000 functional.py:1050(relu)\n",
      "     1842    0.003    0.000    0.033    0.000 functional.py:1221(leaky_relu)\n",
      "    88306    0.084    0.000    0.501    0.000 functional.py:1369(_get_softmax_dim)\n",
      "    91069    0.189    0.000    2.263    0.000 functional.py:1511(log_softmax)\n",
      "   539046    3.526    0.000   18.661    0.000 functional.py:1591(linear)\n",
      "   539046    0.267    0.000    0.267    0.000 functional.py:1606(<listcomp>)\n",
      "   408871    1.590    0.000    6.330    0.000 functional.py:761(norm)\n",
      "     5526    0.015    0.000    0.030    0.000 functional.py:913(dropout)\n",
      "        1    0.000    0.000    0.001    0.001 gcn.py:10(__init__)\n",
      "      921    0.127    0.000  180.914    0.196 gcn.py:119(forward)\n",
      "     4605    0.017    0.000    0.121    0.000 gcn.py:56(index_select_nei)\n",
      "      921    0.128    0.000    1.362    0.001 gcn.py:67(aggregate_atoms)\n",
      "      828    0.006    0.000    0.586    0.001 grad_mode.py:12(decorate_context)\n",
      "   177536    0.141    0.000    0.212    0.000 grad_mode.py:151(__init__)\n",
      "   177536    0.132    0.000    0.197    0.000 grad_mode.py:65(__enter__)\n",
      "   177536    0.178    0.000    0.390    0.000 grad_mode.py:69(__exit__)\n",
      "    88306    0.060    0.000    0.116    0.000 gromov_modules.py:10(np_const_term)\n",
      "   971366   15.877    0.000   86.996    0.000 gromov_modules.py:105(torch_tensor_product)\n",
      "  5118377   21.181    0.000  224.331    0.000 gromov_modules.py:125(np_gwloss)\n",
      "   971366   26.102    0.000  123.758    0.000 gromov_modules.py:130(torch_gwloss)\n",
      "  2888831    5.944    0.000  192.780    0.000 gromov_modules.py:135(np_gwggrad)\n",
      "    88306    0.061    0.000    0.085    0.000 gromov_modules.py:185(sanity_check_ot_mat)\n",
      "    88306    0.857    0.000  820.146    0.009 gromov_modules.py:259(np_fused_gw)\n",
      "    88306    0.031    0.000    0.031    0.000 gromov_modules.py:30(torch_const_term)\n",
      "  5118377    2.346    0.000  226.677    0.000 gromov_modules.py:320(f)\n",
      "  2888831    1.635    0.000  194.415    0.000 gromov_modules.py:323(df)\n",
      "    88306   72.499    0.001 1128.898    0.013 gromov_modules.py:332(fused_gw_torch)\n",
      "    88306   46.538    0.001  819.088    0.009 gromov_modules.py:402(my_cg)\n",
      "  5118377   17.443    0.000  271.692    0.000 gromov_modules.py:476(cost)\n",
      " 10896039  103.215    0.000  170.086    0.000 gromov_modules.py:50(np_ikd_kl_to_ild)\n",
      " 10896039   98.846    0.000  158.503    0.000 gromov_modules.py:59(np_ild_jld_to_ij)\n",
      "   971366    4.674    0.000   37.289    0.000 gromov_modules.py:67(torch_ikd_kl_to_ild)\n",
      "   971366    2.933    0.000   33.830    0.000 gromov_modules.py:76(torch_ild_jld_to_ij)\n",
      "  8007208   20.904    0.000  264.724    0.000 gromov_modules.py:86(np_tensor_product)\n",
      "  2888831    8.279    0.000   94.664    0.000 gromov_modules.py:95(np_tensor_product_t)\n",
      "       24    0.000    0.000    0.000    0.000 hooks.py:51(warn_if_has_hooks)\n",
      "       11    0.000    0.000    0.000    0.000 init.py:12(_no_grad_uniform_)\n",
      "    88306    0.174    0.000    1.156    0.000 init.py:17(_no_grad_normal_)\n",
      "    88330    0.090    0.000    0.187    0.000 init.py:214(_calculate_fan_in_and_fan_out)\n",
      "    88306    0.173    0.000    1.540    0.000 init.py:258(xavier_normal_)\n",
      "       13    0.000    0.000    0.000    0.000 init.py:285(_calculate_correct_fan)\n",
      "       13    0.000    0.000    0.001    0.000 init.py:295(kaiming_uniform_)\n",
      "       13    0.000    0.000    0.000    0.000 init.py:32(calculate_gain)\n",
      "       11    0.000    0.000    0.000    0.000 init.py:74(uniform_)\n",
      "       27    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "       16    0.000    0.000    0.000    0.000 iostream.py:310(_is_master_process)\n",
      "       16    0.000    0.000    0.000    0.000 iostream.py:323(_schedule_flush)\n",
      "        4    0.000    0.000    0.001    0.000 iostream.py:337(flush)\n",
      "       16    0.000    0.000    0.000    0.000 iostream.py:386(write)\n",
      "       27    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "  1854419    0.409    0.000    0.606    0.000 linalg.py:121(isComplexType)\n",
      "  1854419    0.205    0.000    0.205    0.000 linalg.py:2312(_norm_dispatcher)\n",
      "  1854419    6.275    0.000   12.442    0.000 linalg.py:2316(norm)\n",
      "       13    0.000    0.000    0.002    0.000 linear.py:68(__init__)\n",
      "       13    0.000    0.000    0.001    0.000 linear.py:79(reset_parameters)\n",
      "   539046    0.901    0.000   19.857    0.000 linear.py:86(forward)\n",
      "  2888831    7.497    0.000  291.823    0.000 linesearch.py:689(scalar_search_armijo)\n",
      "        2    0.000    0.000    0.024    0.012 model_utils.py:17(load_model)\n",
      "        2    0.000    0.000    0.002    0.001 model_utils.py:6(save_model)\n",
      "    39/12    0.000    0.000    0.000    0.000 module.py:1017(named_modules)\n",
      "     36/4    0.000    0.000    0.000    0.000 module.py:1055(train)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:1075(eval)\n",
      "       26    0.000    0.000    0.000    0.000 module.py:138(register_parameter)\n",
      "    34/11    0.000    0.000    0.002    0.000 module.py:201(_apply)\n",
      "       48    0.000    0.000    0.000    0.000 module.py:205(compute_should_use_set_data)\n",
      "       11    0.000    0.000    0.002    0.000 module.py:360(to)\n",
      "       48    0.000    0.000    0.001    0.000 module.py:438(convert)\n",
      "643009/624589    1.779    0.000  205.342    0.000 module.py:540(__call__)\n",
      "  1623659    0.712    0.000    0.712    0.000 module.py:580(__getattr__)\n",
      "   977280    1.154    0.000    1.662    0.000 module.py:596(__setattr__)\n",
      "       40    0.000    0.000    0.000    0.000 module.py:597(remove_from)\n",
      "       18    0.000    0.000    0.000    0.000 module.py:661(_save_to_state_dict)\n",
      "     18/2    0.000    0.000    0.000    0.000 module.py:681(state_dict)\n",
      "    97534    0.473    0.000    2.178    0.000 module.py:71(__init__)\n",
      "       18    0.000    0.000    0.001    0.000 module.py:721(_load_from_state_dict)\n",
      "       18    0.000    0.000    0.000    0.000 module.py:758(<dictcomp>)\n",
      "        2    0.000    0.000    0.001    0.000 module.py:796(load_state_dict)\n",
      "     18/2    0.000    0.000    0.001    0.000 module.py:824(load)\n",
      "       13    0.000    0.000    0.000    0.000 module.py:850(_named_members)\n",
      "       13    0.000    0.000    0.000    0.000 module.py:863(parameters)\n",
      "       13    0.000    0.000    0.000    0.000 module.py:887(named_parameters)\n",
      "       11    0.000    0.000    0.000    0.000 module.py:908(<lambda>)\n",
      "      125    0.000    0.000    0.000    0.000 module.py:961(children)\n",
      "      125    0.000    0.000    0.000    0.000 module.py:970(named_children)\n",
      "  4036206    1.085    0.000    1.966    0.000 mol_features.py:53(get_bt_index)\n",
      " 37440523   10.073    0.000   83.317    0.000 mol_features.py:67(onek_unk_encoding)\n",
      " 37440523   73.244    0.000   73.244    0.000 mol_features.py:71(<listcomp>)\n",
      "  6588947   18.807    0.000  132.581    0.000 mol_features.py:74(get_atom_features)\n",
      "  4495788    2.628    0.000   11.799    0.000 mol_features.py:95(get_bond_features)\n",
      "      921   18.043    0.020  178.552    0.194 mol_graph.py:168(get_graph_inputs)\n",
      "  3975950    9.882    0.000    9.882    0.000 mol_graph.py:20(__init__)\n",
      "  8531994    1.383    0.000    1.859    0.000 mol_graph.py:43(add_bond)\n",
      "  8531994   16.917    0.000   16.917    0.000 mol_graph.py:48(__init__)\n",
      "   176612    0.043    0.000    0.043    0.000 mol_graph.py:61(__init__)\n",
      "     1842    0.005    0.000   92.393    0.050 mol_graph.py:74(__init__)\n",
      "     1842   62.442    0.034   92.388    0.050 mol_graph.py:93(_parse_molecules)\n",
      "        1    0.000    0.000    0.002    0.002 mol_opt.py:13(__init__)\n",
      "      921    0.056    0.000  246.074    0.267 mol_opt.py:28(encode)\n",
      "      921    7.491    0.008   65.038    0.071 mol_opt.py:34(project)\n",
      "      921    0.008    0.000    0.136    0.000 mol_opt.py:48(optimize)\n",
      "      921    0.003    0.000  246.212    0.267 mol_opt.py:51(forward)\n",
      "  1998380    0.226    0.000    0.226    0.000 multiarray.py:1043(copyto)\n",
      "  4499472    0.362    0.000    0.362    0.000 multiarray.py:145(concatenate)\n",
      "  2914091    0.294    0.000    0.294    0.000 multiarray.py:707(dot)\n",
      "   441530    0.063    0.000    0.063    0.000 multiarray.py:77(empty_like)\n",
      "  1998380    1.404    0.000    8.346    0.000 numeric.py:159(ones)\n",
      "  2888831    8.736    0.000  326.668    0.000 optim.py:19(line_search_armijo)\n",
      "  5030071   18.687    0.000  284.326    0.000 optim.py:59(phi)\n",
      "  2888831    2.637    0.000  329.305    0.000 optim.py:75(solve_linesearch)\n",
      "      828    0.014    0.000    0.133    0.000 optimizer.py:159(zero_grad)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:180(add_param_group)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:32(__init__)\n",
      "   497177   13.125    0.000   21.755    0.000 ot_modules.py:13(compute_cost_mat)\n",
      "   497177   12.105    0.000  161.346    0.000 ot_modules.py:43(compute_ot)\n",
      "      921    0.010    0.000    0.010    0.000 ot_utils.py:11(<listcomp>)\n",
      "      921    0.016    0.000    0.016    0.000 ot_utils.py:12(<listcomp>)\n",
      "      921    0.369    0.000    0.369    0.000 ot_utils.py:14(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 ot_utils.py:40(__init__)\n",
      "      921    9.898    0.011 1295.514    1.407 ot_utils.py:45(__call__)\n",
      "      921  150.940    0.164  153.345    0.166 ot_utils.py:9(encode_target)\n",
      "    88306   31.189    0.000  165.737    0.002 ot_utils.py:94(compute_barycenter)\n",
      "       24    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
      "        2    0.000    0.000    0.026    0.013 popen_fork.py:16(__init__)\n",
      "        2    0.000    0.000    0.034    0.017 popen_fork.py:24(poll)\n",
      "        2    0.000    0.000    0.034    0.017 popen_fork.py:43(wait)\n",
      "        2    0.000    0.000    0.025    0.013 popen_fork.py:63(_launch)\n",
      "        2    0.000    0.000    0.000    0.000 posixpath.py:338(normpath)\n",
      "        2    0.000    0.000    0.000    0.000 posixpath.py:376(abspath)\n",
      "        6    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
      "        2    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
      "        4    0.000    0.000    0.000    0.000 posixpath.py:75(join)\n",
      "        2    0.000    0.000    0.034    0.017 process.py:118(join)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:162(daemon)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:190(ident)\n",
      "       22    0.000    0.000    0.000    0.000 process.py:35(current_process)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:52(_cleanup)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:71(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:83(<genexpr>)\n",
      "        2    0.000    0.000    0.026    0.013 process.py:95(start)\n",
      "        2    0.000    0.000    0.000    0.000 queues.py:131(close)\n",
      "        2    0.000    0.000    0.000    0.000 queues.py:147(cancel_join_thread)\n",
      "        2    0.000    0.000    0.003    0.002 queues.py:155(_start_thread)\n",
      "        2    0.000    0.000    0.000    0.000 queues.py:196(_finalize_close)\n",
      "        4    0.000    0.000    0.001    0.000 queues.py:36(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)\n",
      "      923    0.005    0.000    0.023    0.000 queues.py:80(put)\n",
      "      921    0.009    0.000    0.628    0.001 queues.py:91(get)\n",
      "      176    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
      "      176    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
      "      923    0.023    0.000    0.034    0.000 sampler.py:198(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 sampler.py:61(__iter__)\n",
      "      921    0.000    0.000    0.000    0.000 selectors.py:198(__enter__)\n",
      "      921    0.002    0.000    0.003    0.000 selectors.py:20(_fileobj_to_fd)\n",
      "      921    0.001    0.000    0.002    0.000 selectors.py:201(__exit__)\n",
      "      921    0.002    0.000    0.002    0.000 selectors.py:208(__init__)\n",
      "      921    0.001    0.000    0.004    0.000 selectors.py:214(_fileobj_lookup)\n",
      "      921    0.005    0.000    0.011    0.000 selectors.py:233(register)\n",
      "      921    0.001    0.000    0.001    0.000 selectors.py:268(close)\n",
      "      921    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)\n",
      "      921    0.003    0.000    0.006    0.000 selectors.py:346(__init__)\n",
      "      921    0.002    0.000    0.014    0.000 selectors.py:350(register)\n",
      "      921    0.004    0.000    0.015    0.000 selectors.py:365(select)\n",
      "      921    0.001    0.000    0.001    0.000 selectors.py:62(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 serialization.py:119(_cpu_tag)\n",
      "       24    0.000    0.000    0.000    0.000 serialization.py:124(_cuda_tag)\n",
      "       24    0.000    0.000    0.000    0.000 serialization.py:129(_cpu_deserialize)\n",
      "       24    0.000    0.000    0.000    0.000 serialization.py:134(validate_cuda_device)\n",
      "       24    0.000    0.000    0.001    0.000 serialization.py:152(_cuda_deserialize)\n",
      "       24    0.000    0.000    0.000    0.000 serialization.py:167(location_tag)\n",
      "       24    0.000    0.000    0.001    0.000 serialization.py:176(default_restore_location)\n",
      "       24    0.000    0.000    0.000    0.000 serialization.py:186(normalize_storage_type)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:196(_is_path)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:203(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:206(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:214(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:217(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:232(_open_file_like)\n",
      "       26    0.000    0.000    0.000    0.000 serialization.py:275(_is_compressed_file)\n",
      "       26    0.000    0.000    0.000    0.000 serialization.py:283(_should_read_directly)\n",
      "        2    0.000    0.000    0.000    0.000 serialization.py:299(_check_seekable)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:316(_check_dill_version)\n",
      "        2    0.000    0.000    0.002    0.001 serialization.py:335(save)\n",
      "        2    0.000    0.000    0.002    0.001 serialization.py:373(_legacy_save)\n",
      "      712    0.000    0.000    0.000    0.000 serialization.py:386(persistent_id)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:48(_is_zipfile)\n",
      "        2    0.000    0.000    0.019    0.010 serialization.py:499(load)\n",
      "        2    0.000    0.000    0.019    0.009 serialization.py:613(_legacy_load)\n",
      "        2    0.000    0.000    0.000    0.000 serialization.py:659(legacy_load)\n",
      "       24    0.000    0.000    0.001    0.000 serialization.py:713(persistent_load)\n",
      "       48    0.000    0.000    0.000    0.000 serialization.py:787(_maybe_decode_ascii)\n",
      "        2    0.000    0.000    0.000    0.000 serialization.py:799(_get_restore_location)\n",
      "     1842    0.001    0.000    0.002    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
      "  2888831    0.302    0.000    0.302    0.000 shape_base.py:21(_atleast_1d_dispatcher)\n",
      "  2888831    3.418    0.000    5.867    0.000 shape_base.py:25(atleast_1d)\n",
      "     1842    0.002    0.000    0.003    0.000 shape_base.py:348(_stack_dispatcher)\n",
      "     1842    0.012    0.000    5.899    0.003 shape_base.py:357(stack)\n",
      "     1842    0.922    0.001    2.557    0.001 shape_base.py:420(<listcomp>)\n",
      "     1842    0.551    0.000    0.551    0.000 shape_base.py:424(<setcomp>)\n",
      "     1842    0.945    0.001    0.945    0.001 shape_base.py:432(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)\n",
      "        2    0.000    0.000    0.000    0.000 signal_handling.py:63(handler)\n",
      "       27    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "       22    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)\n",
      "        8    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:144(__init__)\n",
      "       10    0.000    0.000    0.001    0.000 synchronize.py:161(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:287(notify_all)\n",
      "        2    0.000    0.000    0.001    0.000 synchronize.py:334(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:345(set)\n",
      "       22    0.001    0.000    0.001    0.000 synchronize.py:50(__init__)\n",
      "       22    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:1087(fromtarfile)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:1411(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:1522(open)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:1613(taropen)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:2276(next)\n",
      "        2    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
      "       22    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
      "       22    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
      "       22    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
      "      828    0.007    0.000   69.823    0.084 tensor.py:170(backward)\n",
      "   232259    3.195    0.000    3.195    0.000 tensor.py:25(wrapped)\n",
      "     6668    0.002    0.000    0.004    0.000 tensor.py:470(__hash__)\n",
      "    39776    0.036    0.000    0.056    0.000 tensor.py:737(grad)\n",
      "       24    0.000    0.000    0.000    0.000 tensor.py:78(__reduce_ex__)\n",
      "       31    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       31    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1120(daemon)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1230(current_thread)\n",
      "       10    0.000    0.000    0.000    0.000 threading.py:215(__init__)\n",
      "      931    0.001    0.000    0.002    0.000 threading.py:239(__enter__)\n",
      "      931    0.001    0.000    0.001    0.000 threading.py:242(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:248(_release_save)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:251(_acquire_restore)\n",
      "      931    0.001    0.000    0.001    0.000 threading.py:254(_is_owned)\n",
      "        6    0.000    0.000    0.001    0.000 threading.py:263(wait)\n",
      "      925    0.005    0.000    0.010    0.000 threading.py:334(notify)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:498(__init__)\n",
      "       35    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        6    0.000    0.000    0.001    0.000 threading.py:533(wait)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:757(__init__)\n",
      "        2    0.000    0.000    0.003    0.001 threading.py:828(start)\n",
      "        2    0.000    0.000    0.000    0.000 train_mol_opt.py:22(get_latest_model)\n",
      "        2    0.000    0.000    0.000    0.000 train_mol_opt.py:23(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 train_mol_opt.py:24(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 train_mol_opt.py:26(<listcomp>)\n",
      "        1    0.009    0.009 1921.114 1921.114 train_mol_opt.py:34(main)\n",
      "        2    5.817    2.909 1921.078  960.539 train_mol_opt.py:88(run_func)\n",
      "       26    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
      "        6    0.000    0.000    0.000    0.000 util.py:151(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 util.py:167(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 util.py:191(cancel)\n",
      "        2    0.000    0.000    0.001    0.001 util.py:395(_flush_std_streams)\n",
      "        4    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
      "       36    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
      "       24    0.000    0.000    0.000    0.000 weakref.py:109(remove)\n",
      "       26    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
      "       26    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
      "       26    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
      "      973    0.001    0.000    0.001    0.000 {built-in method __new__ of type object at 0x564617763e00}\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method _has_compatible_shallow_copy_type}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _pickle.dump}\n",
      "      921    0.026    0.000    0.026    0.000 {built-in method _pickle.loads}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _pickle.load}\n",
      "      921    0.002    0.000    0.002    0.000 {built-in method _struct.unpack}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        2    0.002    0.001    0.002    0.001 {built-in method _thread.start_new_thread}\n",
      "    88306    0.344    0.000    0.344    0.000 {built-in method _warnings.warn}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "   357829    7.501    0.000    7.501    0.000 {built-in method addmm}\n",
      "     2763    0.036    0.000    0.036    0.000 {built-in method argmax}\n",
      "  5778550    0.616    0.000    0.616    0.000 {built-in method builtins.abs}\n",
      "  1078092    0.391    0.000    1.051    0.000 {built-in method builtins.any}\n",
      "        1    0.000    0.000 1921.114 1921.114 {built-in method builtins.exec}\n",
      " 22206573    2.800    0.000    2.800    0.000 {built-in method builtins.getattr}\n",
      "  1119828    0.382    0.000    0.382    0.000 {built-in method builtins.hasattr}\n",
      "     6698    0.001    0.000    0.001    0.000 {built-in method builtins.id}\n",
      " 18231877    3.252    0.000    3.252    0.000 {built-in method builtins.isinstance}\n",
      "  3708892    0.468    0.000    0.468    0.000 {built-in method builtins.issubclass}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "20179235/20179233    1.854    0.000    1.854    0.000 {built-in method builtins.len}\n",
      "   176614    0.666    0.000    0.666    0.000 {built-in method builtins.max}\n",
      "     1902    0.001    0.000    0.036    0.000 {built-in method builtins.next}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "     1842    0.002    0.000    0.002    0.000 {built-in method builtins.sum}\n",
      "   354145   10.482    0.000   10.482    0.000 {built-in method cat}\n",
      "     5526    0.011    0.000    0.011    0.000 {built-in method dropout}\n",
      "    91992    0.416    0.000    0.416    0.000 {built-in method empty}\n",
      "   408871    4.214    0.000    4.214    0.000 {built-in method frobenius_norm}\n",
      "     4605    0.066    0.000    0.066    0.000 {built-in method index_select}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "      921    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
      "    94993    0.026    0.000    0.026    0.000 {built-in method math.sqrt}\n",
      "  2528215   31.368    0.000   31.368    0.000 {built-in method matmul}\n",
      " 32575877   50.119    0.000   50.119    0.000 {built-in method numpy.array}\n",
      "60318542/58462281   33.395    0.000  186.514    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     1842    0.001    0.000    0.001    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "  1998380    1.988    0.000    1.988    0.000 {built-in method numpy.empty}\n",
      "   531678    0.819    0.000    0.819    0.000 {built-in method numpy.zeros}\n",
      "      828    0.023    0.000    0.023    0.000 {built-in method ones_like}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        2    0.025    0.012    0.025    0.012 {built-in method posix.fork}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "       58    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.listdir}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "     1842    0.452    0.000    0.452    0.000 {built-in method posix.read}\n",
      "        2    0.034    0.017    0.034    0.017 {built-in method posix.waitpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method randn}\n",
      "   269523    3.139    0.000    3.139    0.000 {built-in method relu}\n",
      "      921    0.001    0.000    0.001    0.000 {built-in method select.poll}\n",
      "   177533    6.085    0.000    6.085    0.000 {built-in method stack}\n",
      "  3025392   32.113    0.000   32.113    0.000 {built-in method sum}\n",
      "  1473172   44.867    0.000   44.867    0.000 {built-in method tensor}\n",
      "     2763    0.001    0.000    0.001    0.000 {built-in method time.monotonic}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       72    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._error_if_any_worker_fails}\n",
      "   643009    0.525    0.000    0.525    0.000 {built-in method torch._C._get_tracing_state}\n",
      "    97535    0.195    0.000    0.195    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "     1842    0.030    0.000    0.030    0.000 {built-in method torch._C._nn.leaky_relu}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}\n",
      "   355072    0.079    0.000    0.079    0.000 {built-in method torch._C.is_grad_enabled}\n",
      "   355072    0.058    0.000    0.058    0.000 {built-in method torch._C.set_grad_enabled}\n",
      "  1942732    5.760    0.000    5.760    0.000 {built-in method transpose}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method zeros_like}\n",
      "   410713    4.182    0.000    4.182    0.000 {built-in method zeros}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "      931    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "      931    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}\n",
      "       24    0.017    0.001    0.017    0.001 {method '_set_from_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
      "       24    0.001    0.000    0.001    0.000 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
      "     1852    0.003    0.000    0.003    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "      980    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       84    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "    13248    0.104    0.000    0.104    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "     6624    0.054    0.000    0.054    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
      "     6624    0.052    0.000    0.052    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
      "      958    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      " 32959411    2.394    0.000    2.394    0.000 {method 'append' of 'list' objects}\n",
      "      176    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
      "      921    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
      "  2914098   20.604    0.000   20.604    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "   441530    1.381    0.000    1.381    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
      "   762095   15.312    0.000   15.312    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
      "   762119    0.866    0.000    0.866    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
      "     6616    0.018    0.000    0.018    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
      "  1212883    0.304    0.000    0.304    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "  6595404    6.685    0.000    6.685    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.001    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
      "      921    0.008    0.000    0.008    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
      "  1558691   15.133    0.000   15.133    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BufferedWriter' objects}\n",
      "    88336    0.073    0.000    0.073    0.000 {method 'format' of 'str' objects}\n",
      "  2931796    0.276    0.000    0.276    0.000 {method 'get' of 'dict' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
      "      298    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "     1842    0.001    0.000    0.001    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'has_names' of 'torch._C._TensorBase' objects}\n",
      "  4036206    0.881    0.000    0.881    0.000 {method 'index' of 'list' objects}\n",
      "       48    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "      888    0.001    0.000    0.001    0.000 {method 'item' of 'numpy.generic' objects}\n",
      "      923    0.026    0.000    0.026    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "      268    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      " 23927920    2.342    0.000    2.342    0.000 {method 'items' of 'dict' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        2    0.000    0.000    0.002    0.001 {method 'load' of '_pickle.Unpickler' objects}\n",
      "    91069    1.533    0.000    1.533    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
      "     1842    0.020    0.000    0.020    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
      "   264931    0.035    0.000    0.035    0.000 {method 'lower' of 'str' objects}\n",
      "   269523    5.165    0.000    5.165    0.000 {method 'matmul' of 'torch._C._TensorBase' objects}\n",
      "   706448    0.295    0.000    3.057    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "  2888831    1.422    0.000   13.348    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "    13248    0.120    0.000    0.120    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
      "   264918    1.115    0.000    1.115    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
      "    88306    0.710    0.000    0.710    0.000 {method 'normal_' of 'torch._C._TensorBase' objects}\n",
      "      828    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "   762095    0.859    0.000    0.859    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "      921    0.008    0.000    0.008    0.000 {method 'poll' of 'select.poll' objects}\n",
      "   441530    3.195    0.000    3.195    0.000 {method 'rand' of 'numpy.random.mtrand.RandomState' objects}\n",
      "    88306    0.018    0.000    0.018    0.000 {method 'random' of '_random.Random' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "  1854419    1.193    0.000    1.193    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      " 34118582   80.916    0.000   80.916    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      921    0.001    0.000    0.001    0.000 {method 'register' of 'select.poll' objects}\n",
      "     1844    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "      927    0.005    0.000    0.005    0.000 {method 'release' of '_thread.lock' objects}\n",
      "      921    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "   176612    3.321    0.000    3.321    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
      " 46409948   83.376    0.000   83.376    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "      828   69.781    0.084   69.781    0.084 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "   441530    8.425    0.000    9.212    0.000 {method 'shuffle' of 'numpy.random.mtrand.RandomState' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
      "  1180248    0.504    0.000    0.504    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "       66    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "     6624    0.065    0.000    0.065    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
      "      250    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "  6595404    2.255    0.000   19.082    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "    92911    0.872    0.000    0.872    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "   539046    2.143    0.000    2.143    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "       38    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
      "       48    0.001    0.000    0.001    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      " 38465779   10.968    0.000   10.968    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "  1059672    3.519    0.000    3.519    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "  1286054    0.161    0.000    0.161    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "  5507170   14.797    0.000   14.797    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "     1842    0.072    0.000    0.072    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "     6616    0.074    0.000    0.074    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
      "  3297702    0.636    0.000    0.636    0.000 {ot.lp.emd_wrap.check_result}\n",
      "  3297702  161.197    0.000  161.197    0.000 {ot.lp.emd_wrap.emd_c}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run('main(args, train_data_loader = train_data_loader, val_data_loader = val_data_loader)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try out some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedding, x_delta = molopt.forward(X)\n",
    "y_embedding = molopt.encode(Y)\n",
    "y_aligned = molopt.align(x_embedding, X, y_embedding, Y)\n",
    "xhat_delta = molopt.delta(x_embedding, y_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2098, 50])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 51.2291, -93.8777,  67.3637,  ..., -48.3670, -35.8315,  35.6972],\n",
       "        [ 31.9506, -89.4450,  59.7837,  ..., -90.8423, -70.3604,  44.9571],\n",
       "        [ 38.3420, -81.8791,  54.3903,  ..., -79.0527, -53.9882,  40.6473],\n",
       "        ...,\n",
       "        [ 31.7734,  -5.8973,  50.6671,  ..., -31.8489, -61.3425,  43.7533],\n",
       "        [ 42.1679, -35.2635,  58.6213,  ..., -89.3948, -68.3651,  42.4910],\n",
       "        [ 35.0003, -31.2854,  65.7140,  ..., -27.6888, -69.8974,  40.5666]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2541,  0.9079,  2.0818,  ..., -0.4530, -0.6870, 10.7181],\n",
       "        [-4.7226,  2.0234,  3.6004,  ..., -7.1243, -5.1279,  7.1974],\n",
       "        [-0.2887, -1.2837, 11.8498,  ..., -2.4560,  0.2970,  4.6080],\n",
       "        ...,\n",
       "        [ 0.2980, -3.5470,  1.3268,  ..., -1.1102, -1.8826,  6.5500],\n",
       "        [-1.6307, -0.2229,  1.7089,  ..., -4.2314,  0.2962,  3.2936],\n",
       "        [-1.9074, -1.6668, -0.7295,  ...,  3.5026, -6.8949,  4.3016]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  49.3381,  -93.0658,   71.5300,  ...,  -47.5423,  -28.6862,\n",
       "           35.0504],\n",
       "        [  27.5109,  -83.0824,   59.8990,  ..., -106.6606,  -69.4454,\n",
       "           43.3924],\n",
       "        [  44.8429,  -84.7408,   60.8294,  ...,  -75.3584,  -52.8182,\n",
       "           41.3485],\n",
       "        ...,\n",
       "        [  31.7734,   -5.8973,   50.6671,  ...,  -31.8489,  -61.3425,\n",
       "           43.7533],\n",
       "        [  42.1679,  -35.2635,   58.6213,  ...,  -89.3948,  -68.3651,\n",
       "           42.4910],\n",
       "        [  35.0003,  -31.2854,   65.7140,  ...,  -27.6888,  -69.8974,\n",
       "           40.5666]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_delta - xhat_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c48cdf3c1274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmolopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mxhat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "molopt.delta(x_embedding, y) - xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<otgnn.graph.mol_graph.Molecule at 0x7fec37dd4f60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mols[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
