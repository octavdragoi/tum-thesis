{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from otgnn.models import GCN\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "\n",
    "from mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt.arguments import get_args\n",
    "from mol_opt.train_mol_opt import main, get_latest_model\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/octav/gitrepos/tum-thesis'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"val\", 48, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\", \"-cuda\"]\n",
    "args = get_args()\n",
    "args.output_dir = \"mol_opt/output/\"\n",
    "# args.device = \"cpu\"\n",
    "gcn = GCN(args).to(args.device)\n",
    "opt = torch.nn.Linear(50, 50).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (W_message_i): Linear(in_features=100, out_features=50, bias=False)\n",
       "  (W_message_h): Linear(in_features=50, out_features=50, bias=False)\n",
       "  (W_message_o): Linear(in_features=143, out_features=50, bias=True)\n",
       "  (W_mol_h): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
       "  (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (W_message_i): Linear(in_features=100, out_features=50, bias=False)\n",
       "  (W_message_h): Linear(in_features=50, out_features=50, bias=False)\n",
       "  (W_message_o): Linear(in_features=143, out_features=50, bias=True)\n",
       "  (W_mol_h): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
       "  (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0992, -0.0890,  0.1723,  ...,  0.0831,  0.0952,  0.1011],\n",
       "        [ 0.0569, -0.1528,  0.1374,  ...,  0.0197,  0.0662,  0.2205],\n",
       "        [ 0.0497, -0.1381,  0.1233,  ...,  0.0302,  0.0377,  0.1758],\n",
       "        ...,\n",
       "        [ 0.0960, -0.0695,  0.1740,  ...,  0.0660,  0.1047,  0.0696],\n",
       "        [ 0.0818, -0.1535,  0.1402,  ...,  0.0942,  0.1711,  0.2707],\n",
       "        [-0.0520, -0.1821,  0.1257,  ...,  0.0616,  0.1846,  0.2143]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt(gcn.forward(Y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1061, 50])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn.forward(X)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  18   42   61   87  106  130  150  167  187  212  237  262  286  308\n",
      "  331  353  375  394  418  437  457  477  500  526  552  575  598  622\n",
      "  643  663  688  711  735  757  778  799  816  842  862  884  905  929\n",
      "  950  969  993 1017 1039 1061]\n"
     ]
    }
   ],
   "source": [
    "print (np.cumsum(([len(x.atoms) for x in X.mols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.mols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolOpt(\n",
       "  (GCN): GCN(\n",
       "    (W_message_i): Linear(in_features=100, out_features=50, bias=False)\n",
       "    (W_message_h): Linear(in_features=50, out_features=50, bias=False)\n",
       "    (W_message_o): Linear(in_features=143, out_features=50, bias=True)\n",
       "    (W_mol_h): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (W_mol_o): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (dropout_gcn): Dropout(p=0.0, inplace=False)\n",
       "    (dropout_ffn): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (opt0): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (opt1): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (delta_loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mol_opt import mol_opt\n",
    "molopt = mol_opt.MolOpt(args).to(device = args.device)\n",
    "molopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3221,  0.0038,  0.0035,  ..., -0.1331,  0.1204,  0.1619],\n",
       "        [-0.0960, -0.0575,  0.0851,  ..., -0.1013,  0.1716,  0.2112],\n",
       "        [-0.1319,  0.0630, -0.1862,  ...,  0.0449,  0.1181,  0.1438],\n",
       "        ...,\n",
       "        [-0.1173, -0.0720,  0.1398,  ..., -0.0912,  0.1875,  0.2520],\n",
       "        [-0.0846, -0.0290, -0.0092,  ..., -0.2125,  0.1703,  0.1214],\n",
       "        [-0.1873,  0.0246, -0.1750,  ...,  0.0147,  0.1562,  0.2467]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molopt.align(molopt.encode(X), X, molopt.encode(Y), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3221,  0.0038,  0.0035,  ..., -0.1331,  0.1204,  0.1619],\n",
       "        [-0.1142,  0.0280,  0.1557,  ..., -0.2182,  0.1711,  0.2604],\n",
       "        [-0.1235, -0.0081,  0.0759,  ..., -0.1747,  0.1613,  0.2248],\n",
       "        ...,\n",
       "        [-0.2643,  0.0470, -0.0293,  ..., -0.1391,  0.1221,  0.1442],\n",
       "        [-0.1873,  0.0246, -0.1750,  ...,  0.0147,  0.1562,  0.2467],\n",
       "        [-0.0846, -0.0290, -0.0092,  ..., -0.2125,  0.1703,  0.1214]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molopt.encode(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0144, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molopt.forward_train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: mol_opt/output//model_test\n"
     ]
    }
   ],
   "source": [
    "save_model(molopt, args, args.output_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mol_opt/output/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(args.n_epochs):\n",
    "#     start = time.time()\n",
    "#     for idx, i in enumerate(data_loader):\n",
    "#         X = (MolGraph(i[0]))\n",
    "#         Y = (MolGraph(i[1]))\n",
    "# \n",
    "#         # create your optimizer\n",
    "#         optimizer = torch.optim.SGD(molopt.parameters(), lr=0.01)\n",
    "# \n",
    "#         # in your training loop:\n",
    "#         optimizer.zero_grad()   # zero the gradient buffers\n",
    "#         loss = molopt.forward_train(X, Y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()    # Does the update\n",
    "# \n",
    "#         print (\"Iter: {}, loss: {}\".format(idx, loss.item()))\n",
    "#     end = time.time()\n",
    "#     print(\"Time for epoch {}: {}\", epoch, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 18),\n",
       " (18, 24),\n",
       " (42, 19),\n",
       " (61, 26),\n",
       " (87, 19),\n",
       " (106, 24),\n",
       " (130, 20),\n",
       " (150, 17),\n",
       " (167, 20),\n",
       " (187, 25),\n",
       " (212, 25),\n",
       " (237, 25),\n",
       " (262, 24),\n",
       " (286, 22),\n",
       " (308, 23),\n",
       " (331, 22),\n",
       " (353, 22),\n",
       " (375, 19),\n",
       " (394, 24),\n",
       " (418, 19),\n",
       " (437, 20),\n",
       " (457, 20),\n",
       " (477, 23),\n",
       " (500, 26),\n",
       " (526, 26),\n",
       " (552, 23),\n",
       " (575, 23),\n",
       " (598, 24),\n",
       " (622, 21),\n",
       " (643, 20),\n",
       " (663, 25),\n",
       " (688, 23),\n",
       " (711, 24),\n",
       " (735, 22),\n",
       " (757, 21),\n",
       " (778, 21),\n",
       " (799, 17),\n",
       " (816, 26),\n",
       " (842, 20),\n",
       " (862, 22),\n",
       " (884, 21),\n",
       " (905, 24),\n",
       " (929, 21),\n",
       " (950, 19),\n",
       " (969, 24),\n",
       " (993, 24),\n",
       " (1017, 22),\n",
       " (1039, 22)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0455,  0.0447,  0.0261,  ..., -0.0160,  0.0526,  0.0204],\n",
       "        [-0.0465,  0.0597,  0.0177,  ..., -0.1785, -0.0618,  0.0922],\n",
       "        [ 0.0161,  0.0673, -0.1091,  ...,  0.0081, -0.0677,  0.1738],\n",
       "        ...,\n",
       "        [ 0.0850, -0.0669, -0.0290,  ..., -0.0392, -0.0300,  0.0311],\n",
       "        [ 0.1073, -0.0826, -0.0462,  ..., -0.0227, -0.0654,  0.0300],\n",
       "        [ 0.0796,  0.0683,  0.0362,  ..., -0.0448, -0.0863,  0.0600]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.narrow(0, 0, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 50])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding[0:22,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.2475e-02,  4.4592e-02,  4.1157e-02, -6.2958e-02, -2.6449e-02,\n",
       "          5.1672e-03, -4.6384e-02, -5.3797e-02, -7.3464e-02, -7.3005e-02,\n",
       "         -1.7704e-02,  8.3490e-02, -1.3573e-01,  8.2092e-03, -5.4852e-02,\n",
       "         -1.0005e-01,  1.0265e-01,  8.8467e-02,  1.8191e-02,  8.6351e-02,\n",
       "          1.7423e-01,  2.4751e-02,  6.3913e-03,  3.5624e-03,  8.4073e-03,\n",
       "         -2.3538e-02,  1.3579e-01,  4.8769e-02,  1.5200e-01, -2.5218e-02,\n",
       "          2.4999e-01, -7.4404e-03,  6.2257e-02, -1.2847e-01, -1.4130e-01,\n",
       "          1.4734e-01, -2.1842e-03,  8.3792e-02, -8.7801e-02,  4.2352e-02,\n",
       "          2.5093e-01, -3.2312e-02,  7.7363e-02,  6.2747e-02,  1.1126e-01,\n",
       "          6.4715e-02, -3.6868e-02,  1.1756e-03,  7.7242e-03,  7.6595e-03],\n",
       "        [ 2.0119e-03, -1.1420e-01, -6.6094e-03, -6.3875e-02,  8.7873e-02,\n",
       "          1.7288e-02,  9.8871e-02, -1.4052e-01, -5.1341e-02, -1.6861e-01,\n",
       "         -7.1023e-02,  3.3994e-02,  2.1864e-02, -9.5770e-03,  4.5321e-02,\n",
       "          1.1468e-01,  1.7144e-01,  1.0275e-01,  6.4650e-02,  6.7548e-02,\n",
       "          1.1096e-01, -1.7862e-01, -1.1572e-01,  3.9683e-03,  2.1316e-02,\n",
       "          5.1599e-02,  1.9089e-02, -9.7457e-02, -5.7705e-02, -3.2013e-02,\n",
       "          1.1510e-01, -1.3428e-01,  7.6023e-02,  1.1371e-01, -1.2995e-01,\n",
       "          1.5539e-01,  6.3551e-02,  6.3039e-02, -3.3870e-02,  2.1248e-01,\n",
       "         -5.7164e-03,  5.5832e-02, -1.1985e-01,  3.5071e-02, -5.7318e-02,\n",
       "         -6.9915e-02, -1.2773e-02,  2.2984e-02, -1.9392e-01,  5.6128e-02],\n",
       "        [-7.4831e-02,  1.9202e-02,  2.6232e-02, -4.9086e-02,  1.6536e-01,\n",
       "          1.1132e-02,  2.0409e-02, -1.3349e-01,  1.0190e-02, -1.5394e-01,\n",
       "         -6.3496e-02, -6.5835e-02,  1.8784e-02,  1.0282e-02,  1.2250e-01,\n",
       "          3.5327e-02,  9.5941e-02,  9.9225e-02,  1.0245e-01,  1.0312e-01,\n",
       "          1.3071e-01, -3.9658e-02, -1.2481e-01,  2.3864e-02,  4.8434e-02,\n",
       "          2.9407e-02, -7.0972e-02, -9.2338e-02, -2.1639e-02,  1.9514e-02,\n",
       "          9.3547e-02, -9.2258e-02,  1.4259e-01,  1.0263e-01, -1.0799e-01,\n",
       "          3.9730e-02, -4.9214e-03,  8.1520e-03,  5.2861e-02,  1.0459e-01,\n",
       "          3.7120e-02,  5.9990e-02, -7.3661e-02,  4.6982e-02,  1.8996e-02,\n",
       "         -1.5189e-02,  5.7292e-02, -1.1482e-01, -1.5137e-01,  4.1276e-02],\n",
       "        [ 1.1107e-01, -1.1086e-01, -6.8608e-02, -7.9348e-02, -9.8589e-03,\n",
       "         -3.3475e-02,  2.5361e-02, -1.0676e-01, -3.0541e-02, -1.3399e-01,\n",
       "          7.1472e-02,  1.2067e-02, -1.1203e-01, -6.5732e-02,  3.8560e-02,\n",
       "         -3.7062e-02,  5.2307e-03, -7.6133e-04,  1.2335e-01,  1.3654e-01,\n",
       "          5.2324e-02,  1.1503e-02, -3.3225e-02,  4.9500e-02, -3.9982e-03,\n",
       "         -1.1418e-01,  9.5772e-02, -2.7959e-02,  5.9731e-02, -7.4483e-02,\n",
       "          1.1130e-01, -5.3144e-02,  4.5784e-02,  7.8103e-02, -9.3262e-02,\n",
       "          1.4370e-01,  3.0391e-02,  1.0941e-02, -6.8041e-02,  1.2573e-01,\n",
       "          8.3403e-02, -1.9750e-02,  4.3076e-02,  5.5770e-02, -1.0587e-04,\n",
       "          1.9467e-02, -4.1530e-02, -5.3311e-02, -6.1343e-02,  5.2183e-02],\n",
       "        [ 1.4965e-01, -4.3767e-02, -1.6036e-02, -4.3057e-02, -1.3387e-02,\n",
       "         -4.2743e-02,  3.6037e-02, -1.3668e-01,  7.7198e-03, -1.7244e-01,\n",
       "          4.1195e-02,  7.0311e-02, -1.4857e-01, -1.4191e-01,  5.1213e-02,\n",
       "         -7.0471e-02,  7.4260e-02,  2.3955e-02,  4.7956e-02,  1.9671e-01,\n",
       "         -2.9506e-02, -7.5589e-02, -4.6484e-02, -9.1569e-02,  1.0470e-01,\n",
       "          6.0248e-03,  4.1826e-02,  5.8838e-02,  6.5742e-03,  8.4379e-02,\n",
       "         -4.3867e-02, -1.1369e-02,  1.2448e-01, -2.8557e-02,  5.5058e-02,\n",
       "          1.8164e-01,  6.6553e-03,  9.0238e-02, -2.0040e-01,  1.6113e-01,\n",
       "          1.0416e-01,  9.9796e-02, -4.6932e-02, -2.1982e-02, -1.3103e-01,\n",
       "          5.8650e-02,  1.5278e-02,  8.2953e-02, -1.0486e-01,  1.0686e-01],\n",
       "        [-1.3811e-01, -1.0962e-02,  1.5299e-01, -1.5090e-01,  4.2050e-02,\n",
       "         -7.9550e-02,  1.4646e-01, -3.8062e-02,  1.0760e-02, -9.9155e-02,\n",
       "         -1.3323e-01,  1.3856e-01, -6.6188e-02, -3.5772e-02,  1.2616e-03,\n",
       "         -5.8006e-02,  5.4338e-02,  3.4116e-02,  3.9887e-02, -2.6394e-02,\n",
       "         -3.1722e-02, -7.0152e-02, -1.0378e-01, -6.5871e-02, -2.9889e-02,\n",
       "         -4.4786e-02, -3.9086e-02,  1.8439e-02,  1.9467e-01,  1.3721e-01,\n",
       "          8.1558e-04, -2.5913e-02,  3.7295e-03, -1.0363e-01, -1.8557e-01,\n",
       "          9.6840e-02, -7.1866e-02,  1.1633e-01,  3.3533e-02, -8.6680e-02,\n",
       "          9.4380e-02,  3.4461e-02, -5.2381e-02,  7.9040e-02,  3.4064e-02,\n",
       "          1.6273e-01,  1.3577e-02, -1.4633e-01, -8.3325e-02,  1.2317e-01],\n",
       "        [ 1.3637e-01, -4.4353e-02, -4.4834e-02, -3.8192e-02, -1.4762e-02,\n",
       "         -6.8501e-02,  5.0284e-02, -1.4969e-01, -3.9461e-03, -1.5554e-01,\n",
       "          2.2196e-02,  9.1206e-02, -2.2257e-01, -9.7455e-02,  3.4719e-02,\n",
       "          5.4771e-03,  6.0597e-02,  4.3464e-02,  8.3396e-02,  1.6212e-01,\n",
       "          5.4218e-02, -9.5843e-02, -8.6093e-02, -6.3744e-02,  9.9415e-02,\n",
       "          2.2308e-02,  1.7616e-02,  2.0128e-02,  3.0082e-02,  8.9772e-02,\n",
       "         -1.0687e-02, -8.5193e-02,  1.4852e-01, -1.3911e-02,  7.9518e-02,\n",
       "          2.1588e-01,  2.2159e-02,  5.5309e-02, -2.2926e-01,  1.1593e-01,\n",
       "          1.5672e-01,  7.2799e-02, -5.9888e-04, -4.4272e-02, -7.3670e-02,\n",
       "          1.2101e-01,  6.7118e-03,  4.4005e-02, -7.9488e-02,  1.4179e-01],\n",
       "        [ 5.0304e-04, -4.7265e-02, -6.8680e-02, -1.8989e-02, -4.3069e-02,\n",
       "          1.2028e-02,  3.0058e-02, -1.1381e-01, -4.9087e-03, -9.1327e-02,\n",
       "          4.2059e-02,  3.9389e-02, -1.3250e-01, -4.4926e-02,  2.9262e-02,\n",
       "          9.3829e-03,  6.7096e-02, -1.2767e-02,  1.2730e-01,  1.1479e-01,\n",
       "         -1.2171e-03, -7.9559e-02,  1.3363e-02, -3.9249e-02,  1.0448e-01,\n",
       "         -4.9952e-02,  5.7367e-02,  7.9590e-03,  7.2742e-02,  1.9224e-02,\n",
       "         -5.6658e-02, -7.9287e-02,  3.9887e-02,  6.7840e-02,  1.2043e-01,\n",
       "          2.2017e-01, -2.5548e-02,  6.9413e-02, -1.2256e-01,  1.0479e-01,\n",
       "          8.6722e-02,  1.2362e-01, -3.2506e-02,  1.9682e-02, -4.7247e-02,\n",
       "          1.0296e-01, -2.9497e-02, -6.7464e-02, -5.0787e-02,  2.1128e-01],\n",
       "        [-8.4101e-02, -1.2952e-01,  4.6561e-03,  2.5336e-02,  8.9385e-02,\n",
       "         -3.3152e-02, -6.2429e-02, -1.1558e-01,  3.9478e-02,  7.0717e-04,\n",
       "          1.9344e-03, -1.9591e-03, -4.0175e-02, -1.8285e-01, -2.4802e-02,\n",
       "         -1.2054e-01,  4.9930e-02,  2.6806e-02,  1.5114e-02,  3.2357e-02,\n",
       "          3.1959e-02,  3.0837e-02, -1.8034e-01, -4.4719e-02, -1.4276e-02,\n",
       "         -4.3431e-03, -1.8570e-02,  1.0516e-01,  1.9579e-02,  8.9768e-02,\n",
       "          2.8135e-02, -3.8529e-02,  3.8870e-02, -6.8335e-02, -1.2181e-01,\n",
       "          2.4701e-01, -5.1530e-02,  1.2441e-01, -5.6590e-02,  1.2005e-01,\n",
       "          1.3201e-01, -2.4858e-02,  8.6666e-02, -4.5921e-02,  9.3157e-02,\n",
       "          6.3326e-02,  3.9900e-02, -1.4168e-02, -2.9439e-02,  8.9053e-02],\n",
       "        [-1.1275e-01,  1.2943e-03, -5.4671e-02, -6.5457e-02, -7.1936e-02,\n",
       "         -1.3738e-02, -3.0450e-02,  1.2147e-01,  9.9804e-02, -1.1622e-01,\n",
       "          1.0904e-01,  9.0601e-02, -8.1999e-02, -3.5589e-02,  2.1940e-01,\n",
       "          1.2496e-02, -5.0089e-02, -8.2836e-02,  3.4453e-02, -6.3917e-03,\n",
       "          9.5113e-02,  4.1443e-02,  8.1753e-02,  3.9420e-02, -5.5499e-02,\n",
       "         -8.2504e-02,  7.4723e-02, -1.4665e-01,  7.0595e-02, -3.6533e-02,\n",
       "          8.3312e-02, -8.9807e-02, -3.5077e-02,  1.9412e-01,  1.8954e-02,\n",
       "          2.2515e-01,  3.8089e-02, -5.1842e-02,  8.1517e-02, -4.1861e-03,\n",
       "          2.3012e-02,  1.4055e-02,  3.7473e-02, -3.2812e-02, -1.2586e-02,\n",
       "         -4.8062e-02, -4.3280e-02, -2.8999e-02, -2.0492e-01,  2.0290e-01],\n",
       "        [-3.6591e-02,  4.6016e-03, -7.6796e-02, -1.8898e-02, -4.2509e-02,\n",
       "          5.2543e-02, -9.9672e-03, -1.1597e-01,  1.5406e-02, -3.6737e-02,\n",
       "          6.9244e-02,  1.5420e-02, -1.1354e-01, -5.1621e-02,  5.0807e-02,\n",
       "          2.1520e-02,  5.6531e-02,  2.4925e-02,  1.6732e-01,  9.6959e-02,\n",
       "          7.0073e-03, -7.5256e-02, -4.8453e-02, -2.2980e-02,  9.7129e-02,\n",
       "          6.9751e-02,  6.9503e-02,  1.0228e-02,  1.1353e-01,  3.1293e-02,\n",
       "         -2.1551e-03, -9.0327e-02,  8.6456e-02,  7.5242e-02,  6.5324e-02,\n",
       "          2.2482e-01, -4.8340e-02,  7.8806e-02, -8.1247e-02,  1.1624e-01,\n",
       "          1.5895e-01,  9.4216e-02, -4.1416e-02,  4.3831e-02, -7.5481e-02,\n",
       "          1.1918e-01, -6.2028e-02, -4.3639e-02, -4.4378e-02,  1.7389e-01],\n",
       "        [-5.7643e-02,  9.0985e-03, -2.9833e-02,  4.5143e-03, -9.8575e-03,\n",
       "         -5.3548e-02,  1.5851e-02, -1.0652e-01,  6.3350e-03, -2.0842e-03,\n",
       "          5.1616e-02,  4.2332e-02,  2.1081e-03, -1.9878e-01,  8.5597e-02,\n",
       "         -1.6425e-01, -5.8760e-03,  3.3283e-02, -1.0720e-01,  1.4510e-01,\n",
       "          2.2784e-02,  4.8351e-02, -1.7794e-01,  1.0362e-02, -6.6807e-02,\n",
       "          2.6328e-02,  4.2177e-02,  4.3030e-02,  4.8680e-02,  1.0780e-01,\n",
       "          1.0842e-01, -6.3398e-02,  1.0684e-02,  3.4621e-02, -3.8505e-02,\n",
       "          9.0589e-02,  3.8153e-02,  1.3906e-01, -1.6519e-02,  4.2114e-02,\n",
       "          1.2325e-01, -7.1997e-02, -3.0775e-02,  6.2293e-02, -3.6598e-02,\n",
       "         -6.2821e-02,  8.2474e-03, -8.8951e-02,  5.3630e-02, -1.4264e-02],\n",
       "        [-7.8254e-02, -8.2792e-02,  1.8675e-02, -3.5932e-02,  5.6793e-02,\n",
       "          5.2942e-02,  7.4303e-02, -3.8158e-02, -8.5450e-02, -1.1032e-01,\n",
       "         -4.6928e-02, -3.1212e-03,  8.4089e-02,  4.6139e-02,  5.1325e-02,\n",
       "          1.7325e-01,  1.2102e-01,  7.5074e-02,  1.6370e-01, -4.7505e-02,\n",
       "          1.2629e-01, -2.2183e-01, -8.4482e-02,  6.4749e-02, -9.5201e-03,\n",
       "         -1.6193e-02,  1.7835e-02, -1.0828e-01,  5.5775e-02, -1.0897e-01,\n",
       "          5.6066e-03, -1.4808e-01, -3.7711e-02,  2.1916e-01, -1.1704e-01,\n",
       "          1.4177e-01,  3.2967e-02,  9.5712e-02, -3.4131e-03,  2.3827e-01,\n",
       "         -1.3770e-02,  3.3080e-02, -1.6552e-01,  9.0251e-02,  1.5492e-02,\n",
       "         -2.8265e-02, -4.8025e-02, -1.1888e-01, -1.7046e-01,  1.3865e-01],\n",
       "        [ 3.4114e-02,  1.0204e-01, -9.0270e-02,  2.8761e-02, -3.7776e-02,\n",
       "         -1.2258e-02, -1.4382e-01,  4.7977e-02,  4.9830e-02,  1.5700e-02,\n",
       "          1.3497e-01,  6.7086e-02, -1.2683e-01, -4.5996e-02,  1.0811e-01,\n",
       "          1.4485e-02,  1.6109e-02,  4.6190e-02,  5.7579e-02,  7.8621e-02,\n",
       "          1.5290e-01, -7.5824e-03,  3.9437e-03, -1.0607e-02,  2.2816e-02,\n",
       "         -8.0109e-02,  7.4569e-02, -3.1358e-02,  9.5366e-02,  3.2356e-03,\n",
       "         -4.7866e-02,  8.0441e-02,  1.0015e-01,  2.1060e-02,  5.2461e-02,\n",
       "          6.3485e-02,  1.0180e-03, -5.4314e-02, -3.3123e-03,  3.4116e-02,\n",
       "          7.1588e-02,  1.3165e-01,  1.0242e-02,  1.3733e-02, -2.7791e-02,\n",
       "         -9.8141e-03, -5.0253e-02,  1.8194e-02, -9.1925e-02,  1.7552e-01],\n",
       "        [ 3.7890e-02,  7.0168e-02, -9.0855e-02,  6.6424e-02, -4.5429e-02,\n",
       "         -5.5615e-02, -1.0286e-01,  9.2074e-03, -1.1636e-02, -2.2935e-02,\n",
       "          8.6468e-02,  2.9843e-02, -1.0275e-01, -3.1200e-02,  5.9485e-02,\n",
       "          8.5958e-03, -1.5521e-02,  1.9868e-02,  8.7264e-02,  8.1197e-02,\n",
       "          1.2720e-01, -2.3281e-02, -1.1109e-02, -2.8612e-05,  8.5473e-03,\n",
       "         -9.9978e-02,  8.3859e-02, -4.0947e-03,  8.3056e-02, -1.4108e-02,\n",
       "         -9.8817e-02,  1.2138e-01,  7.1917e-02, -3.6474e-03,  3.2560e-02,\n",
       "          3.9896e-02,  5.0349e-04, -3.1494e-02, -4.4667e-02,  5.3413e-02,\n",
       "          3.8768e-02,  1.0952e-01,  2.6022e-02, -1.3302e-02, -3.4250e-02,\n",
       "         -1.2320e-02, -2.2463e-02, -1.0446e-03, -5.0203e-02,  2.0068e-01],\n",
       "        [ 3.0044e-03,  9.2889e-02,  4.0899e-02,  6.2183e-02,  8.6703e-02,\n",
       "         -1.2006e-02,  5.7864e-03,  1.6809e-02,  1.0045e-01, -8.5322e-03,\n",
       "          9.9359e-02, -3.2882e-02, -1.6531e-02, -2.0355e-01,  1.4233e-01,\n",
       "         -4.0833e-02, -6.8080e-02,  2.4784e-02,  5.1234e-02,  6.8301e-02,\n",
       "         -6.0353e-02, -5.3563e-02, -7.3836e-02,  4.4007e-02,  6.5564e-02,\n",
       "         -6.5315e-02,  2.8460e-02, -2.5883e-02,  1.4184e-02,  8.0203e-02,\n",
       "         -7.9824e-02, -9.4156e-02,  5.4985e-02,  7.5851e-02, -3.3991e-02,\n",
       "          2.1319e-02, -3.2957e-02,  1.0702e-01, -2.6242e-03,  1.0723e-01,\n",
       "          3.0318e-02,  4.1110e-03, -9.3678e-02, -2.2851e-02, -2.4640e-02,\n",
       "         -7.2871e-02,  7.6433e-02, -1.9022e-01, -3.6434e-02,  1.3717e-01],\n",
       "        [ 3.7890e-02,  7.0168e-02, -9.0855e-02,  6.6424e-02, -4.5429e-02,\n",
       "         -5.5615e-02, -1.0286e-01,  9.2074e-03, -1.1636e-02, -2.2935e-02,\n",
       "          8.6468e-02,  2.9843e-02, -1.0275e-01, -3.1200e-02,  5.9485e-02,\n",
       "          8.5958e-03, -1.5521e-02,  1.9868e-02,  8.7264e-02,  8.1197e-02,\n",
       "          1.2720e-01, -2.3281e-02, -1.1109e-02, -2.8612e-05,  8.5473e-03,\n",
       "         -9.9978e-02,  8.3859e-02, -4.0947e-03,  8.3056e-02, -1.4108e-02,\n",
       "         -9.8817e-02,  1.2138e-01,  7.1917e-02, -3.6474e-03,  3.2560e-02,\n",
       "          3.9896e-02,  5.0349e-04, -3.1494e-02, -4.4667e-02,  5.3413e-02,\n",
       "          3.8768e-02,  1.0952e-01,  2.6022e-02, -1.3302e-02, -3.4250e-02,\n",
       "         -1.2320e-02, -2.2463e-02, -1.0446e-03, -5.0203e-02,  2.0068e-01],\n",
       "        [ 3.4114e-02,  1.0204e-01, -9.0270e-02,  2.8761e-02, -3.7776e-02,\n",
       "         -1.2258e-02, -1.4382e-01,  4.7977e-02,  4.9830e-02,  1.5700e-02,\n",
       "          1.3497e-01,  6.7086e-02, -1.2683e-01, -4.5996e-02,  1.0811e-01,\n",
       "          1.4485e-02,  1.6109e-02,  4.6190e-02,  5.7579e-02,  7.8621e-02,\n",
       "          1.5290e-01, -7.5824e-03,  3.9437e-03, -1.0607e-02,  2.2816e-02,\n",
       "         -8.0109e-02,  7.4569e-02, -3.1358e-02,  9.5366e-02,  3.2356e-03,\n",
       "         -4.7866e-02,  8.0441e-02,  1.0015e-01,  2.1060e-02,  5.2461e-02,\n",
       "          6.3485e-02,  1.0180e-03, -5.4314e-02, -3.3123e-03,  3.4116e-02,\n",
       "          7.1588e-02,  1.3165e-01,  1.0242e-02,  1.3733e-02, -2.7791e-02,\n",
       "         -9.8141e-03, -5.0253e-02,  1.8194e-02, -9.1925e-02,  1.7552e-01]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.narrow(0, 22, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# for idx, i in enumerate(data_loader):\n",
    "#     X = (MolGraph(i[0]))\n",
    "#     Y = (MolGraph(i[1]))\n",
    "#     \n",
    "#     # create your optimizer\n",
    "#     optimizer = torch.optim.SGD(molopt.parameters(), lr=0.01)\n",
    "# \n",
    "#     # in your training loop:\n",
    "#     optimizer.zero_grad()   # zero the gradient buffers\n",
    "#     loss = molopt.forward_train(X, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()    # Does the update\n",
    "# \n",
    "#     print (idx, loss)\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the implemented function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(agg_func='sum', batch_norm=False, cuda=True, device='cuda:0', dropout_ffn=0.0, dropout_gcn=0.0, ffn_activation='LeakyReLU', init_model='gcn2', linear_out=False, n_epochs=200, n_ffn_hidden=100, n_hidden=50, n_labels=1, n_layers=5, output_dir='mol_opt/output', pc_hidden=50)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args.n_epochs = 200 \n",
    "args.output_dir = \"mol_opt/output\"\n",
    "args.init_model = \"gcn2\"\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train\", 48, True)\n",
    "val_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"val\", 48, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model gcn2 found in mol_opt/output! Starting from scratch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latest_model(\"gcn2\", args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\n",
      " train_mse: 0.000310\n",
      " val_mse: 0.000002\n",
      "Epoch duration: 27.781742334365845\n",
      "Model saved to: mol_opt/output/model_gcn2_30\n",
      "Epoch: 31\n",
      " train_mse: 0.000000\n",
      " val_mse: 0.000001\n",
      "Epoch duration: 27.766279697418213\n",
      "Model saved to: mol_opt/output/model_gcn2_31\n",
      "Epoch: 32\n",
      " train_mse: 0.000000\n",
      " val_mse: 0.000000\n",
      "Epoch duration: 28.335959672927856\n",
      "Model saved to: mol_opt/output/model_gcn2_32\n",
      "Epoch: 33\n",
      " train_mse: 0.000000\n",
      " val_mse: 0.000000\n",
      "Epoch duration: 28.279423713684082\n",
      "Model saved to: mol_opt/output/model_gcn2_33\n",
      "Epoch: 34\n",
      " train_mse: 0.000000\n",
      " val_mse: 0.000000\n",
      "Epoch duration: 27.708338737487793\n",
      "Model saved to: mol_opt/output/model_gcn2_34\n",
      "Epoch: 35\n",
      " train_mse: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-89:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/threading.py\", line 304, in wait\n",
      "    self._acquire_restore(saved_state)\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/threading.py\", line 251, in _acquire_restore\n",
      "    def _acquire_restore(self, x):\n",
      "RuntimeError: release unlocked lock\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b45cff8cb532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmolopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, molopt, train_data_loader, val_data_loader)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# compute the validation loss as well, at the end of the epoch?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitrepos/tum-thesis/mol_opt/train_mol_opt.py\u001b[0m in \u001b[0;36mrun_func\u001b[0;34m(model, optim, data_loader, data_type, args)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mstats_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatsTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# zero the gradient buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mol_ot/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 192, in _worker_loop\n",
      "    data_queue.put((idx, data))\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/queues.py\", line 87, in put\n",
      "    self._start_thread()\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/multiprocessing/queues.py\", line 169, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/threading.py\", line 851, in start\n",
      "    self._started.wait()\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/threading.py\", line 552, in wait\n",
      "    return signaled\n",
      "  File \"/home/octav/anaconda3/envs/mol_ot/lib/python3.6/threading.py\", line 243, in __exit__\n",
      "    return self._lock.__exit__(*args)\n"
     ]
    }
   ],
   "source": [
    "molopt = main(args, train_data_loader = train_data_loader, val_data_loader = val_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try out some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedding, x_delta = molopt.forward(X)\n",
    "y_embedding = molopt.encode(Y)\n",
    "y_aligned = molopt.align(x_embedding, X, y_embedding, Y)\n",
    "xhat_delta = molopt.delta(x_embedding, y_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1041, 50])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0329,  0.0609, -0.0998,  ...,  0.0075,  0.0955,  0.0417],\n",
       "        [-0.0989,  0.0230, -0.0382,  ...,  0.0112,  0.0739,  0.0399],\n",
       "        [-0.0075,  0.0569, -0.0903,  ..., -0.0105,  0.1205,  0.0362],\n",
       "        ...,\n",
       "        [-0.0320,  0.0622, -0.1089,  ...,  0.0226,  0.0922,  0.0389],\n",
       "        [-0.0710,  0.0140, -0.0761,  ..., -0.0365,  0.0978,  0.0615],\n",
       "        [-0.0357,  0.0151, -0.0686,  ..., -0.0102,  0.0744,  0.0069]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3743e-02,  4.4010e-02, -3.0419e-02,  ..., -3.1573e-02,\n",
       "          3.3295e-02,  5.1158e-02],\n",
       "        [-1.7625e-01,  1.2730e-01, -6.4805e-02,  ...,  5.5192e-02,\n",
       "          1.4270e-01, -6.1634e-03],\n",
       "        [-7.5377e-02, -1.6244e-02,  5.7163e-02,  ...,  5.2657e-02,\n",
       "          6.2681e-02,  2.1037e-02],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-1.9689e-01, -5.8483e-02,  9.4051e-03,  ...,  1.4330e-01,\n",
       "          3.4291e-01,  1.2687e-01],\n",
       "        [-8.1267e-03,  1.4335e-04, -5.4330e-04,  ..., -4.7268e-03,\n",
       "          1.3943e-02, -8.6641e-03]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0209,  0.0169, -0.0694,  ...,  0.0390,  0.0622, -0.0094],\n",
       "        [ 0.0773, -0.1043,  0.0266,  ..., -0.0440, -0.0688,  0.0460],\n",
       "        [ 0.0679,  0.0732, -0.1474,  ..., -0.0631,  0.0578,  0.0152],\n",
       "        ...,\n",
       "        [-0.0320,  0.0622, -0.1089,  ...,  0.0226,  0.0922,  0.0389],\n",
       "        [ 0.1259,  0.0725, -0.0856,  ..., -0.1798, -0.2451, -0.0654],\n",
       "        [-0.0276,  0.0149, -0.0681,  ..., -0.0054,  0.0605,  0.0156]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_delta - xhat_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0016, -0.0741, -0.0745,  ...,  0.0228, -0.0114, -0.0270],\n",
       "        [ 0.0706, -0.2145, -0.2110,  ...,  0.3129,  0.1174, -0.0711],\n",
       "        [-0.1300, -0.2984,  0.1859,  ..., -0.0819,  0.1519, -0.2849],\n",
       "        ...,\n",
       "        [ 0.2385, -0.1195, -0.1575,  ...,  0.0702, -0.1347,  0.0785],\n",
       "        [ 0.0352,  0.1964, -0.0075,  ..., -0.0421,  0.1371, -0.1475],\n",
       "        [-0.0727,  0.1660,  0.0481,  ...,  0.0867,  0.1587, -0.0863]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molopt.delta(x_embedding, y) - xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<otgnn.graph.mol_graph.Molecule at 0x7fec37dd4f60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mols[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
