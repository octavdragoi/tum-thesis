{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octav/gitrepos/tum-thesis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"ntbk\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"otgnn\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"molgen\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from slot_attention import SlotAttention\n",
    "\n",
    "from otgnn.models import GCN\n",
    "# from molgen.dataloading.MolGraphBatchPreprocessor import MolGraph\n",
    "from otgnn.graph import MolGraph\n",
    "from otgnn.utils import save_model, load_model\n",
    "from otgnn.graph import SYMBOLS, FORMAL_CHARGES, BOND_TYPES\n",
    "\n",
    "\n",
    "from mol_opt2.mol_opt.data_mol_opt import MolOptDataset\n",
    "from mol_opt2.mol_opt.data_mol_opt import get_loader\n",
    "from mol_opt2.mol_opt.arguments import get_args\n",
    "from mol_opt2.mol_opt.train_mol_opt import main\n",
    "from mol_opt2.mol_opt.mol_opt import MolOpt\n",
    "from mol_opt2.mol_opt.decoder_mol_opt import MolOptDecoder\n",
    "from mol_opt2.mol_opt.ot_utils import encode_target\n",
    "from mol_opt2.mol_opt.task_metrics import props\n",
    "\n",
    "from molgen.dataloading.feat2smiles import feat2smiles\n",
    "from molgen.dataloading.mol_drawer import MolDrawer\n",
    "from molgen.metrics.Penalty import Penalty\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/octav/anaconda3/envs/mol_ot/lib/python36.zip', '/home/octav/anaconda3/envs/mol_ot/lib/python3.6', '/home/octav/anaconda3/envs/mol_ot/lib/python3.6/lib-dynload', '', '/home/octav/anaconda3/envs/mol_ot/lib/python3.6/site-packages', '/home/octav/anaconda3/envs/mol_ot/lib/python3.6/site-packages/IPython/extensions', '/home/octav/.ipython', '/home/octav/gitrepos/tum-thesis/otgnn', '/home/octav/gitrepos/tum-thesis/molgen', '/home/octav/gitrepos/tum-thesis/otgnn', '/home/octav/gitrepos/tum-thesis/molgen', '..', '..', '/home/octav/gitrepos/tum-thesis/iclr19-graph2graph/props', '..', '..', '/home/octav/gitrepos/tum-thesis/iclr19-graph2graph/props']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3905e-01,  3.7804e-01, -5.8688e-01,  ..., -3.4940e-01,\n",
       "          -4.8382e-01,  9.0381e-04],\n",
       "         [-9.6186e-01,  3.4954e-01, -2.9336e-01,  ..., -4.0235e-01,\n",
       "          -2.3043e-01, -1.0498e-01],\n",
       "         [-1.9537e-01,  1.9760e-01, -4.3224e-01,  ..., -4.4038e-01,\n",
       "           1.4511e-01, -4.7906e-02],\n",
       "         [-4.4555e-01,  8.6506e-01, -6.6218e-01,  ..., -3.8130e-01,\n",
       "          -4.7370e-01,  1.6384e-01],\n",
       "         [-5.8587e-01,  5.1695e-02, -5.8667e-01,  ..., -8.5430e-01,\n",
       "          -8.3580e-02, -4.5780e-01]],\n",
       "\n",
       "        [[-8.9125e-01,  8.1932e-01, -5.2527e-01,  ..., -9.7158e-02,\n",
       "          -1.3352e-01, -1.1089e-01],\n",
       "         [-2.4210e-01,  1.9234e-01, -9.0357e-01,  ..., -1.3499e-01,\n",
       "           1.1638e-01, -2.7185e-01],\n",
       "         [-1.9571e-01,  2.6238e-01, -3.9523e-01,  ..., -3.2779e-01,\n",
       "           1.3290e-01, -1.6547e-01],\n",
       "         [-7.4695e-01,  6.0923e-01, -1.5586e+00,  ..., -4.2516e-01,\n",
       "          -5.0520e-02, -2.3505e-01],\n",
       "         [-3.9515e-01,  3.0549e-01, -4.1426e-01,  ..., -1.0952e+00,\n",
       "           6.2010e-02, -1.1576e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_attn = SlotAttention(\n",
    "    num_slots = 5,\n",
    "    dim = 512,\n",
    "    iters = 3   # iterations of attention, defaults to 3\n",
    ")\n",
    "\n",
    "inputs = torch.randn(2, 1024, 512)\n",
    "slot_attn(inputs) # (2, 5, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_attn(inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_attn(inputs, num_slots = 8).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\", \"-cuda\"]\n",
    "args = get_args()\n",
    "args.output_dir = \"mol_opt2/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "molopt = MolOpt(args).to(device = args.device)\n",
    "molopt_decoder = MolOptDecoder(args).to(device = args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"train\", 96, False)\n",
    "val_data_loader = get_loader(\"iclr19-graph2graph/data/qed\", \"val\", 96, False)\n",
    "\n",
    "for i in val_data_loader:\n",
    "    X = (MolGraph(i[0]))\n",
    "    Y = (MolGraph(i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2238, 50])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molopt(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2238"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x for _, x in X.scope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# overall flow\n",
    "x_embedding = molopt.forward(X)\n",
    "yhat_logits = molopt_decoder.forward(x_embedding, X, Y)\n",
    "yhat_labels = molopt_decoder.discretize(*yhat_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolOptDecoder(\n",
       "  (slot_att): SlotAttention(\n",
       "    (to_q): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (to_k): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (to_v): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (gru): GRUCell(50, 50)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=128, out_features=50, bias=True)\n",
       "    )\n",
       "    (norm_input): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_slots): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_pre_ff): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc1_SYMBOLS): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc2_SYMBOLS): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (fc1_CHARGES): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc2_CHARGES): Linear(in_features=100, out_features=5, bias=True)\n",
       "  (fc1_BONDS): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2_BONDS): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molopt_decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
